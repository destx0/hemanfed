{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.primitives.asymmetric import dh\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchsummary import summary\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"drone/class_dict_seg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [0 , 1, 2]\n",
    "no_clients = len(clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"drone/dataset/semantic_drone_dataset/label_images_semantic\"\n",
    "original_image_path = \"drone/dataset/semantic_drone_dataset/original_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(image_path)\n",
    "\n",
    "# Filter out only the image files (assuming image files have extensions like .jpg, .png, etc.)\n",
    "image_files = [\n",
    "    file for file in files if file.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\"))\n",
    "]\n",
    "image_files = sorted(image_files)\n",
    "\n",
    "# list o image_paths\n",
    "image_list = []\n",
    "# Print the list of image files\n",
    "for image_file in image_files:\n",
    "    image_list.append(image_path + \"/\" + image_file)\n",
    "\n",
    "\n",
    "files_2 = os.listdir(original_image_path)\n",
    "# Filter out only the image files (assuming image files have extensions like .jpg, .png, etc.)\n",
    "image_files = [\n",
    "    file for file in files_2 if file.endswith((\".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\"))\n",
    "]\n",
    "image_files = sorted(image_files)\n",
    "\n",
    "# list o image_paths\n",
    "original_image_list = []\n",
    "# Print the list of image files\n",
    "for image_file in image_files:\n",
    "    original_image_list.append(original_image_path + \"/\" + image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"drone/dataset/semantic_drone_dataset/original_images\"\n",
    "MASK_PATH = \"drone/dataset/semantic_drone_dataset/label_images_semantic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 23\n",
    "\n",
    "\n",
    "def create_df():\n",
    "    name = []\n",
    "    for dirname, _, filenames in os.walk(IMAGE_PATH):\n",
    "        for filename in filenames:\n",
    "            name.append(filename.split(\".\")[0])\n",
    "\n",
    "    return pd.DataFrame({\"id\": name}, index=np.arange(0, len(name)))\n",
    "\n",
    "\n",
    "df = create_df()\n",
    "print(\"Total Images: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data for traning , testing and validation\n",
    "X_trainval, X_test = train_test_split(df[\"id\"].values, test_size=0.1, random_state=42)\n",
    "X_train, X_val = train_test_split(X_trainval, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train = [X_train[i*len(X_train)//no_clients:(i+1)*len(X_train)//no_clients] for i in range(no_clients)]\n",
    "split_val = [X_val[i*len(X_val)//no_clients:(i+1)*len(X_val)//no_clients] for i in range(no_clients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(split_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DroneDataset(Dataset):\n",
    "\n",
    "    def __init__(self, img_path, mask_path, X, mean, std, transform=None, patch=False):\n",
    "        self.img_path = img_path\n",
    "        self.mask_path = mask_path\n",
    "        self.X = X\n",
    "        self.transform = transform\n",
    "        self.patches = patch\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_full_path = os.path.join(self.img_path, self.X[idx] + \".jpg\")\n",
    "        mask_full_path = os.path.join(self.mask_path, self.X[idx] + \".png\")\n",
    "\n",
    "        # Load the image and mask\n",
    "        img = cv2.imread(img_full_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image not found at {img_full_path}\")\n",
    "\n",
    "        mask = cv2.imread(mask_full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            raise FileNotFoundError(f\"Mask not found at {mask_full_path}\")\n",
    "\n",
    "        # Convert color from BGR to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            aug = self.transform(image=img, mask=mask)\n",
    "            img = Image.fromarray(aug[\"image\"])\n",
    "            mask = aug[\"mask\"]\n",
    "\n",
    "        if self.transform is None:\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])\n",
    "        img = t(img)\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "\n",
    "        if self.patches:\n",
    "            img, mask = self.tiles(img, mask)\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "    def tiles(self, img, mask):\n",
    "\n",
    "        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768)\n",
    "        img_patches = img_patches.contiguous().view(3, -1, 512, 768)\n",
    "        img_patches = img_patches.permute(1, 0, 2, 3)\n",
    "\n",
    "        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)\n",
    "        mask_patches = mask_patches.contiguous().view(-1, 512, 768)\n",
    "\n",
    "        return img_patches, mask_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "t_train = A.Compose(\n",
    "    [\n",
    "        A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST),\n",
    "        A.HorizontalFlip(),\n",
    "        A.VerticalFlip(),\n",
    "        A.GridDistortion(p=0.2),\n",
    "        A.RandomBrightnessContrast((0, 0.5), (0, 0.5)),\n",
    "        A.GaussNoise(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "t_val = A.Compose(\n",
    "    [\n",
    "        A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST),\n",
    "        A.HorizontalFlip(),\n",
    "        A.GridDistortion(p=0.2),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# datasets\n",
    "train_set = DroneDataset(\n",
    "    IMAGE_PATH, MASK_PATH, X_train, mean, std, t_train, patch=False\n",
    ")\n",
    "val_set = DroneDataset(IMAGE_PATH, MASK_PATH, X_val, mean, std, t_val, patch=False)\n",
    "\n",
    "# dataloader\n",
    "batch_size = 1\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "train_loaders = []\n",
    "val_loaders = [] \n",
    "for i in range(no_clients):\n",
    "    b_train = split_train[i]\n",
    "    b_val = split_val[i]\n",
    "    train_set = DroneDataset(\n",
    "        IMAGE_PATH, MASK_PATH, b_train, mean, std, t_train, patch=False\n",
    "    )\n",
    "    val_set = DroneDataset(IMAGE_PATH, MASK_PATH, b_val, mean, std, t_val, patch=False)\n",
    "\n",
    "    # dataloader\n",
    "    batch_size = 1\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "    train_loaders.append(train_loader)\n",
    "    val_loaders.append(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(no_clients):\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet34\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=n_classes,\n",
    "    )\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(output, mask):\n",
    "    with torch.no_grad():\n",
    "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
    "        correct = torch.eq(output, mask).int()\n",
    "        accuracy = float(correct.sum()) / float(correct.numel())\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=23):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(0, n_classes):  # loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0:  # no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = (\n",
    "                    torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                )\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union + smooth)\n",
    "                iou_per_class.append(iou)\n",
    "        return np.nanmean(iou_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot(pred_masks, true_masks):\n",
    "    n_classes = len(np.unique(true_masks))  # Number of unique classes\n",
    "    class_colors = plt.cm.tab20.colors  # Colors for different classes\n",
    "\n",
    "    n_images = pred_masks.shape[0]  # Number of images\n",
    "\n",
    "    # Create subplots outside the loop\n",
    "    fig, axes = plt.subplots(n_images, 2, figsize=(10, 5 * n_images))\n",
    "\n",
    "    for i in range(n_images):\n",
    "        im_pred = axes[i, 0].imshow(\n",
    "            pred_masks[i, 0], cmap=\"tab20\", vmin=0, vmax=n_classes - 1\n",
    "        )  # Assuming single channel masks\n",
    "        axes[i, 0].set_title(\"Predicted Mask\")\n",
    "        axes[i, 0].set_axis_off()\n",
    "        fig.colorbar(im_pred, ax=axes[i, 0], label=\"Predicted Class\")\n",
    "\n",
    "        im_true = axes[i, 1].imshow(\n",
    "            true_masks[i], cmap=\"tab20\", vmin=0, vmax=n_classes - 1\n",
    "        )\n",
    "        axes[i, 1].set_title(\"True Mask\")\n",
    "        axes[i, 1].set_axis_off()\n",
    "        fig.colorbar(im_true, ax=axes[i, 1], label=\"True Class\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import learn2learn as l2l\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group[\"lr\"]\n",
    "\n",
    "\n",
    "def fit(\n",
    "    epochs,\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    patch=False,\n",
    "    adaptation_steps=5,\n",
    "    inner_lr=0.01,\n",
    "):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    val_iou = []\n",
    "    val_acc = []\n",
    "    train_iou = []\n",
    "    train_acc = []\n",
    "    lrs = []\n",
    "    min_loss = np.inf\n",
    "    decrease = 1\n",
    "    not_improve = 0\n",
    "\n",
    "    model.to(device)\n",
    "    fit_time = time.time()\n",
    "    for e in range(epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0\n",
    "        iou_score = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        # training loop\n",
    "        model.train()\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "            # training phase\n",
    "            image_tiles, mask_tiles = data\n",
    "            if patch:\n",
    "                bs, n_tiles, c, h, w = image_tiles.size()\n",
    "                image_tiles = image_tiles.view(-1, c, h, w)\n",
    "                mask_tiles = mask_tiles.view(-1, h, w)\n",
    "\n",
    "            image = image_tiles.to(device)\n",
    "            mask = mask_tiles.to(device)\n",
    "\n",
    "            # Meta-learning with MAML\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Clone the model for inner-loop updates\n",
    "            learner = l2l.algorithms.MAML(model, lr=inner_lr).clone()\n",
    "\n",
    "            # Inner loop: Adaptation\n",
    "            for step in range(adaptation_steps):\n",
    "                output = learner(image)\n",
    "                loss = criterion(output, mask)\n",
    "                learner.adapt(loss)\n",
    "\n",
    "            # Meta-update\n",
    "            output = learner(image)\n",
    "            loss = criterion(output, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Step the learning rate\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            # Evaluation metrics\n",
    "            iou_score += mIoU(output, mask)\n",
    "            accuracy += pixel_accuracy(output, mask)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_accuracy = 0\n",
    "        val_iou_score = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(tqdm(val_loader)):\n",
    "                image_tiles, mask_tiles = data\n",
    "                if patch:\n",
    "                    bs, n_tiles, c, h, w = image_tiles.size()\n",
    "                    image_tiles = image_tiles.view(-1, c, h, w)\n",
    "                    mask_tiles = mask_tiles.view(-1, h, w)\n",
    "\n",
    "                image = image_tiles.to(device)\n",
    "                mask = mask_tiles.to(device)\n",
    "\n",
    "                output = model(image)\n",
    "                val_iou_score += mIoU(output, mask)\n",
    "                test_accuracy += pixel_accuracy(output, mask)\n",
    "                loss = criterion(output, mask)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        # Calculate mean for each batch\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        test_losses.append(test_loss / len(val_loader))\n",
    "\n",
    "        if min_loss > (test_loss / len(val_loader)):\n",
    "            print(\n",
    "                \"Loss Decreasing.. {:.3f} >> {:.3f} \".format(\n",
    "                    min_loss, (test_loss / len(val_loader))\n",
    "                )\n",
    "            )\n",
    "            min_loss = test_loss / len(val_loader)\n",
    "            decrease += 1\n",
    "            if decrease % 5 == 0:\n",
    "                print(\"saving model...\")\n",
    "                torch.save(\n",
    "                    model,\n",
    "                    \"Unet-Mobilenet_v2_mIoU-{:.3f}.pt\".format(\n",
    "                        val_iou_score / len(val_loader)\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "        if (test_loss / len(val_loader)) > min_loss:\n",
    "            not_improve += 1\n",
    "            min_loss = test_loss / len(val_loader)\n",
    "            print(f\"Loss Not Decrease for {not_improve} time\")\n",
    "            if not_improve == 7:\n",
    "                print(\"Loss not decrease for 7 times, Stop Training\")\n",
    "                break\n",
    "\n",
    "        # Update metrics\n",
    "        val_iou.append(val_iou_score / len(val_loader))\n",
    "        train_iou.append(iou_score / len(train_loader))\n",
    "        train_acc.append(accuracy / len(train_loader))\n",
    "        val_acc.append(test_accuracy / len(val_loader))\n",
    "        print(\n",
    "            \"Epoch:{}/{}..\".format(e + 1, epochs),\n",
    "            \"Train Loss: {:.3f}..\".format(running_loss / len(train_loader)),\n",
    "            \"Val Loss: {:.3f}..\".format(test_loss / len(val_loader)),\n",
    "            \"Train mIoU:{:.3f}..\".format(iou_score / len(train_loader)),\n",
    "            \"Val mIoU: {:.3f}..\".format(val_iou_score / len(val_loader)),\n",
    "            \"Train Acc:{:.3f}..\".format(accuracy / len(train_loader)),\n",
    "            \"Val Acc:{:.3f}..\".format(test_accuracy / len(val_loader)),\n",
    "            \"Time: {:.2f}m\".format((time.time() - since) / 60),\n",
    "        )\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": train_losses,\n",
    "        \"val_loss\": test_losses,\n",
    "        \"train_miou\": train_iou,\n",
    "        \"val_miou\": val_iou,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"lrs\": lrs,\n",
    "    }\n",
    "    print(\"Total time: {:.2f} m\".format((time.time() - fit_time) / 60))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr = 1e-3\n",
    "epoch = 2\n",
    "weight_decay = 1e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr, epochs=epoch, steps_per_epoch=len(train_loader)\n",
    ")\n",
    "\n",
    "history = fit(epoch, model, train_loader, val_loader, criterion, optimizer, sched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Pyfhel import Pyfhel\n",
    "\n",
    "HE = Pyfhel()\n",
    "ckks_params = {\n",
    "    \"scheme\": \"CKKS\",\n",
    "    \"n\": 2**14,  # Polynomial modulus degree. For CKKS, n/2 values can be\n",
    "    \"scale\": 2**30,  # All the encodings will use it for float->fixed point\n",
    "    \"qi_sizes\": [60, 30, 30, 30, 60],  # Number of bits of each prime in the chain.\n",
    "}\n",
    "HE.contextGen(**ckks_params)  # Generate context for ckks scheme\n",
    "HE.keyGen()  # Key Generation: generates a pair of public/secret keys\n",
    "HE.rotateKeyGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diffie_hellman_parameters():\n",
    "    parameters = dh.generate_parameters(generator=2, key_size=512)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def generate_diffie_hellman_keys(parameters):\n",
    "    private_key = parameters.generate_private_key()\n",
    "    public_key = private_key.public_key()\n",
    "    return private_key, public_key\n",
    "\n",
    "\n",
    "def derive_key(private_key, peer_public_key):\n",
    "    shared_key = private_key.exchange(peer_public_key)\n",
    "    derived_key = HKDF(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32,\n",
    "        salt=None,\n",
    "        info=b\"handshake data\",\n",
    "    ).derive(shared_key)\n",
    "    return derived_key\n",
    "\n",
    "\n",
    "def encrypt_message_AES(key, message):\n",
    "    serialized_obj = pickle.dumps(message)\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    encryptor = cipher.encryptor()\n",
    "    padded_obj = serialized_obj + b\" \" * (16 - len(serialized_obj) % 16)\n",
    "    ciphertext = encryptor.update(padded_obj) + encryptor.finalize()\n",
    "    return ciphertext\n",
    "\n",
    "\n",
    "def decrypt_message_AES(key, ciphertext):\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    decryptor = cipher.decryptor()\n",
    "    padded_obj = decryptor.update(ciphertext) + decryptor.finalize()\n",
    "    serialized_obj = padded_obj.rstrip(b\" \")\n",
    "    obj = pickle.loads(serialized_obj)\n",
    "    return obj\n",
    "\n",
    "\n",
    "def setup_AES():\n",
    "    num_clients = len(clients)\n",
    "    parameters = generate_diffie_hellman_parameters()\n",
    "    server_private_key, server_public_key = generate_diffie_hellman_keys(parameters)\n",
    "    client_keys = [generate_diffie_hellman_keys(parameters) for _ in range(num_clients)]\n",
    "    shared_keys = [\n",
    "        derive_key(server_private_key, client_public_key)\n",
    "        for _, client_public_key in client_keys\n",
    "    ]\n",
    "    client_shared_keys = [\n",
    "        derive_key(client_private_key, server_public_key)\n",
    "        for client_private_key, _ in client_keys\n",
    "    ]\n",
    "\n",
    "    return client_keys, shared_keys, client_shared_keys\n",
    "\n",
    "client_keys, shared_keys, client_shared_keys = setup_AES()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model, weights):\n",
    "    with torch.no_grad(): \n",
    "        for param, weight in zip(model.parameters(), weights):\n",
    "            param.copy_(torch.tensor(weight))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model):\n",
    "    return [param.cpu().detach().numpy() for param in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_wt(encypted_cwts):\n",
    "    cwts = []\n",
    "    for i, ecwt in enumerate(encypted_cwts):\n",
    "        cwts.append(decrypt_message_AES(shared_keys[i], ecwt))\n",
    "    resmodel = []\n",
    "    for j in range(len(cwts[0])):  # for layers\n",
    "        layer = []\n",
    "        for k in range(len(cwts[0][j])):  # for chunks\n",
    "            tmp = cwts[0][j][k].copy()\n",
    "            for i in range(1, len(cwts)):  # for clients\n",
    "                tmp = tmp + cwts[i][j][k]\n",
    "            tmp = tmp / len(cwts)\n",
    "            layer.append(tmp)\n",
    "        resmodel.append(layer)\n",
    "\n",
    "    res = [resmodel.copy() for _ in range(len(clients))]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_wt(wtarray, i):\n",
    "    cwt = []\n",
    "    for layer in wtarray:\n",
    "        flat_array = layer.astype(np.float64).flatten()\n",
    "\n",
    "        chunks = np.array_split(flat_array, (len(flat_array) + 2**10 - 1) // 2**10)\n",
    "        clayer = []\n",
    "        for chunk in chunks:\n",
    "            ptxt = HE.encodeFrac(chunk)\n",
    "            ctxt = HE.encryptPtxt(ptxt)\n",
    "            clayer.append(ctxt)\n",
    "        cwt.append(clayer.copy())\n",
    "    ciphertext = encrypt_message_AES(client_shared_keys[i], cwt)\n",
    "    return ciphertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_weights(res):\n",
    "    decrypted_weights = []\n",
    "    for client_weights, model in zip(res, models):\n",
    "        decrypted_client_weights = []\n",
    "        wtarray = get_weights(model)\n",
    "        for layer_weights, layer in zip(client_weights, wtarray):\n",
    "            decrypted_layer_weights = []\n",
    "            flat_array = layer.astype(np.float64).flatten()\n",
    "            chunks = np.array_split(flat_array, (len(flat_array) + 2**10 - 1) // 2**10)\n",
    "            for chunk, encrypted_chunk in zip(chunks, layer_weights):\n",
    "                decrypted_chunk = HE.decryptFrac(encrypted_chunk)\n",
    "                original_chunk_size = len(chunk)\n",
    "                decrypted_chunk = decrypted_chunk[:original_chunk_size]\n",
    "                decrypted_layer_weights.append(decrypted_chunk)\n",
    "            decrypted_layer_weights = np.concatenate(decrypted_layer_weights, axis=0)\n",
    "            decrypted_layer_weights = decrypted_layer_weights.reshape(layer.shape)\n",
    "            decrypted_client_weights.append(decrypted_layer_weights)\n",
    "        decrypted_weights.append(decrypted_client_weights)\n",
    "    return decrypted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = []\n",
    "\n",
    "for e in range(epoch):\n",
    "    cwts = aggregate_wt(cwts)\n",
    "    wts = decrypt_weights(cwts)\n",
    "    cwts = []\n",
    "    epoch_histories = []  \n",
    "\n",
    "    for i in range(no_clients):\n",
    "        wt = wts[i]\n",
    "        model = load_weights(models[i], wt)\n",
    "        train_loader = train_loaders[i]\n",
    "        val_loader = val_loaders[i]\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), lr=max_lr, weight_decay=weight_decay\n",
    "        )\n",
    "        sched = torch.optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer, max_lr, epochs=1, steps_per_epoch=len(train_loader)\n",
    "        )\n",
    "        history = fit(\n",
    "            1, model, train_loader, val_loader, criterion, optimizer, sched\n",
    "        )\n",
    "        epoch_histories.append(history)  \n",
    "        wtarray = get_weights(model)\n",
    "        cwts.append(encrypt_wt(wtarray, i))\n",
    "\n",
    "    histories.append(epoch_histories)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"Maml-Mobilenet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history[\"val_loss\"], label=\"val\", marker=\"o\")\n",
    "    plt.plot(history[\"train_loss\"], label=\"train\", marker=\"o\")\n",
    "    plt.title(\"Loss per epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend(), plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_score(history):\n",
    "    plt.plot(history[\"train_miou\"], label=\"train_mIoU\", marker=\"*\")\n",
    "    plt.plot(history[\"val_miou\"], label=\"val_mIoU\", marker=\"*\")\n",
    "    plt.title(\"Score per epoch\")\n",
    "    plt.ylabel(\"mean IoU\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend(), plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_acc(history):\n",
    "    plt.plot(history[\"train_acc\"], label=\"train_accuracy\", marker=\"*\")\n",
    "    plt.plot(history[\"val_acc\"], label=\"val_accuracy\", marker=\"*\")\n",
    "    plt.title(\"Accuracy per epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend(), plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)\n",
    "plot_score(history)\n",
    "plot_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DroneTestDataset(Dataset):\n",
    "\n",
    "    def __init__(self, img_path, mask_path, X, transform=None):\n",
    "        self.img_path = img_path\n",
    "        self.mask_path = mask_path\n",
    "        self.X = X\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_full_path = os.path.join(self.img_path, self.X[idx] + \".jpg\")\n",
    "        mask_full_path = os.path.join(self.mask_path, self.X[idx] + \".png\")\n",
    "\n",
    "        img = cv2.imread(img_full_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image not found at {img_full_path}\")\n",
    "\n",
    "        mask = cv2.imread(mask_full_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if mask is None:\n",
    "            raise FileNotFoundError(f\"Mask not found at {mask_full_path}\")\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            aug = self.transform(image=img, mask=mask)\n",
    "            img = Image.fromarray(aug[\"image\"])\n",
    "            mask = aug[\"mask\"]\n",
    "\n",
    "        if self.transform is None:\n",
    "            img = Image.fromarray(img)\n",
    "\n",
    "        mask = torch.from_numpy(mask).long()\n",
    "\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "t_test = A.Resize(768, 1152, interpolation=cv2.INTER_NEAREST)\n",
    "test_set = DroneTestDataset(IMAGE_PATH, MASK_PATH, X_test, transform=t_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_mask_miou(\n",
    "    model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "):\n",
    "    model.eval()\n",
    "    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
    "    image = t(image)\n",
    "    model.to(device)\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        image = image.unsqueeze(0)\n",
    "        mask = mask.unsqueeze(0)\n",
    "\n",
    "        output = model(image)\n",
    "        score = mIoU(output, mask)\n",
    "        masked = torch.argmax(output, dim=1)\n",
    "        masked = masked.cpu().squeeze(0)\n",
    "    return masked, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_mask_pixel(\n",
    "    model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "):\n",
    "    model.eval()\n",
    "    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
    "    image = t(image)\n",
    "    model.to(device)\n",
    "    image = image.to(device)\n",
    "    mask = mask.to(device)\n",
    "    with torch.no_grad():\n",
    "\n",
    "        image = image.unsqueeze(0)\n",
    "        mask = mask.unsqueeze(0)\n",
    "\n",
    "        output = model(image)\n",
    "        acc = pixel_accuracy(output, mask)\n",
    "        masked = torch.argmax(output, dim=1)\n",
    "        masked = masked.cpu().squeeze(0)\n",
    "    return masked, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = test_set[3]\n",
    "pred_mask, score = predict_image_mask_miou(model, image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def miou_score(model, test_set):\n",
    "    score_iou = []\n",
    "    for i in tqdm(range(len(test_set))):\n",
    "        img, mask = test_set[i]\n",
    "        pred_mask, score = predict_image_mask_miou(model, img, mask)\n",
    "        score_iou.append(score)\n",
    "    return score_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mob_miou = miou_score(model, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_acc(model, test_set):\n",
    "    accuracy = []\n",
    "    for i in tqdm(range(len(test_set))):\n",
    "        img, mask = test_set[i]\n",
    "        pred_mask, acc = predict_image_mask_pixel(model, img, mask)\n",
    "        accuracy.append(acc)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_acc = pixel_acc(model, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 10))\n",
    "ax1.imshow(image)\n",
    "ax1.set_title(\"Picture\")\n",
    "\n",
    "ax2.imshow(mask)\n",
    "ax2.set_title(\"Ground truth\")\n",
    "ax2.set_axis_off()\n",
    "\n",
    "ax3.imshow(pred_mask)\n",
    "ax3.set_title(\"UNet-MobileNet | mIoU {:.3f}\".format(score))\n",
    "ax3.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image3, mask3 = test_set[6]\n",
    "pred_mask3, score3 = predict_image_mask_miou(model, image3, mask3)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 10))\n",
    "ax1.imshow(image3)\n",
    "ax1.set_title(\"Picture\")\n",
    "\n",
    "ax2.imshow(mask3)\n",
    "ax2.set_title(\"Ground truth\")\n",
    "ax2.set_axis_off()\n",
    "\n",
    "ax3.imshow(pred_mask3)\n",
    "ax3.set_title(\"UNet-MobileNet | mIoU {:.3f}\".format(score3))\n",
    "ax3.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Set mIoU\", np.mean(mob_miou))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test Set Pixel Accuracy\", np.mean(mob_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "he39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
