{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.primitives.asymmetric import dh\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [0 , 1, 2]\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train_all = x_train_all.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(\n",
    "                32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# # Define the MAML model\n",
    "# class MAML(tf.keras.Model):\n",
    "#     def __init__(self, model):\n",
    "#         super(MAML, self).__init__()\n",
    "#         self.model = model\n",
    "\n",
    "#     def train_step(self, data):\n",
    "#         x, y = data\n",
    "#         x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "#         y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             y_pred = self.model(x)\n",
    "#             loss = self.compiled_loss(y, y_pred)\n",
    "#         gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "#         self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "#         self.compiled_metrics.update_state(y, y_pred)\n",
    "#         return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "#     def test_step(self, data):\n",
    "#         x, y = data\n",
    "#         x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "#         y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "#         y_pred = self.model(x)\n",
    "#         self.compiled_loss(y, y_pred)\n",
    "#         self.compiled_metrics.update_state(y, y_pred)\n",
    "#         return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "class MAML(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(MAML, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "        return self.model(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"model\": self.model.get_config()}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        model = tf.keras.models.Model.from_config(config[\"model\"])\n",
    "        return cls(model)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "        y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "        y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "        y_pred = self.model(x)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "# Define the meta-learning parameters\n",
    "num_meta_updates = 10\n",
    "num_inner_updates = 5\n",
    "meta_batch_size = 32\n",
    "inner_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# assume X is your feature data and y is your target data\n",
    "X_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_train_all, y_train_all, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# split data into n parts\n",
    "n_parts = len(clients)\n",
    "part_size = len(X_train) // n_parts\n",
    "dataset_parts = []\n",
    "for i in range(n_parts):\n",
    "    start = i * part_size\n",
    "    end = (i + 1) * part_size\n",
    "    X_part = X_train[start:end]\n",
    "    y_part = y_train[start:end]\n",
    "    dataset_parts.append((X_part, y_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 16000)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dataset_parts\n",
    "x , y = a[2]\n",
    "len(x) , len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    model = MAML(create_model())\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Num GPUs Available: \", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.19 (main, May  6 2024, 19:43:03) \n",
      "[GCC 11.2.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Get the Python version\n",
    "python_version = sys.version\n",
    "\n",
    "# Print the Python version\n",
    "print(f\"Python version: {python_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for _ in range(len(clients)):\n",
    "    models.append(model_init())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Pyfhel import Pyfhel\n",
    "\n",
    "HE = Pyfhel() \n",
    "ckks_params = {\n",
    "    \"scheme\": \"CKKS\", \n",
    "    \"n\": 2**14,  # Polynomial modulus degree. For CKKS, n/2 values can be\n",
    "    \"scale\": 2**30,  # All the encodings will use it for float->fixed point\n",
    "    \"qi_sizes\": [60, 30, 30, 30, 60],  # Number of bits of each prime in the chain.\n",
    "}\n",
    "HE.contextGen(**ckks_params)  # Generate context for ckks scheme\n",
    "HE.keyGen()  # Key Generation: generates a pair of public/secret keys\n",
    "HE.rotateKeyGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 3, 1, 32), (32,), (3, 3, 32, 64), (64,), (3, 3, 64, 64), (64,), (576, 64), (64,), (64, 10), (10,)]\n"
     ]
    }
   ],
   "source": [
    "shapedims = [l.shape for l in models[0].get_weights()]\n",
    "print(shapedims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diffie_hellman_parameters():\n",
    "    parameters = dh.generate_parameters(generator=2, key_size=512)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def generate_diffie_hellman_keys(parameters):\n",
    "    private_key = parameters.generate_private_key()\n",
    "    public_key = private_key.public_key()\n",
    "    return private_key, public_key\n",
    "\n",
    "\n",
    "def derive_key(private_key, peer_public_key):\n",
    "    shared_key = private_key.exchange(peer_public_key)\n",
    "    derived_key = HKDF(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32,\n",
    "        salt=None,\n",
    "        info=b\"handshake data\",\n",
    "    ).derive(shared_key)\n",
    "    return derived_key\n",
    "\n",
    "\n",
    "def encrypt_message_AES(key, message):\n",
    "    serialized_obj = pickle.dumps(message)\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    encryptor = cipher.encryptor()\n",
    "    padded_obj = serialized_obj + b\" \" * (16 - len(serialized_obj) % 16)\n",
    "    ciphertext = encryptor.update(padded_obj) + encryptor.finalize()\n",
    "    return ciphertext\n",
    "\n",
    "\n",
    "def decrypt_message_AES(key, ciphertext):\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    decryptor = cipher.decryptor()\n",
    "    padded_obj = decryptor.update(ciphertext) + decryptor.finalize()\n",
    "    serialized_obj = padded_obj.rstrip(b\" \")\n",
    "    obj = pickle.loads(serialized_obj)\n",
    "    return obj\n",
    "\n",
    "\n",
    "def setup_AES():\n",
    "    num_clients = len(clients)\n",
    "    parameters = generate_diffie_hellman_parameters()\n",
    "    server_private_key, server_public_key = generate_diffie_hellman_keys(parameters)\n",
    "    client_keys = [generate_diffie_hellman_keys(parameters) for _ in range(num_clients)]\n",
    "    shared_keys = [\n",
    "        derive_key(server_private_key, client_public_key)\n",
    "        for _, client_public_key in client_keys\n",
    "    ]\n",
    "    client_shared_keys = [\n",
    "        derive_key(client_private_key, server_public_key)\n",
    "        for client_private_key, _ in client_keys\n",
    "    ]\n",
    "\n",
    "    return client_keys, shared_keys , client_shared_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_keys, shared_keys, client_shared_keys = setup_AES()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_wt(wtarray , i):\n",
    "    cwt = []\n",
    "    for layer in wtarray:\n",
    "        flat_array = layer.astype(np.float64).flatten()\n",
    "\n",
    "        chunks = np.array_split(flat_array, (len(flat_array) + 2**10 - 1) // 2**10)\n",
    "        clayer = []\n",
    "        for chunk in chunks:\n",
    "            ptxt = HE.encodeFrac(chunk)\n",
    "            ctxt = HE.encryptPtxt(ptxt)\n",
    "            clayer.append(ctxt)\n",
    "        cwt.append(clayer.copy())\n",
    "    ciphertext = encrypt_message_AES(client_shared_keys[i], cwt)\n",
    "    return ciphertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_wt(encypted_cwts):\n",
    "    cwts = []\n",
    "    for i , ecwt in enumerate(encypted_cwts):\n",
    "        cwts.append(decrypt_message_AES(shared_keys[i], ecwt))\n",
    "    resmodel = []\n",
    "    for j in range(len(cwts[0])):  # for layers\n",
    "        layer = []\n",
    "        for k in range(len(cwts[0][j])):  # for chunks\n",
    "            tmp = cwts[0][j][k].copy()\n",
    "            for i in range(1, len(cwts)):  # for clients\n",
    "                tmp = tmp + cwts[i][j][k]\n",
    "            tmp = tmp / len(cwts)\n",
    "            layer.append(tmp)\n",
    "        resmodel.append(layer)\n",
    "\n",
    "    res = [resmodel.copy() for _ in range(len(clients))]\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_weights(res):\n",
    "    decrypted_weights = []\n",
    "    for client_weights, model in zip(res, models):\n",
    "        decrypted_client_weights = []\n",
    "        wtarray = model.get_weights()\n",
    "        for layer_weights, layer in zip(client_weights, wtarray):\n",
    "            decrypted_layer_weights = []\n",
    "            flat_array = layer.astype(np.float64).flatten()\n",
    "            chunks = np.array_split(flat_array, (len(flat_array) + 2**10 - 1) // 2**10)\n",
    "            for chunk, encrypted_chunk in zip(chunks, layer_weights):\n",
    "                decrypted_chunk = HE.decryptFrac(encrypted_chunk)\n",
    "                original_chunk_size = len(chunk)\n",
    "                decrypted_chunk = decrypted_chunk[:original_chunk_size]\n",
    "                decrypted_layer_weights.append(decrypted_chunk)\n",
    "            decrypted_layer_weights = np.concatenate(decrypted_layer_weights, axis=0)\n",
    "            decrypted_layer_weights = decrypted_layer_weights.reshape(layer.shape)\n",
    "            decrypted_client_weights.append(decrypted_layer_weights)\n",
    "        decrypted_weights.append(decrypted_client_weights)\n",
    "    return decrypted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [[] for _ in range(len(clients))]\n",
    "losses = [[] for _ in range(len(clients))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, x_train, y_train):\n",
    "#     meta_updates = []\n",
    "#     accuracy_over_time = []\n",
    "#     for meta_update in range(num_meta_updates):\n",
    "#         # Sample a meta-batch of tasks\n",
    "#         meta_batch = tf.random.shuffle(tf.range(len(x_train)))[:meta_batch_size]\n",
    "\n",
    "#         # Inner loop updates for each task\n",
    "#         for task in meta_batch:\n",
    "#             task_data = (\n",
    "#                 x_train[task : task + inner_batch_size],\n",
    "#                 y_train[task : task + inner_batch_size],\n",
    "#             )\n",
    "            \n",
    "#             for inner_update in range(num_inner_updates):\n",
    "#                 model.train_step(task_data)\n",
    "\n",
    "#         # Evaluate on the meta-test set\n",
    "#         _, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "#         # Store the meta-update step and accuracy\n",
    "#         meta_updates.append(meta_update + 1)\n",
    "#         accuracy_over_time.append(accuracy)\n",
    "#     avg_accuracy = sum(accuracy_over_time) / len(accuracy_over_time)\n",
    "#     return model , avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_batch_size = 32  # Number of tasks per meta-update\n",
    "inner_batch_size = 5  # Number of examples per task\n",
    "num_inner_updates = 5  # Number of inner loop updates per task\n",
    "num_meta_updates = 100\n",
    "optimizer = tf.keras.optimizers.legacy.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train):\n",
    "    meta_updates = []\n",
    "    accuracy_over_time = []\n",
    "    for meta_update in range(num_meta_updates):\n",
    "        # Sample a meta-batch of tasks\n",
    "        meta_batch = tf.random.shuffle(tf.range(len(x_train)))[:meta_batch_size]\n",
    "\n",
    "        # Inner loop updates for each task\n",
    "        task_gradients = []\n",
    "        for task in meta_batch:\n",
    "            task_data = (\n",
    "                x_train[task : task + inner_batch_size],\n",
    "                y_train[task : task + inner_batch_size],\n",
    "            )\n",
    "\n",
    "            with tf.GradientTape() as outer_tape:\n",
    "                with tf.GradientTape() as inner_tape:\n",
    "                    # Forward pass on the task-specific data\n",
    "                    predictions = model(task_data[0])\n",
    "                    loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "                        task_data[1], predictions\n",
    "                    )\n",
    "\n",
    "                # Compute gradients for inner loop update\n",
    "                inner_gradients = inner_tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "                # Apply inner loop update to the model's variables\n",
    "                inner_model = MAML(create_model())\n",
    "                inner_model.set_weights(model.get_weights())\n",
    "                optimizer.apply_gradients(\n",
    "                    zip(inner_gradients, inner_model.trainable_variables)\n",
    "                )\n",
    "\n",
    "                # Forward pass with the updated model\n",
    "                updated_predictions = inner_model(task_data[0])\n",
    "                updated_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "                    task_data[1], updated_predictions\n",
    "                )\n",
    "\n",
    "            # Compute gradients for outer loop update\n",
    "            outer_gradients = outer_tape.gradient(\n",
    "                updated_loss, model.trainable_variables\n",
    "            )\n",
    "            task_gradients.append(outer_gradients)\n",
    "\n",
    "        # Filter out None gradients\n",
    "        filtered_task_gradients = [\n",
    "            [grad for grad in task_grad if grad is not None]\n",
    "            for task_grad in task_gradients\n",
    "        ]\n",
    "\n",
    "        # Compute average gradients across tasks\n",
    "        avg_gradients = [\n",
    "            tf.reduce_mean(grad_list, axis=0)\n",
    "            for grad_list in zip(*filtered_task_gradients)\n",
    "        ]\n",
    "\n",
    "        # Apply outer loop update to the model's variables\n",
    "        optimizer.apply_gradients(zip(avg_gradients, model.trainable_variables))\n",
    "\n",
    "        # Evaluate on the meta-test set\n",
    "        _, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "        # Store the meta-update step and accuracy\n",
    "        meta_updates.append(meta_update + 1)\n",
    "        accuracy_over_time.append(accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracy_over_time) / len(accuracy_over_time)\n",
    "    return model, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                      | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3029 - accuracy: 0.0721\n",
      "340/375 [==========================>...] - ETA: 0s - loss: 2.3029 - accuracy: 0.0713"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                      | 0/2 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m wt,model , dataset , i , \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(wts, models, dataset_parts , \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(clients))):\n\u001b[1;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mset_weights(wt)\n\u001b[0;32m----> 8\u001b[0m     model, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# history = model.fit(dataset[0], dataset[1], epochs=1,  verbose=1)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;66;03m# print(history.history[\"accuracy\"][0], history.history[\"loss\"][0])\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# accuracies[i ].append(history.history[\"accuracy\"][0])\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# losses[i].append(history.history[\"loss\"][0])\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "Cell \u001b[0;32mIn[72], line 62\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, x_train, y_train)\u001b[0m\n\u001b[1;32m     59\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(avg_gradients, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Evaluate on the meta-test set\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m _, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Store the meta-update step and accuracy\u001b[39;00m\n\u001b[1;32m     65\u001b[0m meta_updates\u001b[38;5;241m.\u001b[39mappend(meta_update \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/tf_env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/envs/tf_env/lib/python3.9/site-packages/keras/engine/training.py:1947\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1944\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1945\u001b[0m ):\n\u001b[1;32m   1946\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1947\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1948\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1949\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/conda/envs/tf_env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cwts = [encrypt_wt(model.get_weights() , i) for i , model in enumerate(models)]\n",
    "for e in tqdm(range(epochs)):\n",
    "    cwts = aggregate_wt(cwts)\n",
    "    wts = decrypt_weights(cwts)\n",
    "    cwts = []\n",
    "    for wt,model , dataset , i , in zip(wts, models, dataset_parts , range(len(clients))):\n",
    "        model.set_weights(wt)\n",
    "        model, accuracy = train_model(model, dataset[0], dataset[1])\n",
    "        # history = model.fit(dataset[0], dataset[1], epochs=1,  verbose=1)\n",
    "        # print(history.history[\"accuracy\"][0], history.history[\"loss\"][0])\n",
    "        # accuracies[i ].append(history.history[\"accuracy\"][0])\n",
    "        # losses[i].append(history.history[\"loss\"][0])\n",
    "        accuracies.append(accuracy)\n",
    "        print(\"accuracies\" , accuracy)\n",
    "        wtarray = model.get_weights()\n",
    "        cwts.append(encrypt_wt(wtarray , i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_range = range(1, epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, client in enumerate(clients):\n",
    "    plt.plot(\n",
    "        epochs_range,\n",
    "        accuracies[i],\n",
    "        label=f\"Client {client}\" if client != 0 else \"aggregate\",\n",
    "    )\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy for Each Client\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, client in enumerate(clients):\n",
    "    plt.plot(epochs_range, losses[i], label=f\"Client {client}\" if client != 0 else \"aggregate\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss for Each Client\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# for i, client in enumerate(clients):\n",
    "plt.plot(epochs_range, accuracies[0], label=f\"Client {client}\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy for Each Client\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = models[0]\n",
    "# Assuming you have a trained model named 'model'\n",
    "# and input data 'X_test' and corresponding labels 'y_test'\n",
    "\n",
    "# Select a sample image from the test set\n",
    "# Select a sample image from the test set\n",
    "sample_image = X_test[1]  # Adjust the index as needed\n",
    "sample_label = y_test[1]\n",
    "\n",
    "# Preprocess the sample image\n",
    "sample_image = sample_image[np.newaxis, ...]  # Add batch dimension\n",
    "\n",
    "# Initialize the model\n",
    "# model = model_init()\n",
    "\n",
    "# Create a model that outputs the activations of the first dense layer\n",
    "layer_name = \"dense_40\"  # Name of the first dense layer in your model\n",
    "activation_model = Model(\n",
    "    inputs=model.inputs, outputs=model.get_layer(layer_name).output\n",
    ")\n",
    "\n",
    "# Get the activations of the first dense layer\n",
    "activations = activation_model.predict(sample_image)\n",
    "\n",
    "# Plot the sample image and the activation map\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax1.imshow(sample_image[0], cmap=\"gray\")  # Assuming grayscale image\n",
    "ax1.set_title(\"Sample Image\")\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2.imshow(activations[0].reshape(2, 4), cmap=\"viridis\", interpolation=\"nearest\")\n",
    "ax2.set_title(\"Activation Map\")\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
