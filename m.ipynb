{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "\n",
    "# Create a TFF dataset from the training data\n",
    "mnist_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "mnist_train = mnist_train.repeat(2).shuffle(5000).batch(100)\n",
    "\n",
    "# Split the data for multiple clients\n",
    "num_clients = 3\n",
    "client_datasets = [\n",
    "    mnist_train.shard(num_shards=num_clients, index=i) for i in range(num_clients)\n",
    "]\n",
    "\n",
    "# Create a federated dataset\n",
    "federated_train_data = [\n",
    "    client_dataset.map(lambda x, y: (tf.reshape(x, [-1]), y))\n",
    "    for client_dataset in client_datasets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_MapDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.uint8, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(federated_train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model1.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "model2 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model3 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model3.compile(\n",
    "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "from_keras_model() missing 2 required positional arguments: 'loss' and 'input_spec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create a federated averaging algorithm\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m fed_avg \u001b[38;5;241m=\u001b[39m \u001b[43mtff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_weighted_fed_avg\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_optimizer_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_optimizer_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Build a federated learning process\u001b[39;00m\n\u001b[1;32m     38\u001b[0m federated_process \u001b[38;5;241m=\u001b[39m tff\u001b[38;5;241m.\u001b[39mlearning\u001b[38;5;241m.\u001b[39mbuild_federated_averaging_process(\n\u001b[1;32m     39\u001b[0m     model_fn, server_optimizer_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m: tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mSGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     40\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/he39/lib/python3.9/site-packages/tensorflow_federated/python/learning/algorithms/fed_avg.py:210\u001b[0m, in \u001b[0;36mbuild_weighted_fed_avg\u001b[0;34m(model_fn, client_optimizer_fn, server_optimizer_fn, client_weighting, model_distributor, model_aggregator, metrics_aggregator, use_experimental_simulation_loop)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_weights\u001b[38;5;241m.\u001b[39mModelWeights(\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m trainable_weights),\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28mtuple\u001b[39m(tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(w) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m non_trainable_weights),\n\u001b[1;32m    205\u001b[0m     )\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;129;43m@tensorflow_computation\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_computation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m--> 210\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43minitial_model_weights_fn\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pytype: disable=not-callable\u001b[39;49;00m\n\u001b[1;32m    212\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariableModel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/he39/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/computation/computation_wrapper.py:495\u001b[0m, in \u001b[0;36mComputationWrapper.__call__.<locals>.<lambda>\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    486\u001b[0m   \u001b[38;5;66;03m# If invoked as a decorator, and with an empty argument list as \"@xyz()\"\u001b[39;00m\n\u001b[1;32m    487\u001b[0m   \u001b[38;5;66;03m# applied to a function definition, expect the Python function being\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    492\u001b[0m   \u001b[38;5;66;03m# The tricky partial recursion is needed to inline the logic in the\u001b[39;00m\n\u001b[1;32m    493\u001b[0m   \u001b[38;5;66;03m# \"success\" case below.\u001b[39;00m\n\u001b[1;32m    494\u001b[0m   provided_types \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 495\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m fn: \u001b[43m_wrap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapper_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovided_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_infer_type_fn\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_function(args[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    499\u001b[0m   \u001b[38;5;66;03m# If the first argument on the list is a Python function, instance method,\u001b[39;00m\n\u001b[1;32m    500\u001b[0m   \u001b[38;5;66;03m# or a tf.function, this is the one that's being wrapped. This is the case\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m   \u001b[38;5;66;03m# Any of the following arguments, if present, are the arguments to the\u001b[39;00m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;66;03m# wrapper that are to be interpreted as the type specification.\u001b[39;00m\n\u001b[1;32m    506\u001b[0m   fn \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/he39/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/computation/computation_wrapper.py:236\u001b[0m, in \u001b[0;36m_wrap\u001b[0;34m(fn, wrapper_fn, parameter_types, infer_type_fn)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m   \u001b[38;5;66;03m# Either we have a concrete parameter type, or this is no-arg function.\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   parameter_type \u001b[38;5;241m=\u001b[39m _parameter_type(parameters, parameter_types)\n\u001b[0;32m--> 236\u001b[0m   wrapped_fn \u001b[38;5;241m=\u001b[39m \u001b[43m_wrap_concrete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapper_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# When applying a decorator, the __doc__ attribute with the documentation\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# in triple-quotes is not automatically transferred from the function on\u001b[39;00m\n\u001b[1;32m    240\u001b[0m wrapped_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fn, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__doc__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/he39/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/computation/computation_wrapper.py:98\u001b[0m, in \u001b[0;36m_wrap_concrete\u001b[0;34m(fn, wrapper_fn, parameter_type)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m   name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m concrete_fn \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m py_typecheck\u001b[38;5;241m.\u001b[39mcheck_type(\n\u001b[1;32m    100\u001b[0m     concrete_fn,\n\u001b[1;32m    101\u001b[0m     computation_impl\u001b[38;5;241m.\u001b[39mConcreteComputation,\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue returned by the wrapper\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    104\u001b[0m result_parameter_type \u001b[38;5;241m=\u001b[39m concrete_fn\u001b[38;5;241m.\u001b[39mtype_signature\u001b[38;5;241m.\u001b[39mparameter\n",
      "File \u001b[0;32m~/.conda/envs/he39/lib/python3.9/site-packages/tensorflow_federated/python/core/environments/tensorflow_frontend/tensorflow_computation.py:67\u001b[0m, in \u001b[0;36m_tf_wrapper_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     64\u001b[0m context_stack \u001b[38;5;241m=\u001b[39m context_stack_impl\u001b[38;5;241m.\u001b[39mcontext_stack\n\u001b[1;32m     65\u001b[0m layout_map \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayout_map\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     66\u001b[0m comp_pb, extra_type_spec \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 67\u001b[0m     \u001b[43mtensorflow_serialization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserialize_py_fn_as_tf_computation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameter_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext_stack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_map\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m )\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m computation_impl\u001b[38;5;241m.\u001b[39mConcreteComputation(\n\u001b[1;32m     72\u001b[0m     comp_pb,\n\u001b[1;32m     73\u001b[0m     context_stack,\n\u001b[1;32m     74\u001b[0m     extra_type_spec,\n\u001b[1;32m     75\u001b[0m     _transform_result,\n\u001b[1;32m     76\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/he39/lib/python3.9/site-packages/tensorflow_federated/python/core/environments/tensorflow_frontend/tensorflow_serialization.py:113\u001b[0m, in \u001b[0;36mserialize_py_fn_as_tf_computation\u001b[0;34m(fn, parameter_type, context_stack, layout_map)\u001b[0m\n\u001b[1;32m    111\u001b[0m   result \u001b[38;5;241m=\u001b[39m fn(parameter_value)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m computation_wrapper\u001b[38;5;241m.\u001b[39mComputationReturnedNoneError(fn)\n",
      "File \u001b[0;32m~/.conda/envs/he39/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/computation/function_utils.py:446\u001b[0m, in \u001b[0;36mwrap_as_zero_or_one_arg_callable.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parameter_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    443\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_signature_compatible_with_types(signature):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;66;03m# Deliberate wrapping to isolate the caller from `fn`, e.g., to prevent\u001b[39;00m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# the caller from mistakenly specifying args that match fn's defaults.\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=unnecessary-lambda\u001b[39;00m\n\u001b[1;32m    447\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of the supplied function cannot be interpreted as \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    450\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma body of a no-parameter computation.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(signature)\n\u001b[1;32m    451\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/he39/lib/python3.9/site-packages/tensorflow_federated/python/learning/algorithms/fed_avg.py:211\u001b[0m, in \u001b[0;36mbuild_weighted_fed_avg.<locals>.initial_model_weights_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;129m@tensorflow_computation\u001b[39m\u001b[38;5;241m.\u001b[39mtf_computation()\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minitial_model_weights_fn\u001b[39m():\n\u001b[0;32m--> 211\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pytype: disable=not-callable\u001b[39;00m\n\u001b[1;32m    212\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, variable\u001b[38;5;241m.\u001b[39mVariableModel):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhen `model_fn` is a callable, it return instances of\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m tff.learning.models.VariableModel. Instead callable returned\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    217\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m, in \u001b[0;36mmodel_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_fn\u001b[39m():\n\u001b[1;32m      6\u001b[0m     keras_model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      7\u001b[0m         [\n\u001b[1;32m      8\u001b[0m             tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mFlatten(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m         ]\n\u001b[1;32m     12\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_keras_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeras_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: from_keras_model() missing 2 required positional arguments: 'loss' and 'input_spec'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "\n",
    "def model_fn():\n",
    "    keras_model = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    return tff.learning.models.from_keras_model(keras_model)\n",
    "\n",
    "\n",
    "def client_fn(model, dataset):\n",
    "    model.compile(\n",
    "        optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    model.fit(dataset, epochs=5)\n",
    "    return model.get_weights()\n",
    "\n",
    "\n",
    "def server_fn(model_weights):\n",
    "    model = model_fn()\n",
    "    model.set_weights(model_weights)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create a federated averaging algorithm\n",
    "fed_avg = tff.learning.algorithms.build_weighted_fed_avg(\n",
    "    model_fn,\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),\n",
    ")\n",
    "\n",
    "# Build a federated learning process\n",
    "federated_process = tff.learning.build_federated_averaging_process(\n",
    "    model_fn, server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)\n",
    ")\n",
    "\n",
    "# Train each model on a different client dataset\n",
    "for i, client_dataset in enumerate(federated_train_data):\n",
    "    print(f\"Training model {i+1} on client dataset {i+1}\")\n",
    "    model_weights = client_fn(eval(f\"model{i+1}\"), client_dataset)\n",
    "    server_model = server_fn(model_weights)\n",
    "    eval(f\"model{i+1}\").set_weights(server_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "he38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
