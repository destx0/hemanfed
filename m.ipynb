{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.primitives.asymmetric import dh\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [0 , 1, 2]\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "x_train_all = x_train_all.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(\n",
    "                32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# # Define the MAML model\n",
    "# class MAML(tf.keras.Model):\n",
    "#     def __init__(self, model):\n",
    "#         super(MAML, self).__init__()\n",
    "#         self.model = model\n",
    "\n",
    "#     def train_step(self, data):\n",
    "#         x, y = data\n",
    "#         x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "#         y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             y_pred = self.model(x)\n",
    "#             loss = self.compiled_loss(y, y_pred)\n",
    "#         gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "#         self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "#         self.compiled_metrics.update_state(y, y_pred)\n",
    "#         return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "#     def test_step(self, data):\n",
    "#         x, y = data\n",
    "#         x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "#         y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "#         y_pred = self.model(x)\n",
    "#         self.compiled_loss(y, y_pred)\n",
    "#         self.compiled_metrics.update_state(y, y_pred)\n",
    "#         return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "class MAML(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(MAML, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = tf.reshape(inputs, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "        return self.model(x)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"model\": self.model.get_config()}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        model = tf.keras.models.Model.from_config(config[\"model\"])\n",
    "        return cls(model)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "        y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "        y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "        y_pred = self.model(x)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "# Define the meta-learning parameters\n",
    "num_meta_updates = 10\n",
    "num_inner_updates = 5\n",
    "meta_batch_size = 32\n",
    "inner_batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# assume X is your feature data and y is your target data\n",
    "X_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_train_all, y_train_all, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# split data into n parts\n",
    "n_parts = len(clients)\n",
    "part_size = len(X_train) // n_parts\n",
    "dataset_parts = []\n",
    "for i in range(n_parts):\n",
    "    start = i * part_size\n",
    "    end = (i + 1) * part_size\n",
    "    X_part = X_train[start:end]\n",
    "    y_part = y_train[start:end]\n",
    "    dataset_parts.append((X_part, y_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 16000)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = dataset_parts\n",
    "x , y = a[2]\n",
    "len(x) , len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    model = MAML(create_model())\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for _ in range(len(clients)):\n",
    "    models.append(model_init())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Pyfhel import Pyfhel\n",
    "\n",
    "HE = Pyfhel() \n",
    "ckks_params = {\n",
    "    \"scheme\": \"CKKS\", \n",
    "    \"n\": 2**14,  # Polynomial modulus degree. For CKKS, n/2 values can be\n",
    "    \"scale\": 2**30,  # All the encodings will use it for float->fixed point\n",
    "    \"qi_sizes\": [60, 30, 30, 30, 60],  # Number of bits of each prime in the chain.\n",
    "}\n",
    "HE.contextGen(**ckks_params)  # Generate context for ckks scheme\n",
    "HE.keyGen()  # Key Generation: generates a pair of public/secret keys\n",
    "HE.rotateKeyGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 3, 1, 32), (32,), (3, 3, 32, 64), (64,), (3, 3, 64, 64), (64,), (576, 64), (64,), (64, 10), (10,)]\n"
     ]
    }
   ],
   "source": [
    "shapedims = [l.shape for l in models[0].get_weights()]\n",
    "print(shapedims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diffie_hellman_parameters():\n",
    "    parameters = dh.generate_parameters(generator=2, key_size=512)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def generate_diffie_hellman_keys(parameters):\n",
    "    private_key = parameters.generate_private_key()\n",
    "    public_key = private_key.public_key()\n",
    "    return private_key, public_key\n",
    "\n",
    "\n",
    "def derive_key(private_key, peer_public_key):\n",
    "    shared_key = private_key.exchange(peer_public_key)\n",
    "    derived_key = HKDF(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32,\n",
    "        salt=None,\n",
    "        info=b\"handshake data\",\n",
    "    ).derive(shared_key)\n",
    "    return derived_key\n",
    "\n",
    "\n",
    "def encrypt_message_AES(key, message):\n",
    "    serialized_obj = pickle.dumps(message)\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    encryptor = cipher.encryptor()\n",
    "    padded_obj = serialized_obj + b\" \" * (16 - len(serialized_obj) % 16)\n",
    "    ciphertext = encryptor.update(padded_obj) + encryptor.finalize()\n",
    "    return ciphertext\n",
    "\n",
    "\n",
    "def decrypt_message_AES(key, ciphertext):\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    decryptor = cipher.decryptor()\n",
    "    padded_obj = decryptor.update(ciphertext) + decryptor.finalize()\n",
    "    serialized_obj = padded_obj.rstrip(b\" \")\n",
    "    obj = pickle.loads(serialized_obj)\n",
    "    return obj\n",
    "\n",
    "\n",
    "def setup_AES():\n",
    "    num_clients = len(clients)\n",
    "    parameters = generate_diffie_hellman_parameters()\n",
    "    server_private_key, server_public_key = generate_diffie_hellman_keys(parameters)\n",
    "    client_keys = [generate_diffie_hellman_keys(parameters) for _ in range(num_clients)]\n",
    "    shared_keys = [\n",
    "        derive_key(server_private_key, client_public_key)\n",
    "        for _, client_public_key in client_keys\n",
    "    ]\n",
    "    client_shared_keys = [\n",
    "        derive_key(client_private_key, server_public_key)\n",
    "        for client_private_key, _ in client_keys\n",
    "    ]\n",
    "\n",
    "    return client_keys, shared_keys , client_shared_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_keys, shared_keys, client_shared_keys = setup_AES()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_wt(wtarray , i):\n",
    "    cwt = []\n",
    "    for layer in wtarray:\n",
    "        flat_array = layer.astype(np.float64).flatten()\n",
    "\n",
    "        chunks = np.array_split(flat_array, (len(flat_array) + 2**10 - 1) // 2**10)\n",
    "        clayer = []\n",
    "        for chunk in chunks:\n",
    "            ptxt = HE.encodeFrac(chunk)\n",
    "            ctxt = HE.encryptPtxt(ptxt)\n",
    "            clayer.append(ctxt)\n",
    "        cwt.append(clayer.copy())\n",
    "    ciphertext = encrypt_message_AES(client_shared_keys[i], cwt)\n",
    "    return ciphertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_wt(encypted_cwts):\n",
    "    cwts = []\n",
    "    for i , ecwt in enumerate(encypted_cwts):\n",
    "        cwts.append(decrypt_message_AES(shared_keys[i], ecwt))\n",
    "    resmodel = []\n",
    "    for j in range(len(cwts[0])):  # for layers\n",
    "        layer = []\n",
    "        for k in range(len(cwts[0][j])):  # for chunks\n",
    "            tmp = cwts[0][j][k].copy()\n",
    "            for i in range(1, len(cwts)):  # for clients\n",
    "                tmp = tmp + cwts[i][j][k]\n",
    "            tmp = tmp / len(cwts)\n",
    "            layer.append(tmp)\n",
    "        resmodel.append(layer)\n",
    "\n",
    "    res = [resmodel.copy() for _ in range(len(clients))]\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_weights(res):\n",
    "    decrypted_weights = []\n",
    "    for client_weights, model in zip(res, models):\n",
    "        decrypted_client_weights = []\n",
    "        wtarray = model.get_weights()\n",
    "        for layer_weights, layer in zip(client_weights, wtarray):\n",
    "            decrypted_layer_weights = []\n",
    "            flat_array = layer.astype(np.float64).flatten()\n",
    "            chunks = np.array_split(flat_array, (len(flat_array) + 2**10 - 1) // 2**10)\n",
    "            for chunk, encrypted_chunk in zip(chunks, layer_weights):\n",
    "                decrypted_chunk = HE.decryptFrac(encrypted_chunk)\n",
    "                original_chunk_size = len(chunk)\n",
    "                decrypted_chunk = decrypted_chunk[:original_chunk_size]\n",
    "                decrypted_layer_weights.append(decrypted_chunk)\n",
    "            decrypted_layer_weights = np.concatenate(decrypted_layer_weights, axis=0)\n",
    "            decrypted_layer_weights = decrypted_layer_weights.reshape(layer.shape)\n",
    "            decrypted_client_weights.append(decrypted_layer_weights)\n",
    "        decrypted_weights.append(decrypted_client_weights)\n",
    "    return decrypted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [[] for _ in range(len(clients))]\n",
    "losses = [[] for _ in range(len(clients))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, x_train, y_train):\n",
    "#     meta_updates = []\n",
    "#     accuracy_over_time = []\n",
    "#     for meta_update in range(num_meta_updates):\n",
    "#         # Sample a meta-batch of tasks\n",
    "#         meta_batch = tf.random.shuffle(tf.range(len(x_train)))[:meta_batch_size]\n",
    "\n",
    "#         # Inner loop updates for each task\n",
    "#         for task in meta_batch:\n",
    "#             task_data = (\n",
    "#                 x_train[task : task + inner_batch_size],\n",
    "#                 y_train[task : task + inner_batch_size],\n",
    "#             )\n",
    "            \n",
    "#             for inner_update in range(num_inner_updates):\n",
    "#                 model.train_step(task_data)\n",
    "\n",
    "#         # Evaluate on the meta-test set\n",
    "#         _, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "#         # Store the meta-update step and accuracy\n",
    "#         meta_updates.append(meta_update + 1)\n",
    "#         accuracy_over_time.append(accuracy)\n",
    "#     avg_accuracy = sum(accuracy_over_time) / len(accuracy_over_time)\n",
    "#     return model , avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_batch_size = 32  # Number of tasks per meta-update\n",
    "inner_batch_size = 5  # Number of examples per task\n",
    "num_inner_updates = 5  # Number of inner loop updates per task\n",
    "num_meta_updates = 100\n",
    "optimizer = tf.keras.optimizers.legacy.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train):\n",
    "    meta_updates = []\n",
    "    accuracy_over_time = []\n",
    "    for meta_update in range(num_meta_updates):\n",
    "        # Sample a meta-batch of tasks\n",
    "        meta_batch = tf.random.shuffle(tf.range(len(x_train)))[:meta_batch_size]\n",
    "\n",
    "        # Inner loop updates for each task\n",
    "        task_gradients = []\n",
    "        for task in meta_batch:\n",
    "            task_data = (\n",
    "                x_train[task : task + inner_batch_size],\n",
    "                y_train[task : task + inner_batch_size],\n",
    "            )\n",
    "\n",
    "            with tf.GradientTape() as outer_tape:\n",
    "                with tf.GradientTape() as inner_tape:\n",
    "                    # Forward pass on the task-specific data\n",
    "                    predictions = model(task_data[0])\n",
    "                    loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "                        task_data[1], predictions\n",
    "                    )\n",
    "\n",
    "                # Compute gradients for inner loop update\n",
    "                inner_gradients = inner_tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "                # Apply inner loop update to the model's variables\n",
    "                inner_model = MAML(create_model())\n",
    "                inner_model.set_weights(model.get_weights())\n",
    "                optimizer.apply_gradients(\n",
    "                    zip(inner_gradients, inner_model.trainable_variables)\n",
    "                )\n",
    "\n",
    "                # Forward pass with the updated model\n",
    "                updated_predictions = inner_model(task_data[0])\n",
    "                updated_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "                    task_data[1], updated_predictions\n",
    "                )\n",
    "\n",
    "            # Compute gradients for outer loop update\n",
    "            outer_gradients = outer_tape.gradient(\n",
    "                updated_loss, model.trainable_variables\n",
    "            )\n",
    "            task_gradients.append(outer_gradients)\n",
    "\n",
    "        # Filter out None gradients\n",
    "        filtered_task_gradients = [\n",
    "            [grad for grad in task_grad if grad is not None]\n",
    "            for task_grad in task_gradients\n",
    "        ]\n",
    "\n",
    "        # Compute average gradients across tasks\n",
    "        avg_gradients = [\n",
    "            tf.reduce_mean(grad_list, axis=0)\n",
    "            for grad_list in zip(*filtered_task_gradients)\n",
    "        ]\n",
    "\n",
    "        # Apply outer loop update to the model's variables\n",
    "        optimizer.apply_gradients(zip(avg_gradients, model.trainable_variables))\n",
    "\n",
    "        # Evaluate on the meta-test set\n",
    "        _, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "        # Store the meta-update step and accuracy\n",
    "        meta_updates.append(meta_update + 1)\n",
    "        accuracy_over_time.append(accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracy_over_time) / len(accuracy_over_time)\n",
    "    return model, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "accuracies 0.06891666352748871\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "accuracies 0.06891666352748871\n",
      "375/375 [==============================] - 3s 6ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 2s 5ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0689\n",
      "accuracies 0.06891666352748871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|         | 1/20 [26:15<8:18:53, 1575.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 4ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "accuracies 0.06883333623409271\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "accuracies 0.06883333623409271\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 2s 4ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0688\n",
      "accuracies 0.06883333623409271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 2/20 [45:33<6:38:56, 1329.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "accuracies 0.06866666674613953\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "accuracies 0.06866666674613953\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "accuracies 0.06866666674613953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|        | 3/20 [1:02:07<5:33:17, 1176.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "accuracies 0.06866666674613953\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "accuracies 0.06866666674613953\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 1ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n",
      "375/375 [==============================] - 1s 2ms/step - loss: 2.3026 - accuracy: 0.0687\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "cwts = [encrypt_wt(model.get_weights() , i) for i , model in enumerate(models)]\n",
    "for e in tqdm(range(epochs)):\n",
    "    cwts = aggregate_wt(cwts)\n",
    "    wts = decrypt_weights(cwts)\n",
    "    cwts = []\n",
    "    for wt,model , dataset , i , in zip(wts, models, dataset_parts , range(len(clients))):\n",
    "        model.set_weights(wt)\n",
    "        model, accuracy = train_model(model, dataset[0], dataset[1])\n",
    "        # history = model.fit(dataset[0], dataset[1], epochs=1,  verbose=1)\n",
    "        # print(history.history[\"accuracy\"][0], history.history[\"loss\"][0])\n",
    "        # accuracies[i ].append(history.history[\"accuracy\"][0])\n",
    "        # losses[i].append(history.history[\"loss\"][0])\n",
    "        accuracies.append(accuracy)\n",
    "        print(\"accuracies\" , accuracy)\n",
    "        wtarray = model.get_weights()\n",
    "        cwts.append(encrypt_wt(wtarray , i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs_range = range(1, epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, client in enumerate(clients):\n",
    "    plt.plot(\n",
    "        epochs_range,\n",
    "        accuracies[i],\n",
    "        label=f\"Client {client}\" if client != 0 else \"aggregate\",\n",
    "    )\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy for Each Client\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i, client in enumerate(clients):\n",
    "    plt.plot(epochs_range, losses[i], label=f\"Client {client}\" if client != 0 else \"aggregate\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss for Each Client\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_range = range(1, epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# for i, client in enumerate(clients):\n",
    "plt.plot(epochs_range, accuracies[0], label=f\"Client {client}\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy for Each Client\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = models[0]\n",
    "# Assuming you have a trained model named 'model'\n",
    "# and input data 'X_test' and corresponding labels 'y_test'\n",
    "\n",
    "# Select a sample image from the test set\n",
    "# Select a sample image from the test set\n",
    "sample_image = X_test[1]  # Adjust the index as needed\n",
    "sample_label = y_test[1]\n",
    "\n",
    "# Preprocess the sample image\n",
    "sample_image = sample_image[np.newaxis, ...]  # Add batch dimension\n",
    "\n",
    "# Initialize the model\n",
    "# model = model_init()\n",
    "\n",
    "# Create a model that outputs the activations of the first dense layer\n",
    "layer_name = \"dense_40\"  # Name of the first dense layer in your model\n",
    "activation_model = Model(\n",
    "    inputs=model.inputs, outputs=model.get_layer(layer_name).output\n",
    ")\n",
    "\n",
    "# Get the activations of the first dense layer\n",
    "activations = activation_model.predict(sample_image)\n",
    "\n",
    "# Plot the sample image and the activation map\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax1.imshow(sample_image[0], cmap=\"gray\")  # Assuming grayscale image\n",
    "ax1.set_title(\"Sample Image\")\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "ax2.imshow(activations[0].reshape(2, 4), cmap=\"viridis\", interpolation=\"nearest\")\n",
    "ax2.set_title(\"Activation Map\")\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "he38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
