{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs-lab-12/.anaconda3/envs/he39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 104] Connection reset by peer>\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error downloading train-images-idx3-ubyte.gz",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 204\u001b[0m\n\u001b[1;32m    200\u001b[0m n_clients \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    201\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[1;32m    202\u001b[0m     [transforms\u001b[38;5;241m.\u001b[39mToTensor(), transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.1307\u001b[39m,), (\u001b[38;5;241m0.3081\u001b[39m,))]\n\u001b[1;32m    203\u001b[0m )\n\u001b[0;32m--> 204\u001b[0m full_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m train_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(full_dataset))\n\u001b[1;32m    208\u001b[0m test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(full_dataset) \u001b[38;5;241m-\u001b[39m train_size\n",
      "File \u001b[0;32m~/.anaconda3/envs/he39/lib/python3.9/site-packages/torchvision/datasets/mnist.py:100\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.anaconda3/envs/he39/lib/python3.9/site-packages/torchvision/datasets/mnist.py:196\u001b[0m, in \u001b[0;36mMNIST.download\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError downloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error downloading train-images-idx3-ubyte.gz"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import learn2learn as l2l\n",
    "import copy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group[\"lr\"]\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def split_dataset(dataset, n):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    split_sizes = dataset_size // n\n",
    "    subsets = []\n",
    "    for i in range(n):\n",
    "        subset_indices = indices[i * split_sizes : (i + 1) * split_sizes]\n",
    "        subsets.append(Subset(dataset, subset_indices))\n",
    "    return subsetsimport torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import learn2learn as l2l\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group[\"lr\"]\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def split_dataset(dataset, n):\n",
    "    dataset_size = len(dataset)\n",
    "    indices = list(range(dataset_size))\n",
    "    np.random.shuffle(indices)\n",
    "    split_sizes = dataset_size // n\n",
    "    subsets = []\n",
    "    for i in range(n):\n",
    "        subset_indices = indices[i * split_sizes : (i + 1) * split_sizes]\n",
    "        subsets.append(Subset(dataset, subset_indices))\n",
    "    return subsets\n",
    "\n",
    "\n",
    "def federated_fit(\n",
    "    epochs,\n",
    "    model,\n",
    "    client_loaders,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    adaptation_steps=5,\n",
    "    inner_lr=0.01,\n",
    "):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_acc = []\n",
    "    train_acc = []\n",
    "    lrs = []\n",
    "    min_loss = np.inf\n",
    "    decrease = 1\n",
    "    not_improve = 0\n",
    "\n",
    "    model.to(device)\n",
    "    fit_time = time.time()\n",
    "    for e in range(epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0\n",
    "        overall_accuracy = 0\n",
    "\n",
    "        model.train()\n",
    "        client_accuracies = []\n",
    "        for client_idx, client_loader in enumerate(client_loaders):\n",
    "            client_accuracy = 0\n",
    "            for i, data in enumerate(tqdm(client_loader)):\n",
    "                images, labels = data\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                learner = l2l.algorithms.MAML(model, lr=inner_lr).clone()\n",
    "\n",
    "                for step in range(adaptation_steps):\n",
    "                    output = learner(images)\n",
    "                    loss = criterion(output, labels)\n",
    "                    learner.adapt(loss)\n",
    "\n",
    "                output = learner(images)\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                lrs.append(get_lr(optimizer))\n",
    "                scheduler.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                client_accuracy += (\n",
    "                    (output.argmax(dim=1) == labels).float().mean().item()\n",
    "                )\n",
    "\n",
    "            client_accuracy /= len(client_loader)\n",
    "            client_accuracies.append(client_accuracy)\n",
    "            print(\n",
    "                f\"Epoch {e + 1}, Client {client_idx + 1} Accuracy: {client_accuracy:.4f}\"\n",
    "            )\n",
    "\n",
    "        overall_accuracy = sum(client_accuracies) / len(client_accuracies)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(tqdm(val_loader)):\n",
    "                images, labels = data\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                output = model(images)\n",
    "                test_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "                loss = criterion(output, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        train_losses.append(\n",
    "            running_loss / sum(len(loader.dataset) for loader in client_loaders)\n",
    "        )\n",
    "        val_losses.append(test_loss / len(val_loader))\n",
    "        val_accuracy = test_accuracy / len(val_loader)\n",
    "        val_acc.append(val_accuracy)\n",
    "\n",
    "        if min_loss > (test_loss / len(val_loader)):\n",
    "            print(\n",
    "                \"Loss Decreasing.. {:.3f} >> {:.3f} \".format(\n",
    "                    min_loss, (test_loss / len(val_loader))\n",
    "                )\n",
    "            )\n",
    "            min_loss = test_loss / len(val_loader)\n",
    "            decrease += 1\n",
    "            if decrease % 5 == 0:\n",
    "                print(\"saving model...\")\n",
    "                torch.save(\n",
    "                    model,\n",
    "                    \"Federated-MAML-Model-Accuracy-{:.3f}.pt\".format(val_accuracy),\n",
    "                )\n",
    "\n",
    "        if (test_loss / len(val_loader)) > min_loss:\n",
    "            not_improve += 1\n",
    "            min_loss = test_loss / len(val_loader)\n",
    "            print(f\"Loss Not Decrease for {not_improve} time\")\n",
    "            if not_improve == 7:\n",
    "                print(\"Loss not decrease for 7 times, Stop Training\")\n",
    "                break\n",
    "\n",
    "        train_acc.append(overall_accuracy)\n",
    "        print(\n",
    "            \"Epoch:{}/{}..\".format(e + 1, epochs),\n",
    "            \"Train Loss: {:.3f}..\".format(\n",
    "                running_loss / sum(len(loader.dataset) for loader in client_loaders)\n",
    "            ),\n",
    "            \"Val Loss: {:.3f}..\".format(test_loss / len(val_loader)),\n",
    "            \"Train Acc:{:.3f}..\".format(overall_accuracy),\n",
    "            \"Val Acc:{:.3f}..\".format(val_accuracy),\n",
    "            \"Time: {:.2f}m\".format((time.time() - since) / 60),\n",
    "        )\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": train_losses,\n",
    "        \"val_loss\": val_losses,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"lrs\": lrs,\n",
    "    }\n",
    "    print(\"Total time: {:.2f} m\".format((time.time() - fit_time) / 60))\n",
    "    return history\n",
    "\n",
    "\n",
    "n_clients = 3\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "full_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "client_datasets = split_dataset(train_dataset, n_clients)\n",
    "client_loaders = [\n",
    "    DataLoader(dataset, batch_size=64, shuffle=True) for dataset in client_datasets\n",
    "]\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "model = CNN()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=0.001, weight_decay=1e-5\n",
    ")  # Added weight decay\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "history = federated_fit(\n",
    "    epochs=1,\n",
    "    model=model,\n",
    "    client_loaders=client_loaders,\n",
    "    val_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    adaptation_steps=5,\n",
    "    inner_lr=0.01,\n",
    ")\n",
    "\n",
    "\n",
    "def average_weights(models):\n",
    "    avg_model = copy.deepcopy(models[0])\n",
    "    for key in avg_model.state_dict().keys():\n",
    "        avg_model.state_dict()[key] = torch.mean(\n",
    "            torch.stack([model.state_dict()[key] for model in models]), dim=0\n",
    "        )\n",
    "    return avg_model\n",
    "\n",
    "\n",
    "def federated_fit(\n",
    "    epochs,\n",
    "    model,\n",
    "    client_loaders,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    adaptation_steps=5,\n",
    "    inner_lr=0.01,\n",
    "):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_acc = []\n",
    "    train_acc = []\n",
    "    lrs = []\n",
    "    min_loss = np.inf\n",
    "    decrease = 1\n",
    "    not_improve = 0\n",
    "\n",
    "    model.to(device)\n",
    "    fit_time = time.time()\n",
    "    for e in range(epochs):\n",
    "        since = time.time()\n",
    "        running_loss = 0\n",
    "        overall_accuracy = 0\n",
    "\n",
    "        model.train()\n",
    "        client_accuracies = []\n",
    "        client_models = []\n",
    "        for client_idx, client_loader in enumerate(client_loaders):\n",
    "            client_model = copy.deepcopy(model)\n",
    "            client_model.to(device)\n",
    "            client_optimizer = optim.Adam(\n",
    "                client_model.parameters(), lr=inner_lr, weight_decay=1e-5\n",
    "            )\n",
    "            client_accuracy = 0\n",
    "            for i, data in enumerate(tqdm(client_loader)):\n",
    "                images, labels = data\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                client_optimizer.zero_grad()\n",
    "\n",
    "                learner = l2l.algorithms.MAML(client_model, lr=inner_lr).clone()\n",
    "\n",
    "                for step in range(adaptation_steps):\n",
    "                    output = learner(images)\n",
    "                    loss = criterion(output, labels)\n",
    "                    learner.adapt(loss)\n",
    "\n",
    "                output = learner(images)\n",
    "                loss = criterion(output, labels)\n",
    "                loss.backward()\n",
    "                client_optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                client_accuracy += (\n",
    "                    (output.argmax(dim=1) == labels).float().mean().item()\n",
    "                )\n",
    "\n",
    "            client_accuracy /= len(client_loader)\n",
    "            client_accuracies.append(client_accuracy)\n",
    "            client_models.append(client_model)\n",
    "            print(\n",
    "                f\"Epoch {e + 1}, Client {client_idx + 1} Accuracy: {client_accuracy:.4f}\"\n",
    "            )\n",
    "\n",
    "        # Aggregate the client models' weights\n",
    "        model = average_weights(client_models)\n",
    "\n",
    "        overall_accuracy = sum(client_accuracies) / len(client_accuracies)\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(tqdm(val_loader)):\n",
    "                images, labels = data\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                output = model(images)\n",
    "                test_accuracy += (output.argmax(dim=1) == labels).float().mean().item()\n",
    "                loss = criterion(output, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        train_losses.append(\n",
    "            running_loss / sum(len(loader.dataset) for loader in client_loaders)\n",
    "        )\n",
    "        val_losses.append(test_loss / len(val_loader))\n",
    "        val_accuracy = test_accuracy / len(val_loader)\n",
    "        val_acc.append(val_accuracy)\n",
    "\n",
    "        if min_loss > (test_loss / len(val_loader)):\n",
    "            print(\n",
    "                \"Loss Decreasing.. {:.3f} >> {:.3f}\".format(\n",
    "                    min_loss, (test_loss / len(val_loader))\n",
    "                )\n",
    "            )\n",
    "            min_loss = test_loss / len(val_loader)\n",
    "            decrease += 1\n",
    "            if decrease % 5 == 0:\n",
    "                print(\"saving model...\")\n",
    "                torch.save(\n",
    "                    model,\n",
    "                    \"Federated-MAML-Model-Accuracy-{:.3f}.pt\".format(val_accuracy),\n",
    "                )\n",
    "\n",
    "        if (test_loss / len(val_loader)) > min_loss:\n",
    "            not_improve += 1\n",
    "            min_loss = test_loss / len(val_loader)\n",
    "            print(f\"Loss Not Decrease for {not_improve} time\")\n",
    "            if not_improve == 7:\n",
    "                print(\"Loss not decrease for 7 times, Stop Training\")\n",
    "                break\n",
    "\n",
    "        train_acc.append(overall_accuracy)\n",
    "        print(\n",
    "            \"Epoch:{}/{}..\".format(e + 1, epochs),\n",
    "            \"Train Loss: {:.3f}..\".format(\n",
    "                running_loss / sum(len(loader.dataset) for loader in client_loaders)\n",
    "            ),\n",
    "            \"Val Loss: {:.3f}..\".format(test_loss / len(val_loader)),\n",
    "            \"Train Acc:{:.3f}..\".format(overall_accuracy),\n",
    "            \"Val Acc:{:.3f}..\".format(val_accuracy),\n",
    "            \"Time: {:.2f}m\".format((time.time() - since) / 60),\n",
    "        )\n",
    "\n",
    "    history = {\n",
    "        \"train_loss\": train_losses,\n",
    "        \"val_loss\": val_losses,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"lrs\": lrs,\n",
    "    }\n",
    "    print(\"Total time: {:.2f} m\".format((time.time() - fit_time) / 60))\n",
    "    return history\n",
    "\n",
    "\n",
    "n_clients = 3\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "full_dataset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "client_datasets = split_dataset(train_dataset, n_clients)\n",
    "client_loaders = [\n",
    "    DataLoader(dataset, batch_size=64, shuffle=True) for dataset in client_datasets\n",
    "]\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "model = CNN()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=0.001, weight_decay=1e-5\n",
    ")  # Added weight decay\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "history = federated_fit(\n",
    "    epochs=10,\n",
    "    model=model,\n",
    "    client_loaders=client_loaders,\n",
    "    val_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    adaptation_steps=5,\n",
    "    inner_lr=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs-lab-12/.anaconda3/envs/he39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle DB :train, b:10000, 5-way, 1-shot, 15-query, resize:84\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mini-imagenet/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 322\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest acc:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accs)\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 267\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    252\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    253\u001b[0m maml \u001b[38;5;241m=\u001b[39m Meta(\n\u001b[1;32m    254\u001b[0m     n_way,\n\u001b[1;32m    255\u001b[0m     k_spt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m     imgsz,\n\u001b[1;32m    265\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 267\u001b[0m mini \u001b[38;5;241m=\u001b[39m \u001b[43mMiniImagenet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmini-imagenet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_way\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_way\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_spt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk_qry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatchsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimgsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m mini_test \u001b[38;5;241m=\u001b[39m MiniImagenet(\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmini-imagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    278\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m     resize\u001b[38;5;241m=\u001b[39mimgsz,\n\u001b[1;32m    284\u001b[0m )\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_count \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10000\u001b[39m):\n",
      "File \u001b[0;32m~/space/dest/hemanfed/MiniImagenet.py:65\u001b[0m, in \u001b[0;36mMiniImagenet.__init__\u001b[0;34m(self, root, mode, batchsz, n_way, k_shot, k_query, resize, startidx)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\u001b[38;5;28;01mlambda\u001b[39;00m x: Image\u001b[38;5;241m.\u001b[39mopen(x)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     59\u001b[0m                                          transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize)),\n\u001b[1;32m     60\u001b[0m                                          transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     61\u001b[0m                                          transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m), (\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m))\n\u001b[1;32m     62\u001b[0m                                          ])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# image path\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m csvdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadCSV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# csv path\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg2label \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/space/dest/hemanfed/MiniImagenet.py:82\u001b[0m, in \u001b[0;36mMiniImagenet.loadCSV\u001b[0;34m(self, csvf)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03mreturn a dict saving the information of csv\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m:param splitFile: csv file name\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;124;03m:return: {label:[file1, file2 ...]}\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m dictLabels \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcsvf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[1;32m     83\u001b[0m     csvreader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(csvfile, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mnext\u001b[39m(csvreader, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# skip (filename, label)\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'mini-imagenet/train.csv'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from MiniImagenet import MiniImagenet\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Learner(nn.Module):\n",
    "    def __init__(self, config, imgc, imgsz):\n",
    "        super(Learner, self).__init__()\n",
    "        self.config = config\n",
    "        self.vars = nn.ParameterList()\n",
    "        self.vars_bn = nn.ParameterList()\n",
    "\n",
    "        for i, (name, param) in enumerate(self.config):\n",
    "            if name == \"conv2d\":\n",
    "                w = nn.Parameter(torch.ones(*param[:4]))\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "            elif name == \"linear\":\n",
    "                w = nn.Parameter(torch.ones(*param))\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "            elif name == \"bn\":\n",
    "                w = nn.Parameter(torch.ones(param[0]))\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "                running_mean = nn.Parameter(torch.zeros(param[0]), requires_grad=False)\n",
    "                running_var = nn.Parameter(torch.ones(param[0]), requires_grad=False)\n",
    "                self.vars_bn.extend([running_mean, running_var])\n",
    "\n",
    "    def forward(self, x, vars=None, bn_training=True):\n",
    "        if vars is None:\n",
    "            vars = self.vars\n",
    "\n",
    "        idx = 0\n",
    "        bn_idx = 0\n",
    "        for name, param in self.config:\n",
    "            if name == \"conv2d\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                x = F.conv2d(x, w, b, stride=param[4], padding=param[5])\n",
    "                idx += 2\n",
    "            elif name == \"linear\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                x = F.linear(x, w, b)\n",
    "                idx += 2\n",
    "            elif name == \"bn\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                running_mean, running_var = (\n",
    "                    self.vars_bn[bn_idx],\n",
    "                    self.vars_bn[bn_idx + 1],\n",
    "                )\n",
    "                x = F.batch_norm(\n",
    "                    x, running_mean, running_var, weight=w, bias=b, training=bn_training\n",
    "                )\n",
    "                idx += 2\n",
    "                bn_idx += 2\n",
    "            elif name == \"flatten\":\n",
    "                x = x.view(x.size(0), -1)\n",
    "            elif name == \"relu\":\n",
    "                x = F.relu(x, inplace=param[0])\n",
    "            elif name == \"max_pool2d\":\n",
    "                x = F.max_pool2d(x, param[0], param[1], param[2])\n",
    "\n",
    "        assert idx == len(vars)\n",
    "        assert bn_idx == len(self.vars_bn)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.vars\n",
    "\n",
    "\n",
    "class Meta(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_way,\n",
    "        k_spt,\n",
    "        k_qry,\n",
    "        task_num,\n",
    "        update_step,\n",
    "        update_step_test,\n",
    "        update_lr,\n",
    "        meta_lr,\n",
    "        config,\n",
    "        imgc,\n",
    "        imgsz,\n",
    "    ):\n",
    "        super(Meta, self).__init__()\n",
    "        self.n_way = n_way\n",
    "        self.k_spt = k_spt\n",
    "        self.k_qry = k_qry\n",
    "        self.task_num = task_num\n",
    "        self.update_step = update_step\n",
    "        self.update_step_test = update_step_test\n",
    "        self.update_lr = update_lr\n",
    "        self.meta_lr = meta_lr\n",
    "        self.config = config\n",
    "        self.imgc = imgc\n",
    "        self.imgsz = imgsz\n",
    "\n",
    "        self.net = Learner(config, imgc, imgsz)\n",
    "        self.meta_optim = optim.Adam(self.net.parameters(), lr=meta_lr)\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        task_num = x_spt.size(0)\n",
    "        querysz = x_qry.size(1)\n",
    "\n",
    "        losses_q = [0 for _ in range(self.update_step + 1)]\n",
    "        corrects = [0 for _ in range(self.update_step + 1)]\n",
    "\n",
    "        for i in range(task_num):\n",
    "            logits = self.net(x_spt[i], vars=None, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt[i])\n",
    "            grad = torch.autograd.grad(loss, self.net.parameters())\n",
    "            fast_weights = list(\n",
    "                map(\n",
    "                    lambda p: p[1] - self.update_lr * p[0],\n",
    "                    zip(grad, self.net.parameters()),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[0] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[0] = corrects[0] + correct\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[1] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[1] = corrects[1] + correct\n",
    "\n",
    "            for k in range(1, self.update_step):\n",
    "                logits = self.net(x_spt[i], fast_weights, bn_training=True)\n",
    "                loss = F.cross_entropy(logits, y_spt[i])\n",
    "                grad = torch.autograd.grad(loss, fast_weights)\n",
    "                fast_weights = list(\n",
    "                    map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights))\n",
    "                )\n",
    "\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[k + 1] += loss_q\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                    corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "        loss_q = losses_q[-1] / task_num\n",
    "        self.meta_optim.zero_grad()\n",
    "        loss_q.backward()\n",
    "        self.meta_optim.step()\n",
    "\n",
    "        accs = np.array(corrects) / (querysz * task_num)\n",
    "        return accs\n",
    "\n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        assert len(x_spt.shape) == 4\n",
    "        querysz = x_qry.size(0)\n",
    "        corrects = [0 for _ in range(self.update_step_test + 1)]\n",
    "        net = deepcopy(self.net)\n",
    "\n",
    "        logits = net(x_spt)\n",
    "        loss = F.cross_entropy(logits, y_spt)\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        fast_weights = list(\n",
    "            map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters()))\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, net.parameters(), bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[0] = corrects[0] + correct\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[1] = corrects[1] + correct\n",
    "\n",
    "        for k in range(1, self.update_step_test):\n",
    "            logits = net(x_spt, fast_weights, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt)\n",
    "            grad = torch.autograd.grad(loss, fast_weights)\n",
    "            fast_weights = list(\n",
    "                map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights))\n",
    "            )\n",
    "\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "            loss_q = F.cross_entropy(logits_q, y_qry)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "                corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "        del net\n",
    "        accs = np.array(corrects) / querysz\n",
    "        return accs\n",
    "\n",
    "\n",
    "def main():\n",
    "    epoch = 60000\n",
    "    n_way = 5\n",
    "    k_spt = 1\n",
    "    k_qry = 15\n",
    "    imgsz = 84\n",
    "    imgc = 3\n",
    "    task_num = 4\n",
    "    meta_lr = 1e-3\n",
    "    update_lr = 0.01\n",
    "    update_step = 5\n",
    "    update_step_test = 10\n",
    "    torch.manual_seed(222)\n",
    "    torch.cuda.manual_seed_all(222)\n",
    "    np.random.seed(222)\n",
    "\n",
    "    config = [\n",
    "        (\"conv2d\", [32, 3, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 1, 0]),\n",
    "        (\"flatten\", []),\n",
    "        (\"linear\", [n_way, 32 * 5 * 5]),\n",
    "    ]\n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "    maml = Meta(\n",
    "        n_way,\n",
    "        k_spt,\n",
    "        k_qry,\n",
    "        task_num,\n",
    "        update_step,\n",
    "        update_step_test,\n",
    "        update_lr,\n",
    "        meta_lr,\n",
    "        config,\n",
    "        imgc,\n",
    "        imgsz,\n",
    "    ).to(device)\n",
    "\n",
    "    mini = MiniImagenet(\n",
    "        \"mini-imagenet\",\n",
    "        mode=\"train\",\n",
    "        n_way=n_way,\n",
    "        k_shot=k_spt,\n",
    "        k_query=k_qry,\n",
    "        batchsz=10000,\n",
    "        resize=imgsz,\n",
    "    )\n",
    "    mini_test = MiniImagenet(\n",
    "        \"mini-imagenet\",\n",
    "        mode=\"test\",\n",
    "        n_way=n_way,\n",
    "        k_shot=k_spt,\n",
    "        k_query=k_qry,\n",
    "        batchsz=100,\n",
    "        resize=imgsz,\n",
    "    )\n",
    "\n",
    "    for epoch_count in range(epoch // 10000):\n",
    "        db = DataLoader(mini, task_num, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "        for step, (x_spt, y_spt, x_qry, y_qry) in enumerate(db):\n",
    "            x_spt, y_spt, x_qry, y_qry = (\n",
    "                x_spt.to(device),\n",
    "                y_spt.to(device),\n",
    "                x_qry.to(device),\n",
    "                y_qry.to(device),\n",
    "            )\n",
    "            accs = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "            if step % 30 == 0:\n",
    "                print(\"step:\", step, \"\\ttraining acc:\", accs)\n",
    "\n",
    "            if step % 500 == 0:  # evaluation\n",
    "                db_test = DataLoader(\n",
    "                    mini_test, 1, shuffle=True, num_workers=1, pin_memory=True\n",
    "                )\n",
    "                accs_all_test = []\n",
    "\n",
    "                for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                    x_spt, y_spt, x_qry, y_qry = (\n",
    "                        x_spt.squeeze(0).to(device),\n",
    "                        y_spt.squeeze(0).to(device),\n",
    "                        x_qry.squeeze(0).to(device),\n",
    "                        y_qry.squeeze(0).to(device),\n",
    "                    )\n",
    "                    accs = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                    accs_all_test.append(accs)\n",
    "\n",
    "                accs = np.array(accs_all_test).mean(axis=0).astype(np.float16)\n",
    "                print(\"Test acc:\", accs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MiniImagenet(Dataset):\n",
    "    def __init__(self, root, mode, batchsz, n_way, k_shot, k_query, resize, startidx=0):\n",
    "        self.batchsz = batchsz\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.k_query = k_query\n",
    "        self.setsz = self.n_way * self.k_shot\n",
    "        self.querysz = self.n_way * self.k_query\n",
    "        self.resize = resize\n",
    "        self.startidx = startidx\n",
    "        print(\n",
    "            \"shuffle DB :%s, b:%d, %d-way, %d-shot, %d-query, resize:%d\"\n",
    "            % (mode, batchsz, n_way, k_shot, k_query, resize)\n",
    "        )\n",
    "\n",
    "        if mode == \"train\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                    transforms.Resize((self.resize, self.resize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                    transforms.Resize((self.resize, self.resize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.path = os.path.join(root, \"images\")\n",
    "        csvdata = self.loadCSV(os.path.join(root, mode + \".csv\"))\n",
    "        self.data = []\n",
    "        self.img2label = {}\n",
    "        for i, (k, v) in enumerate(csvdata.items()):\n",
    "            self.data.append(v)\n",
    "            self.img2label[k] = i + self.startidx\n",
    "        self.cls_num = len(self.data)\n",
    "\n",
    "        self.create_batch(self.batchsz)\n",
    "\n",
    "    def loadCSV(self, csvf):\n",
    "        dictLabels = {}\n",
    "        with open(csvf) as csvfile:\n",
    "            csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "            next(csvreader, None)\n",
    "            for i, row in enumerate(csvreader):\n",
    "                filename = row[0]\n",
    "                label = row[1]\n",
    "                if label in dictLabels.keys():\n",
    "                    dictLabels[label].append(filename)\n",
    "                else:\n",
    "                    dictLabels[label] = [filename]\n",
    "        return dictLabels\n",
    "\n",
    "    def create_batch(self, batchsz):\n",
    "        self.support_x_batch = []\n",
    "        self.query_x_batch = []\n",
    "        for b in range(batchsz):\n",
    "            selected_cls = np.random.choice(self.cls_num, self.n_way, False)\n",
    "            np.random.shuffle(selected_cls)\n",
    "            support_x = []\n",
    "            query_x = []\n",
    "            for cls in selected_cls:\n",
    "                selected_imgs_idx = np.random.choice(\n",
    "                    len(self.data[cls]), self.k_shot + self.k_query, False\n",
    "                )\n",
    "                np.random.shuffle(selected_imgs_idx)\n",
    "                indexDtrain = np.array(selected_imgs_idx[: self.k_shot])\n",
    "                indexDtest = np.array(selected_imgs_idx[self.k_shot :])\n",
    "                support_x.append(np.array(self.data[cls])[indexDtrain].tolist())\n",
    "                query_x.append(np.array(self.data[cls])[indexDtest].tolist())\n",
    "\n",
    "            random.shuffle(support_x)\n",
    "            random.shuffle(query_x)\n",
    "\n",
    "            self.support_x_batch.append(support_x)\n",
    "            self.query_x_batch.append(query_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        support_x = torch.FloatTensor(self.setsz, 3, self.resize, self.resize)\n",
    "        support_y = np.zeros((self.setsz), dtype=np.int32)\n",
    "        query_x = torch.FloatTensor(self.querysz, 3, self.resize, self.resize)\n",
    "        query_y = np.zeros((self.querysz), dtype=np.int32)\n",
    "\n",
    "        flatten_support_x = [\n",
    "            os.path.join(self.path, item)\n",
    "            for sublist in self.support_x_batch[index]\n",
    "            for item in sublist\n",
    "        ]\n",
    "        support_y = np.array(\n",
    "            [\n",
    "                self.img2label[item[:9]]\n",
    "                for sublist in self.support_x_batch[index]\n",
    "                for item in sublist\n",
    "            ]\n",
    "        ).astype(np.int32)\n",
    "\n",
    "        flatten_query_x = [\n",
    "            os.path.join(self.path, item)\n",
    "            for sublist in self.query_x_batch[index]\n",
    "            for item in sublist\n",
    "        ]\n",
    "        query_y = np.array(\n",
    "            [\n",
    "                self.img2label[item[:9]]\n",
    "                for sublist in self.query_x_batch[index]\n",
    "                for item in sublist\n",
    "            ]\n",
    "        ).astype(np.int32)\n",
    "\n",
    "        unique = np.unique(support_y)\n",
    "        random.shuffle(unique)\n",
    "        support_y_relative = np.zeros(self.setsz)\n",
    "        query_y_relative = np.zeros(self.querysz)\n",
    "        for idx, l in enumerate(unique):\n",
    "            support_y_relative[support_y == l] = idx\n",
    "            query_y_relative[query_y == l] = idx\n",
    "\n",
    "        for i, path in enumerate(flatten_support_x):\n",
    "            support_x[i] = self.transform(path)\n",
    "\n",
    "        for i, path in enumerate(flatten_query_x):\n",
    "            query_x[i] = self.transform(path)\n",
    "\n",
    "        return (\n",
    "            support_x,\n",
    "            torch.LongTensor(support_y_relative),\n",
    "            query_x,\n",
    "            torch.LongTensor(query_y_relative),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batchsz\n",
    "\n",
    "\n",
    "class Learner(nn.Module):\n",
    "    def __init__(self, config, imgc, imgsz):\n",
    "        super(Learner, self).__init__()\n",
    "        self.config = config\n",
    "        self.vars = nn.ParameterList()\n",
    "        self.vars_bn = nn.ParameterList()\n",
    "\n",
    "        for i, (name, param) in enumerate(self.config):\n",
    "            if name == \"conv2d\":\n",
    "                w = nn.Parameter(torch.ones(*param[:4]))\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "            elif name == \"linear\":\n",
    "                w = nn.Parameter(torch.ones(*param))\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "            elif name == \"bn\":\n",
    "                w = nn.Parameter(torch.ones(param[0]))\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "                running_mean = nn.Parameter(torch.zeros(param[0]), requires_grad=False)\n",
    "                running_var = nn.Parameter(torch.ones(param[0]), requires_grad=False)\n",
    "                self.vars_bn.extend([running_mean, running_var])\n",
    "\n",
    "    def forward(self, x, vars=None, bn_training=True):\n",
    "        if vars is None:\n",
    "            vars = self.vars\n",
    "\n",
    "        idx = 0\n",
    "        bn_idx = 0\n",
    "        for name, param in self.config:\n",
    "            if name == \"conv2d\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                x = F.conv2d(x, w, b, stride=param[4], padding=param[5])\n",
    "                idx += 2\n",
    "            elif name == \"linear\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                x = F.linear(x, w, b)\n",
    "                idx += 2\n",
    "            elif name == \"bn\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                running_mean, running_var = (\n",
    "                    self.vars_bn[bn_idx],\n",
    "                    self.vars_bn[bn_idx + 1],\n",
    "                )\n",
    "                x = F.batch_norm(\n",
    "                    x, running_mean, running_var, weight=w, bias=b, training=bn_training\n",
    "                )\n",
    "                idx += 2\n",
    "                bn_idx += 2\n",
    "            elif name == \"flatten\":\n",
    "                x = x.view(x.size(0), -1)\n",
    "            elif name == \"relu\":\n",
    "                x = F.relu(x, inplace=param[0])\n",
    "            elif name == \"max_pool2d\":\n",
    "                x = F.max_pool2d(x, param[0], param[1], param[2])\n",
    "\n",
    "        assert idx == len(vars)\n",
    "        assert bn_idx == len(self.vars_bn)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.vars\n",
    "\n",
    "\n",
    "class Meta(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_way,\n",
    "        k_spt,\n",
    "        k_qry,\n",
    "        task_num,\n",
    "        update_step,\n",
    "        update_step_test,\n",
    "        update_lr,\n",
    "        meta_lr,\n",
    "        config,\n",
    "        imgc,\n",
    "        imgsz,\n",
    "    ):\n",
    "        super(Meta, self).__init__()\n",
    "        self.n_way = n_way\n",
    "        self.k_spt = k_spt\n",
    "        self.k_qry = k_qry\n",
    "        self.task_num = task_num\n",
    "        self.update_step = update_step\n",
    "        self.update_step_test = update_step_test\n",
    "        self.update_lr = update_lr\n",
    "        self.meta_lr = meta_lr\n",
    "        self.config = config\n",
    "        self.imgc = imgc\n",
    "        self.imgsz = imgsz\n",
    "\n",
    "        self.net = Learner(config, imgc, imgsz)\n",
    "        self.meta_optim = optim.Adam(self.net.parameters(), lr=meta_lr)\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        task_num = x_spt.size(0)\n",
    "        querysz = x_qry.size(1)\n",
    "\n",
    "        losses_q = [0 for _ in range(self.update_step + 1)]\n",
    "        corrects = [0 for _ in range(self.update_step + 1)]\n",
    "\n",
    "        for i in range(task_num):\n",
    "            logits = self.net(x_spt[i], vars=None, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt[i])\n",
    "            grad = torch.autograd.grad(loss, self.net.parameters())\n",
    "            fast_weights = list(\n",
    "                map(\n",
    "                    lambda p: p[1] - self.update_lr * p[0],\n",
    "                    zip(grad, self.net.parameters()),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[0] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[0] = corrects[0] + correct\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[1] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[1] = corrects[1] + correct\n",
    "\n",
    "            for k in range(1, self.update_step):\n",
    "                logits = self.net(x_spt[i], fast_weights, bn_training=True)\n",
    "                loss = F.cross_entropy(logits, y_spt[i])\n",
    "                grad = torch.autograd.grad(loss, fast_weights)\n",
    "                fast_weights = list(\n",
    "                    map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights))\n",
    "                )\n",
    "\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[k + 1] += loss_q\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                    corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "        loss_q = losses_q[-1] / task_num\n",
    "        self.meta_optim.zero_grad()\n",
    "        loss_q.backward()\n",
    "        self.meta_optim.step()\n",
    "\n",
    "        accs = np.array(corrects) / (querysz * task_num)\n",
    "        return accs\n",
    "\n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        assert len(x_spt.shape) == 4\n",
    "        querysz = x_qry.size(0)\n",
    "        corrects = [0 for _ in range(self.update_step_test + 1)]\n",
    "        net = deepcopy(self.net)\n",
    "\n",
    "        logits = net(x_spt)\n",
    "        loss = F.cross_entropy(logits, y_spt)\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        fast_weights = list(\n",
    "            map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters()))\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, net.parameters(), bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[0] = corrects[0] + correct\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[1] = corrects[1] + correct\n",
    "\n",
    "        for k in range(1, self.update_step_test):\n",
    "            logits = net(x_spt, fast_weights, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt)\n",
    "            grad = torch.autograd.grad(loss, fast_weights)\n",
    "            fast_weights = list(\n",
    "                map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights))\n",
    "            )\n",
    "\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "                corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "        del net\n",
    "        accs = np.array(corrects) / querysz\n",
    "        return accs\n",
    "\n",
    "\n",
    "def main():\n",
    "    epoch = 60000\n",
    "    n_way = 5\n",
    "    k_spt = 1\n",
    "    k_qry = 15\n",
    "    imgsz = 84\n",
    "    imgc = 3\n",
    "    task_num = 4\n",
    "    meta_lr = 1e-3\n",
    "    update_lr = 0.01\n",
    "    update_step = 5\n",
    "    update_step_test = 10\n",
    "\n",
    "    # Set the paths to your mini-imagenet dataset\n",
    "    root = \"./mini-imagenet\"\n",
    "\n",
    "    torch.manual_seed(222)\n",
    "    torch.cuda.manual_seed_all(222)\n",
    "    np.random.seed(222)\n",
    "\n",
    "    config = [\n",
    "        (\"conv2d\", [32, 3, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 1, 0]),\n",
    "        (\"flatten\", []),\n",
    "        (\"linear\", [n_way, 32 * 5 * 5]),\n",
    "    ]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    maml = Meta(\n",
    "        n_way,\n",
    "        k_spt,\n",
    "        k_qry,\n",
    "        task_num,\n",
    "        update_step,\n",
    "        update_step_test,\n",
    "        update_lr,\n",
    "        meta_lr,\n",
    "        config,\n",
    "        imgc,\n",
    "        imgsz,\n",
    "    ).to(device)\n",
    "\n",
    "    tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "    num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "    print(maml)\n",
    "    print(\"Total trainable tensors:\", num)\n",
    "\n",
    "    # batchsz here means total episode number\n",
    "    mini = MiniImagenet(\n",
    "        root,\n",
    "        mode=\"train\",\n",
    "        n_way=n_way,\n",
    "        k_shot=k_spt,\n",
    "        k_query=k_qry,\n",
    "        batchsz=10000,\n",
    "        resize=imgsz,\n",
    "    )\n",
    "    mini_test = MiniImagenet(\n",
    "        root,\n",
    "        mode=\"test\",\n",
    "        n_way=n_way,\n",
    "        k_shot=k_spt,\n",
    "        k_query=k_qry,\n",
    "        batchsz=100,\n",
    "        resize=imgsz,\n",
    "    )\n",
    "\n",
    "    for epoch_count in range(epoch // 10000):\n",
    "        db = DataLoader(mini, task_num, shuffle=True, num_workers=1, pin_memory=True)\n",
    "\n",
    "        for step, (x_spt, y_spt, x_qry, y_qry) in enumerate(db):\n",
    "            x_spt, y_spt, x_qry, y_qry = (\n",
    "                x_spt.to(device),\n",
    "                y_spt.to(device),\n",
    "                x_qry.to(device),\n",
    "                y_qry.to(device),\n",
    "            )\n",
    "\n",
    "            accs = maml(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "            if step % 50 == 0:\n",
    "                print(\"step:\", step, \"\\ttraining acc:\", accs)\n",
    "\n",
    "            if step % 500 == 0:  # evaluation\n",
    "                db_test = DataLoader(\n",
    "                    mini_test, 1, shuffle=True, num_workers=1, pin_memory=True\n",
    "                )\n",
    "                accs_all_test = []\n",
    "\n",
    "                for x_spt, y_spt, x_qry, y_qry in db_test:\n",
    "                    x_spt, y_spt, x_qry, y_qry = (\n",
    "                        x_spt.squeeze(0).to(device),\n",
    "                        y_spt.squeeze(0).to(device),\n",
    "                        x_qry.squeeze(0).to(device),\n",
    "                        y_qry.squeeze(0).to(device),\n",
    "                    )\n",
    "\n",
    "                    accs = maml.finetunning(x_spt, y_spt, x_qry, y_qry)\n",
    "                    accs_all_test.append(accs)\n",
    "\n",
    "                # [b, update_step+1]\n",
    "                accs = np.array(accs_all_test).mean(axis=0).astype(np.float16)\n",
    "                print(\"Test acc:\", accs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "\n",
    "\n",
    "# Define the model architecture\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(\n",
    "                32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)\n",
    "            ),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(10),\n",
    "        ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define the MAML model\n",
    "class MAML(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super(MAML, self).__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "        y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self.model(x)\n",
    "            loss = self.compiled_loss(y, y_pred)\n",
    "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, y = data\n",
    "        x = tf.reshape(x, (-1, 28, 28, 1))  # Reshape the input tensor\n",
    "        y = tf.reshape(y, (-1,))  # Reshape the target labels\n",
    "        y_pred = self.model(x)\n",
    "        self.compiled_loss(y, y_pred)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "\n",
    "# Define the meta-learning parameters\n",
    "num_meta_updates = 10\n",
    "num_inner_updates = 5\n",
    "meta_batch_size = 32\n",
    "inner_batch_size = 10\n",
    "\n",
    "# Create the MAML model\n",
    "model = MAML(create_model())\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Initialize variables to store accuracy over time\n",
    "meta_updates = []\n",
    "accuracy_over_time = []\n",
    "\n",
    "# Meta-training loop\n",
    "for meta_update in range(num_meta_updates):\n",
    "    # Sample a meta-batch of tasks\n",
    "    meta_batch = tf.random.shuffle(tf.range(len(x_train)))[:meta_batch_size]\n",
    "\n",
    "    # Inner loop updates for each task\n",
    "    for task in meta_batch:\n",
    "        task_data = (\n",
    "            x_train[task : task + inner_batch_size],\n",
    "            y_train[task : task + inner_batch_size],\n",
    "        )\n",
    "        for inner_update in range(num_inner_updates):\n",
    "            model.train_step(task_data)\n",
    "\n",
    "    # Evaluate on the meta-test set\n",
    "    _, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "    # Store the meta-update step and accuracy\n",
    "    meta_updates.append(meta_update + 1)\n",
    "    accuracy_over_time.append(accuracy)\n",
    "\n",
    "# Fine-tuning on a new task\n",
    "new_task_data = (x_test[:100], y_test[:100])\n",
    "model.fit(new_task_data[0], new_task_data[1], epochs=10)\n",
    "\n",
    "# Plot the accuracy over time graph\n",
    "plt.plot(meta_updates, accuracy_over_time)\n",
    "plt.xlabel(\"Meta-Update Step\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy Over Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.primitives.asymmetric import dh\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Pyfhel import Pyfhel\n",
    "\n",
    "\n",
    "class MiniImagenet(Dataset):\n",
    "    def __init__(self, root, mode, batchsz, n_way, k_shot, k_query, resize, startidx=0):\n",
    "        self.batchsz = batchsz\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.k_query = k_query\n",
    "        self.setsz = self.n_way * self.k_shot\n",
    "        self.querysz = self.n_way * self.k_query\n",
    "        self.resize = resize\n",
    "        self.startidx = startidx\n",
    "        print(\n",
    "            \"shuffle DB :%s, b:%d, %d-way, %d-shot, %d-query, resize:%d\"\n",
    "            % (mode, batchsz, n_way, k_shot, k_query, resize)\n",
    "        )\n",
    "\n",
    "        if mode == \"train\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                    transforms.Resize((self.resize, self.resize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                    transforms.Resize((self.resize, self.resize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.path = os.path.join(root, \"images\")\n",
    "        csvdata = self.loadCSV(os.path.join(root, mode + \".csv\"))\n",
    "        self.data = []\n",
    "        self.img2label = {}\n",
    "        for i, (k, v) in enumerate(csvdata.items()):\n",
    "            self.data.append(v)\n",
    "            self.img2label[k] = i + self.startidx\n",
    "        self.cls_num = len(self.data)\n",
    "\n",
    "        self.create_batch(self.batchsz)\n",
    "\n",
    "    def loadCSV(self, csvf):\n",
    "        dictLabels = {}\n",
    "        with open(csvf) as csvfile:\n",
    "            csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "            next(csvreader, None)\n",
    "            for i, row in enumerate(csvreader):\n",
    "                filename = row[0]\n",
    "                label = row[1]\n",
    "                if label in dictLabels.keys():\n",
    "                    dictLabels[label].append(filename)\n",
    "                else:\n",
    "                    dictLabels[label] = [filename]\n",
    "        return dictLabels\n",
    "\n",
    "    def create_batch(self, batchsz):\n",
    "        self.support_x_batch = []\n",
    "        self.query_x_batch = []\n",
    "        for b in range(batchsz):\n",
    "            selected_cls = np.random.choice(self.cls_num, self.n_way, False)\n",
    "            np.random.shuffle(selected_cls)\n",
    "            support_x = []\n",
    "            query_x = []\n",
    "            for cls in selected_cls:\n",
    "                selected_imgs_idx = np.random.choice(\n",
    "                    len(self.data[cls]), self.k_shot + self.k_query, False\n",
    "                )\n",
    "                np.random.shuffle(selected_imgs_idx)\n",
    "                indexDtrain = np.array(selected_imgs_idx[: self.k_shot])\n",
    "                indexDtest = np.array(selected_imgs_idx[self.k_shot :])\n",
    "                support_x.append(np.array(self.data[cls])[indexDtrain].tolist())\n",
    "                query_x.append(np.array(self.data[cls])[indexDtest].tolist())\n",
    "\n",
    "            random.shuffle(support_x)\n",
    "            random.shuffle(query_x)\n",
    "\n",
    "            self.support_x_batch.append(support_x)\n",
    "            self.query_x_batch.append(query_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        support_x = torch.FloatTensor(self.setsz, 3, self.resize, self.resize)\n",
    "        support_y = np.zeros((self.setsz), dtype=np.int32)\n",
    "        query_x = torch.FloatTensor(self.querysz, 3, self.resize, self.resize)\n",
    "        query_y = np.zeros((self.querysz), dtype=np.int32)\n",
    "\n",
    "        flatten_support_x = [\n",
    "            os.path.join(self.path, item)\n",
    "            for sublist in self.support_x_batch[index]\n",
    "            for item in sublist\n",
    "        ]\n",
    "        support_y = np.array(\n",
    "            [\n",
    "                self.img2label[item[:9]]\n",
    "                for sublist in self.support_x_batch[index]\n",
    "                for item in sublist\n",
    "            ]\n",
    "        ).astype(np.int32)\n",
    "\n",
    "        flatten_query_x = [\n",
    "            os.path.join(self.path, item)\n",
    "            for sublist in self.query_x_batch[index]\n",
    "            for item in sublist\n",
    "        ]\n",
    "        query_y = np.array(\n",
    "            [\n",
    "                self.img2label[item[:9]]\n",
    "                for sublist in self.query_x_batch[index]\n",
    "                for item in sublist\n",
    "            ]\n",
    "        ).astype(np.int32)\n",
    "\n",
    "        unique = np.unique(support_y)\n",
    "        random.shuffle(unique)\n",
    "        support_y_relative = np.zeros(self.setsz)\n",
    "        query_y_relative = np.zeros(self.querysz)\n",
    "        for idx, l in enumerate(unique):\n",
    "            support_y_relative[support_y == l] = idx\n",
    "            query_y_relative[query_y == l] = idx\n",
    "\n",
    "        for i, path in enumerate(flatten_support_x):\n",
    "            support_x[i] = self.transform(path)\n",
    "\n",
    "        for i, path in enumerate(flatten_query_x):\n",
    "            query_x[i] = self.transform(path)\n",
    "\n",
    "        return (\n",
    "            support_x,\n",
    "            torch.LongTensor(support_y_relative),\n",
    "            query_x,\n",
    "            torch.LongTensor(query_y_relative),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batchsz\n",
    "\n",
    "\n",
    "class Learner(nn.Module):\n",
    "    def __init__(self, config, imgc, imgsz):\n",
    "        super(Learner, self).__init__()\n",
    "        self.config = config\n",
    "        self.vars = nn.ParameterList()\n",
    "        self.vars_bn = nn.ParameterList()\n",
    "\n",
    "        for i, (name, param) in enumerate(self.config):\n",
    "            if name == \"conv2d\":\n",
    "                w = nn.Parameter(torch.ones(*param[:4]))\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "            elif name == \"linear\":\n",
    "                w = nn.Parameter(torch.ones(*param))\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "            elif name == \"bn\":\n",
    "                w = nn.Parameter(torch.ones(param[0]))\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "                running_mean = nn.Parameter(torch.zeros(param[0]), requires_grad=False)\n",
    "                running_var = nn.Parameter(torch.ones(param[0]), requires_grad=False)\n",
    "                self.vars_bn.extend([running_mean, running_var])\n",
    "\n",
    "    def forward(self, x, vars=None, bn_training=True):\n",
    "        if vars is None:\n",
    "            vars = self.vars\n",
    "\n",
    "        idx = 0\n",
    "        bn_idx = 0\n",
    "        for name, param in self.config:\n",
    "            if name == \"conv2d\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                x = F.conv2d(x, w, b, stride=param[4], padding=param[5])\n",
    "                idx += 2\n",
    "            elif name == \"linear\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                x = F.linear(x, w, b)\n",
    "                idx += 2\n",
    "            elif name == \"bn\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                running_mean, running_var = (\n",
    "                    self.vars_bn[bn_idx],\n",
    "                    self.vars_bn[bn_idx + 1],\n",
    "                )\n",
    "                x = F.batch_norm(\n",
    "                    x, running_mean, running_var, weight=w, bias=b, training=bn_training\n",
    "                )\n",
    "                idx += 2\n",
    "                bn_idx += 2\n",
    "            elif name == \"flatten\":\n",
    "                x = x.view(x.size(0), -1)\n",
    "            elif name == \"relu\":\n",
    "                x = F.relu(x, inplace=param[0])\n",
    "            elif name == \"max_pool2d\":\n",
    "                x = F.max_pool2d(x, param[0], param[1], param[2])\n",
    "\n",
    "        assert idx == len(vars)\n",
    "        assert bn_idx == len(self.vars_bn)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.vars\n",
    "\n",
    "\n",
    "class Meta(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_way,\n",
    "        k_spt,\n",
    "        k_qry,\n",
    "        task_num,\n",
    "        update_step,\n",
    "        update_step_test,\n",
    "        update_lr,\n",
    "        meta_lr,\n",
    "        config,\n",
    "        imgc,\n",
    "        imgsz,\n",
    "    ):\n",
    "        super(Meta, self).__init__()\n",
    "        self.n_way = n_way\n",
    "        self.k_spt = k_spt\n",
    "        self.k_qry = k_qry\n",
    "        self.task_num = task_num\n",
    "        self.update_step = update_step\n",
    "        self.update_step_test = update_step_test\n",
    "        self.update_lr = update_lr\n",
    "        self.meta_lr = meta_lr\n",
    "        self.config = config\n",
    "        self.imgc = imgc\n",
    "        self.imgsz = imgsz\n",
    "\n",
    "        self.net = Learner(config, imgc, imgsz)\n",
    "        self.meta_optim = optim.Adam(self.net.parameters(), lr=meta_lr)\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        task_num = x_spt.size(0)\n",
    "        querysz = x_qry.size(1)\n",
    "\n",
    "        losses_q = [0 for _ in range(self.update_step + 1)]\n",
    "        corrects = [0 for _ in range(self.update_step + 1)]\n",
    "\n",
    "        for i in range(task_num):\n",
    "            logits = self.net(x_spt[i], vars=None, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt[i])\n",
    "            grad = torch.autograd.grad(loss, self.net.parameters())\n",
    "            fast_weights = list(\n",
    "                map(\n",
    "                    lambda p: p[1] - self.update_lr * p[0],\n",
    "                    zip(grad, self.net.parameters()),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[0] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[0] = corrects[0] + correct\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[1] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[1] = corrects[1] + correct\n",
    "\n",
    "            for k in range(1, self.update_step):\n",
    "                logits = self.net(x_spt[i], fast_weights, bn_training=True)\n",
    "                loss = F.cross_entropy(logits, y_spt[i])\n",
    "                grad = torch.autograd.grad(loss, fast_weights)\n",
    "                fast_weights = list(\n",
    "                    map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights))\n",
    "                )\n",
    "\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[k + 1] += loss_q\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                    corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "        loss_q = losses_q[-1] / task_num\n",
    "        self.meta_optim.zero_grad()\n",
    "        loss_q.backward()\n",
    "        self.meta_optim.step()\n",
    "\n",
    "        accs = np.array(corrects) / (querysz * task_num)\n",
    "        return accs\n",
    "\n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        assert len(x_spt.shape) == 4\n",
    "        querysz = x_qry.size(0)\n",
    "        corrects = [0 for _ in range(self.update_step_test + 1)]\n",
    "        net = deepcopy(self.net)\n",
    "\n",
    "        logits = net(x_spt)\n",
    "        loss = F.cross_entropy(logits, y_spt)\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        fast_weights = list(\n",
    "            map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters()))\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, net.parameters(), bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[0] = corrects[0] + correct\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[1] = corrects[1] + correct\n",
    "\n",
    "        for k in range(1, self.update_step_test):\n",
    "            logits = net(x_spt, fast_weights, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.primitives.asymmetric import dh\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Pyfhel import Pyfhel\n",
    "\n",
    "\n",
    "class MiniImagenet(Dataset):\n",
    "    def __init__(self, root, mode, batchsz, n_way, k_shot, k_query, resize, startidx=0):\n",
    "        self.batchsz = batchsz\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.k_query = k_query\n",
    "        self.setsz = self.n_way * self.k_shot\n",
    "        self.querysz = self.n_way * self.k_query\n",
    "        self.resize = resize\n",
    "        self.startidx = startidx\n",
    "        print(\n",
    "            \"shuffle DB :%s, b:%d, %d-way, %d-shot, %d-query, resize:%d\"\n",
    "            % (mode, batchsz, n_way, k_shot, k_query, resize)\n",
    "        )\n",
    "\n",
    "        if mode == \"train\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                    transforms.Resize((self.resize, self.resize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                    transforms.Resize((self.resize, self.resize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.path = os.path.join(root, \"images\")\n",
    "        csvdata = self.loadCSV(os.path.join(root, mode + \".csv\"))\n",
    "        self.data = []\n",
    "        self.img2label = {}\n",
    "        for i, (k, v) in enumerate(csvdata.items()):\n",
    "            self.data.append(v)\n",
    "            self.img2label[k] = i + self.startidx\n",
    "        self.cls_num = len(self.data)\n",
    "\n",
    "        self.create_batch(self.batchsz)\n",
    "\n",
    "    def loadCSV(self, csvf):\n",
    "        dictLabels = {}\n",
    "        with open(csvf) as csvfile:\n",
    "            csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "            next(csvreader, None)\n",
    "            for i, row in enumerate(csvreader):\n",
    "                filename = row[0]\n",
    "                label = row[1]\n",
    "                if label in dictLabels.keys():\n",
    "                    dictLabels[label].append(filename)\n",
    "                else:\n",
    "                    dictLabels[label] = [filename]\n",
    "        return dictLabels\n",
    "\n",
    "    def create_batch(self, batchsz):\n",
    "        self.support_x_batch = []\n",
    "        self.query_x_batch = []\n",
    "        for b in range(batchsz):\n",
    "            selected_cls = np.random.choice(self.cls_num, self.n_way, False)\n",
    "            np.random.shuffle(selected_cls)\n",
    "            support_x = []\n",
    "            query_x = []\n",
    "            for cls in selected_cls:\n",
    "                selected_imgs_idx = np.random.choice(\n",
    "                    len(self.data[cls]), self.k_shot + self.k_query, False\n",
    "                )\n",
    "                np.random.shuffle(selected_imgs_idx)\n",
    "                indexDtrain = np.array(selected_imgs_idx[: self.k_shot])\n",
    "                indexDtest = np.array(selected_imgs_idx[self.k_shot :])\n",
    "                support_x.append(np.array(self.data[cls])[indexDtrain].tolist())\n",
    "                query_x.append(np.array(self.data[cls])[indexDtest].tolist())\n",
    "\n",
    "            random.shuffle(support_x)\n",
    "            random.shuffle(query_x)\n",
    "\n",
    "            self.support_x_batch.append(support_x)\n",
    "            self.query_x_batch.append(query_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        support_x = torch.FloatTensor(self.setsz, 3, self.resize, self.resize)\n",
    "        support_y = np.zeros((self.setsz), dtype=np.int32)\n",
    "        query_x = torch.FloatTensor(self.querysz, 3, self.resize, self.resize)\n",
    "        query_y = np.zeros((self.querysz), dtype=np.int32)\n",
    "\n",
    "        flatten_support_x = [\n",
    "            os.path.join(self.path, item)\n",
    "            for sublist in self.support_x_batch[index]\n",
    "            for item in sublist\n",
    "        ]\n",
    "        support_y = np.array(\n",
    "            [\n",
    "                self.img2label[item[:9]]\n",
    "                for sublist in self.support_x_batch[index]\n",
    "                for item in sublist\n",
    "            ]\n",
    "        ).astype(np.int32)\n",
    "\n",
    "        flatten_query_x = [\n",
    "            os.path.join(self.path, item)\n",
    "            for sublist in self.query_x_batch[index]\n",
    "            for item in sublist\n",
    "        ]\n",
    "        query_y = np.array(\n",
    "            [\n",
    "                self.img2label[item[:9]]\n",
    "                for sublist in self.query_x_batch[index]\n",
    "                for item in sublist\n",
    "            ]\n",
    "        ).astype(np.int32)\n",
    "\n",
    "        unique = np.unique(support_y)\n",
    "        random.shuffle(unique)\n",
    "        support_y_relative = np.zeros(self.setsz)\n",
    "        query_y_relative = np.zeros(self.querysz)\n",
    "        for idx, l in enumerate(unique):\n",
    "            support_y_relative[support_y == l] = idx\n",
    "            query_y_relative[query_y == l] = idx\n",
    "\n",
    "        for i, path in enumerate(flatten_support_x):\n",
    "            support_x[i] = self.transform(path)\n",
    "\n",
    "        for i, path in enumerate(flatten_query_x):\n",
    "            query_x[i] = self.transform(path)\n",
    "\n",
    "        return (\n",
    "            support_x,\n",
    "            torch.LongTensor(support_y_relative),\n",
    "            query_x,\n",
    "            torch.LongTensor(query_y_relative),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batchsz\n",
    "\n",
    "\n",
    "class Learner(nn.Module):\n",
    "    def __init__(self, config, imgc, imgsz):\n",
    "        super(Learner, self).__init__()\n",
    "        self.config = config\n",
    "        self.vars = nn.ParameterList()\n",
    "        self.vars_bn = nn.ParameterList()\n",
    "\n",
    "        for i, (name, param) in enumerate(self.config):\n",
    "            if name == \"conv2d\":\n",
    "                w = nn.Parameter(torch.ones(*param[:4]))\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "            elif name == \"linear\":\n",
    "                w = nn.Parameter(torch.ones(*param))\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "            elif name == \"bn\":\n",
    "                w = nn.Parameter(torch.ones(param[0]))\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "                running_mean = nn.Parameter(torch.zeros(param[0]), requires_grad=False)\n",
    "                running_var = nn.Parameter(torch.ones(param[0]), requires_grad=False)\n",
    "                self.vars_bn.extend([running_mean, running_var])\n",
    "\n",
    "    def forward(self, x, vars=None, bn_training=True):\n",
    "        if vars is None:\n",
    "            vars = self.vars\n",
    "\n",
    "        idx = 0\n",
    "        bn_idx = 0\n",
    "        for name, param in self.config:\n",
    "            if name == \"conv2d\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                x = F.conv2d(x, w, b, stride=param[4], padding=param[5])\n",
    "                idx += 2\n",
    "            elif name == \"linear\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                x = F.linear(x, w, b)\n",
    "                idx += 2\n",
    "            elif name == \"bn\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                running_mean, running_var = (\n",
    "                    self.vars_bn[bn_idx],\n",
    "                    self.vars_bn[bn_idx + 1],\n",
    "                )\n",
    "                x = F.batch_norm(\n",
    "                    x, running_mean, running_var, weight=w, bias=b, training=bn_training\n",
    "                )\n",
    "                idx += 2\n",
    "                bn_idx += 2\n",
    "            elif name == \"flatten\":\n",
    "                x = x.view(x.size(0), -1)\n",
    "            elif name == \"relu\":\n",
    "                x = F.relu(x, inplace=param[0])\n",
    "            elif name == \"max_pool2d\":\n",
    "                x = F.max_pool2d(x, param[0], param[1], param[2])\n",
    "\n",
    "        assert idx == len(vars)\n",
    "        assert bn_idx == len(self.vars_bn)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.vars\n",
    "\n",
    "\n",
    "class Meta(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_way,\n",
    "        k_spt,\n",
    "        k_qry,\n",
    "        task_num,\n",
    "        update_step,\n",
    "        update_step_test,\n",
    "        update_lr,\n",
    "        meta_lr,\n",
    "        config,\n",
    "        imgc,\n",
    "        imgsz,\n",
    "    ):\n",
    "        super(Meta, self).__init__()\n",
    "        self.n_way = n_way\n",
    "        self.k_spt = k_spt\n",
    "        self.k_qry = k_qry\n",
    "        self.task_num = task_num\n",
    "        self.update_step = update_step\n",
    "        self.update_step_test = update_step_test\n",
    "        self.update_lr = update_lr\n",
    "        self.meta_lr = meta_lr\n",
    "        self.config = config\n",
    "        self.imgc = imgc\n",
    "        self.imgsz = imgsz\n",
    "\n",
    "        self.net = Learner(config, imgc, imgsz)\n",
    "        self.meta_optim = optim.Adam(self.net.parameters(), lr=meta_lr)\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        task_num = x_spt.size(0)\n",
    "        querysz = x_qry.size(1)\n",
    "\n",
    "        losses_q = [0 for _ in range(self.update_step + 1)]\n",
    "        corrects = [0 for _ in range(self.update_step + 1)]\n",
    "\n",
    "        for i in range(task_num):\n",
    "            logits = self.net(x_spt[i], vars=None, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt[i])\n",
    "            grad = torch.autograd.grad(loss, self.net.parameters())\n",
    "            fast_weights = list(\n",
    "                map(\n",
    "                    lambda p: p[1] - self.update_lr * p[0],\n",
    "                    zip(grad, self.net.parameters()),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[0] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[0] = corrects[0] + correct\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[1] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[1] = corrects[1] + correct\n",
    "\n",
    "            for k in range(1, self.update_step):\n",
    "                logits = self.net(x_spt[i], fast_weights, bn_training=True)\n",
    "                loss = F.cross_entropy(logits, y_spt[i])\n",
    "                grad = torch.autograd.grad(loss, fast_weights)\n",
    "                fast_weights = list(\n",
    "                    map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights))\n",
    "                )\n",
    "\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[k + 1] += loss_q\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                    corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "        loss_q = losses_q[-1] / task_num\n",
    "        self.meta_optim.zero_grad()\n",
    "        loss_q.backward()\n",
    "        self.meta_optim.step()\n",
    "\n",
    "        accs = np.array(corrects) / (querysz * task_num)\n",
    "        return accs\n",
    "\n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        assert len(x_spt.shape) == 4\n",
    "        querysz = x_qry.size(0)\n",
    "        corrects = [0 for _ in range(self.update_step_test + 1)]\n",
    "        net = deepcopy(self.net)\n",
    "\n",
    "        logits = net(x_spt)\n",
    "        loss = F.cross_entropy(logits, y_spt)\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        fast_weights = list(\n",
    "            map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters()))\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, net.parameters(), bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[0] = corrects[0] + correct\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[1] = corrects[1] + correct\n",
    "\n",
    "        for k in range(1, self.update_step_test):\n",
    "            logits = net(x_spt, fast_weights, bn_training=True)\n",
    "            loss = F.cross_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entropy(logits, y_spt)\n",
    "#             grad = torch.autograd.grad(loss, fast_weights)\n",
    "#             fast_weights = list(\n",
    "#                 map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights))\n",
    "#             )\n",
    "\n",
    "#             logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "#                 correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "#                 corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "#         del net\n",
    "#         accs = np.array(corrects) / querysz\n",
    "#         return accs\n",
    "\n",
    "\n",
    "# def train_model(model, x_train, y_train):\n",
    "#     meta_updates = []\n",
    "#     accuracy_over_time = []\n",
    "#     for meta_update in range(num_meta_updates):\n",
    "#         # Sample a meta-batch of tasks\n",
    "#         meta_batch_indices = torch.randperm(len(x_train))[:meta_batch_size]\n",
    "\n",
    "#         # Inner loop updates for each task\n",
    "#         for task_index in meta_batch_indices:\n",
    "#             task_data = (\n",
    "#                 x_train[task_index : task_index + inner_batch_size],\n",
    "#                 y_train[task_index : task_index + inner_batch_size],\n",
    "#             )\n",
    "\n",
    "#             # Create a copy of the model for the inner loop updates\n",
    "#             inner_model = deepcopy(model)\n",
    "#             inner_model.load_state_dict(model.state_dict())\n",
    "\n",
    "#             for inner_update in range(num_inner_updates):\n",
    "#                 # Perform inner loop update on the task-specific model\n",
    "#                 inner_model.train_step(task_data)\n",
    "\n",
    "#             # Update the original model with the adapted weights\n",
    "#             model.load_state_dict(inner_model.state_dict())\n",
    "\n",
    "#         # Evaluate on the meta-test set\n",
    "#         _, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "#         # Store the meta-update step and accuracy\n",
    "#         meta_updates.append(meta_update + 1)\n",
    "#         accuracy_over_time.append(accuracy)\n",
    "\n",
    "#     avg_accuracy = sum(accuracy_over_time) / len(accuracy_over_time)\n",
    "#     return model, avg_accuracy\n",
    "\n",
    "\n",
    "# def generate_diffie_hellman_parameters():\n",
    "#     parameters = dh.generate_parameters(generator=2, key_size=512)\n",
    "#     return parameters\n",
    "\n",
    "\n",
    "# def generate_diffie_hellman_keys(parameters):\n",
    "#     private_key = parameters.generate_private_key()\n",
    "#     public_key = private_key.public_key()\n",
    "#     return private_key, public_key\n",
    "\n",
    "\n",
    "# def derive_key(private_key, peer_public_key):\n",
    "#     shared_key = private_key.exchange(peer_public_key)\n",
    "#     derived_key = HKDF(\n",
    "#         algorithm=hashes.SHA256(),\n",
    "#         length=32,\n",
    "#         salt=None,\n",
    "#         info=b\"handshake data\",\n",
    "#     ).derive(shared_key)\n",
    "#     return derived_key\n",
    "\n",
    "\n",
    "# def encrypt_message_AES(key, message):\n",
    "#     serialized_obj = pickle.dumps(message)\n",
    "#     cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "#     encryptor = cipher.encryptor()\n",
    "#     padded_obj = serialized_obj + b\" \" * (16 - len(serialized_obj) % 16)\n",
    "#     ciphertext = encryptor.update(padded_obj) + encryptor.finalize()\n",
    "#     return ciphertext\n",
    "\n",
    "\n",
    "# def decrypt_message_AES(key, ciphertext):\n",
    "#     cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "#     decryptor = cipher.decryptor()\n",
    "#     padded_obj = decryptor.update(ciphertext) + decryptor.finalize()\n",
    "#     serialized_obj = padded_obj.rstrip(b\" \")\n",
    "#     obj = pickle.loads(serialized_obj)\n",
    "#     return obj\n",
    "\n",
    "\n",
    "# def setup_AES():\n",
    "#     num_clients = len(clients)\n",
    "#     parameters = generate_diffie_hellman_parameters()\n",
    "#     server_private_key, server_public_key = generate_diffie_hellman_keys(parameters)\n",
    "#     client_keys = [generate_diffie_hellman_keys(parameters) for _ in range(num_clients)]\n",
    "#     shared_keys = [\n",
    "#         derive_key(server_private_key, client_public_key)\n",
    "#         for _, client_public_key in client_keys\n",
    "#     ]\n",
    "#     client_shared_keys = [\n",
    "#         derive_key(client_private_key, server_public_key)\n",
    "#         for client_private_key, _ in client_keys\n",
    "#     ]\n",
    "\n",
    "#     return client_keys, shared_keys, client_shared_keys\n",
    "\n",
    "\n",
    "# def encrypt_wt(wtarray, i):\n",
    "#     cwt = []\n",
    "#     for layer in wtarray:\n",
    "#         flat_array = layer.astype(np.float64).flatten()\n",
    "#         chunks = np.array_split(flat_array, (len(flat_array) + 2 ** 10 - 1) // 2 ** 10)\n",
    "#         clayer = []\n",
    "#         for chunk in chunks:\n",
    "#             ptxt = HE.encodeFrac(chunk)\n",
    "#             ctxt = HE.encryptPtxt(ptxt)\n",
    "#             clayer.append(ctxt)\n",
    "#         cwt.append(clayer.copy())\n",
    "#     ciphertext = encrypt_message_AES(client_shared_keys[i], cwt)\n",
    "#     return ciphertext\n",
    "\n",
    "\n",
    "# def aggregate_wt(encrypted_cwts):\n",
    "#     cwts = []\n",
    "#     for i, ecwt in enumerate(encrypted_cwts):\n",
    "#         cwts.append(decrypt_message_AES(shared_keys[i], ecwt))\n",
    "#     resmodel = []\n",
    "#     for j in range(len(cwts[0])):  # for layers\n",
    "#         layer = []\n",
    "#         for k in range(len(cwts[0][j])):  # for chunks\n",
    "#             tmp = cwts[0][j][k].copy()\n",
    "#             for i in range(1, len(cwts)):  # for clients\n",
    "#                 tmp = tmp + cwts[i][j][k]\n",
    "#             tmp = tmp / len(cwts)\n",
    "#             layer.append(tmp)\n",
    "#         resmodel.append(layer)\n",
    "\n",
    "#     res = [resmodel.copy() for _ in range(len(clients))]\n",
    "#     return res\n",
    "\n",
    "\n",
    "# def decrypt_weights(res):\n",
    "#     decrypted_weights = []\n",
    "#     for client_weights, model in zip(res, models):\n",
    "#         decrypted_client_weights = []\n",
    "#         wtarray = model.get_weights()\n",
    "#         for layer_weights, layer in zip(client_weights, wtarray):\n",
    "#             decrypted_layer_weights = []\n",
    "#             flat_array = layer.astype(np.float64).flatten()\n",
    "#             chunks = np.array_split(flat_array, (len(flat_array) + 2 ** 10 - 1) // 2 ** 10)\n",
    "#             for chunk, encrypted_chunk in zip(chunks, layer_weights):\n",
    "#                 decrypted_chunk = HE.decryptFrac(encrypted_chunk)\n",
    "#                 original_chunk_size = len(chunk)\n",
    "#                 decrypted_chunk = decrypted_chunk[:original_chunk_size]\n",
    "#                 decrypted_layer_weights.append(decrypted_chunk)\n",
    "#             decrypted_layer_weights = np.concatenate(decrypted_layer_weights, axis=0)\n",
    "#             decrypted_layer_weights = decrypted_layer_weights.reshape(layer.shape)\n",
    "#             decrypted_client_weights.append(decrypted_layer_weights)\n",
    "#         decrypted_weights.append(decrypted_client_weights)\n",
    "#     return decrypted_weights\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     epoch = 60000\n",
    "#     n_way = 5\n",
    "#     k_spt = 1\n",
    "#     k_qry = 15\n",
    "#     imgsz = 84\n",
    "#     imgc = 3\n",
    "#     task_num = 4\n",
    "#     meta_lr = 1e-3\n",
    "#     update_lr = 0.01\n",
    "#     update_step = 5\n",
    "#     update_step_test = 10\n",
    "\n",
    "#     # Set the paths to your mini-imagenet dataset\n",
    "#     root = \"./mini-imagenet\"\n",
    "\n",
    "#     torch.manual_seed(222)\n",
    "#     torch.cuda.manual_seed_all(222)\n",
    "#     np.random.seed(222)\n",
    "\n",
    "#     config = [\n",
    "#         (\"conv2d\", [32, 3, 3, 3, 1, 0]),\n",
    "#         (\"relu\", [True]),\n",
    "#         (\"bn\", [32]),\n",
    "#         (\"max_pool2d\", [2, 2, 0]),\n",
    "#         (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "#         (\"relu\", [True]),\n",
    "#         (\"bn\", [32]),\n",
    "#         (\"max_pool2d\", [2, 2, 0]),\n",
    "#         (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "#         (\"relu\", [True]),\n",
    "#         (\"bn\", [32]),\n",
    "#         (\"max_pool2d\", [2, 2, 0]),\n",
    "#         (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "#         (\"relu\", [True]),\n",
    "#         (\"bn\", [32]),\n",
    "#         (\"max_pool2d\", [2, 1, 0]),\n",
    "#         (\"flatten\", []),\n",
    "#         (\"linear\", [n_way, 32 * 5 * 5]),\n",
    "#     ]\n",
    "\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     maml = Meta(\n",
    "#         n_way,\n",
    "#         k_spt,\n",
    "#         k_qry,\n",
    "#         task_num,\n",
    "#         update_step,\n",
    "#         update_step_test,\n",
    "#         update_lr,\n",
    "#         meta_lr,\n",
    "#         config,\n",
    "#         imgc,\n",
    "#         imgsz,\n",
    "#     ).to(device)\n",
    "\n",
    "#     tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "#     num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "#     print(maml)\n",
    "#     print(\"Total trainable tensors:\", num)\n",
    "\n",
    "#     # batchsz here means total episode number\n",
    "#     mini = MiniImagenet(\n",
    "#         root,\n",
    "#         mode=\"train\",\n",
    "#         n_way=n_way,\n",
    "#         k_shot=k_spt,\n",
    "#         k_query=k_qry,\n",
    "#         batchsz=10000,\n",
    "#         resize=imgsz,\n",
    "#     )\n",
    "#     mini_test = MiniImagenet(\n",
    "#         root,\n",
    "#         mode=\"test\",\n",
    "#         n_way=n_way,\n",
    "#         k_shot=k_spt,\n",
    "#         k_query=k_qry,\n",
    "#         batchsz=100,\n",
    "#         resize=imgsz,\n",
    "#     )\n",
    "\n",
    "#     # Load the MNIST dataset\n",
    "#     (x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "#     # Preprocess the data\n",
    "#     x_train_all = x_train_all.astype(np.float32) / 255.0\n",
    "#     x_test = x_test.astype(np.float32) / 255.0\n",
    "\n",
    "#     # Split data into n parts\n",
    "#     X_train, _, y_train, _ = train_test_split(\n",
    "#         x_train_all, y_train_all, test_size=0.2, random_state=42\n",
    "#     )\n",
    "#     n_parts = len(clients)\n",
    "#     part_size = len(X_train) // n_parts\n",
    "#     dataset_parts = []\n",
    "#     for i in range(n_parts):\n",
    "#         start = i * part_size\n",
    "#         end = (i + 1) * part_size\n",
    "#         X_part = X_train[start:end]\n",
    "#         y_part = y_train[start:end]\n",
    "#         dataset_parts.append((X_part, y_part))\n",
    "\n",
    "#     models = [maml for _ in range(len(clients))]\n",
    "\n",
    "#     HE = Pyfhel()\n",
    "#     ckks_params = {\n",
    "#         \"scheme\": \"CKKS\",\n",
    "#         \"n\": 2 ** 14,\n",
    "#         \"scale\": 2 ** 30,\n",
    "#         \"qi_sizes\": [60, 30, 30, 30, 60],\n",
    "#     }\n",
    "#     HE.contextGen(**ckks_params)\n",
    "#     HE.keyGen()\n",
    "#     HE.rotateKeyGen()\n",
    "\n",
    "#     client_keys, shared_keys, client_shared_keys = setup_AES()\n",
    "\n",
    "#     accuracies = [[] for _ in range(len(clients))]\n",
    "#     losses = [[] for _ in range(len(clients))]\n",
    "\n",
    "#     meta_batch_size = 32  # Number of tasks per meta-update\n",
    "#     inner_batch_size = 5  # Number of examples per task\n",
    "#     num_inner_updates = 5  # Number of inner loop updates per task\n",
    "#     num_meta_updates = 100\n",
    "\n",
    "#     cwts = [encrypt_wt(model.get_weights(), i) for i, model in enumerate(models)]\n",
    "#     for e in tqdm(range(epoch)):\n",
    "#         cwts = aggregate_wt(cwts)\n",
    "#         wts = decrypt_weights(cwts)\n",
    "#         cwts = []\n",
    "#         for wt, model, dataset, i in zip(wts, models, dataset_parts, range(len(clients))):\n",
    "#             model.set_weights(wt)\n",
    "#             model, accuracy = train_model(model, dataset[0], dataset[1])\n",
    "#             accuracies[i].append(accuracy)\n",
    "#             print(\"Accuracies\", accuracy)\n",
    "#             wtarray = model.get_weights()\n",
    "#             cwts.append(encrypt_wt(wtarray, i))\n",
    "\n",
    "#     import matplotlib.pyplot as plt\n",
    "\n",
    "#     epochs_range = range(1, epoch + 1)\n",
    "\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     for i, client in enumerate(clients):\n",
    "#         plt.plot(\n",
    "#             epochs_range,\n",
    "#             accuracies[i],\n",
    "#             label=f\"Client {client}\" if client != 0 else \"Aggregate\",\n",
    "#         )\n",
    "#     plt.xlabel(\"Epochs\")\n",
    "#     plt.ylabel(\"Accuracy\")\n",
    "#     plt.legend()\n",
    "#     plt.title(\"Accuracy for Each Client\")\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     for i, client in enumerate(clients):\n",
    "#         plt.plot(\n",
    "#             epochs_range, losses[i], label=f\"Client {client}\" if client != 0 else \"Aggregate\"\n",
    "#         )\n",
    "#     plt.xlabel(\"Epochs\")\n",
    "#     plt.ylabel(\"Loss\")\n",
    "#     plt.legend()\n",
    "#     plt.title(\"Loss for Each Client\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "# ```\n",
    "\n",
    "# This code combines the PyTorch model with MAML and includes the rest of the code for data loading, encryption, decryption, and aggregation. The `train_model` function has been updated to work with the PyTorch model.\n",
    "\n",
    "# Please note that you may need to adjust the paths and settings according to your specific dataset and requirements. Also, make sure you have the necessary dependencies installed, such as PyTorch, NumPy, Pyfhel, and cryptography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta(\n",
      "  (net): Learner(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 32x3x3x3 (cuda:0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (2): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (3): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (4): Parameter containing: [torch.float32 of size 32x32x3x3 (cuda:0)]\n",
      "        (5): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (6): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (7): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (8): Parameter containing: [torch.float32 of size 32x32x3x3 (cuda:0)]\n",
      "        (9): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (10): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (11): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (12): Parameter containing: [torch.float32 of size 32x32x3x3 (cuda:0)]\n",
      "        (13): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (14): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (15): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (16): Parameter containing: [torch.float32 of size 5x800 (cuda:0)]\n",
      "        (17): Parameter containing: [torch.float32 of size 5 (cuda:0)]\n",
      "    )\n",
      "    (vars_bn): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (2): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (3): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (4): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (5): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (6): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (7): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 32901\n",
      "shuffle DB :train, b:10000, 5-way, 1-shot, 15-query, resize:84\n",
      "shuffle DB :test, b:100, 5-way, 1-shot, 15-query, resize:84\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 703\u001b[0m\n\u001b[1;32m    699\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 703\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 613\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    602\u001b[0m mini_test \u001b[38;5;241m=\u001b[39m MiniImagenet(\n\u001b[1;32m    603\u001b[0m     root,\n\u001b[1;32m    604\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    609\u001b[0m     resize\u001b[38;5;241m=\u001b[39mimgsz,\n\u001b[1;32m    610\u001b[0m )\n\u001b[1;32m    612\u001b[0m \u001b[38;5;66;03m# Load the MNIST dataset\u001b[39;00m\n\u001b[0;32m--> 613\u001b[0m (x_train_all, y_train_all), (x_test, y_test) \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mmnist\u001b[38;5;241m.\u001b[39mload_data()\n\u001b[1;32m    615\u001b[0m \u001b[38;5;66;03m# Preprocess the data\u001b[39;00m\n\u001b[1;32m    616\u001b[0m x_train_all \u001b[38;5;241m=\u001b[39m x_train_all\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.primitives.asymmetric import dh\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Pyfhel import Pyfhel\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "HE = Pyfhel()\n",
    "ckks_params = {\n",
    "    \"scheme\": \"CKKS\",\n",
    "    \"n\": 2**14,\n",
    "    \"scale\": 2**30,\n",
    "    \"qi_sizes\": [60, 30, 30, 30, 60],\n",
    "}\n",
    "HE.contextGen(**ckks_params)\n",
    "HE.keyGen()\n",
    "HE.rotateKeyGen()\n",
    "\n",
    "\n",
    "\n",
    "class MiniImagenet(Dataset):\n",
    "   def __init__(self, root, mode, batchsz, n_way, k_shot, k_query, resize, startidx=0):\n",
    "       self.batchsz = batchsz\n",
    "       self.n_way = n_way\n",
    "       self.k_shot = k_shot\n",
    "       self.k_query = k_query\n",
    "       self.setsz = self.n_way * self.k_shot\n",
    "       self.querysz = self.n_way * self.k_query\n",
    "       self.resize = resize\n",
    "       self.startidx = startidx\n",
    "       print(\n",
    "           \"shuffle DB :%s, b:%d, %d-way, %d-shot, %d-query, resize:%d\"\n",
    "           % (mode, batchsz, n_way, k_shot, k_query, resize)\n",
    "       )\n",
    "\n",
    "       if mode == \"train\":\n",
    "           self.transform = transforms.Compose(\n",
    "               [\n",
    "                   lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                   transforms.Resize((self.resize, self.resize)),\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "               ]\n",
    "           )\n",
    "       else:\n",
    "           self.transform = transforms.Compose(\n",
    "               [\n",
    "                   lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                   transforms.Resize((self.resize, self.resize)),\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "               ]\n",
    "           )\n",
    "\n",
    "       self.path = os.path.join(root, \"images\")\n",
    "       csvdata = self.loadCSV(os.path.join(root, mode + \".csv\"))\n",
    "       self.data = []\n",
    "       self.img2label = {}\n",
    "       for i, (k, v) in enumerate(csvdata.items()):\n",
    "           self.data.append(v)\n",
    "           self.img2label[k] = i + self.startidx\n",
    "       self.cls_num = len(self.data)\n",
    "\n",
    "       self.create_batch(self.batchsz)\n",
    "\n",
    "   def loadCSV(self, csvf):\n",
    "       dictLabels = {}\n",
    "       with open(csvf) as csvfile:\n",
    "           csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "           next(csvreader, None)\n",
    "           for i, row in enumerate(csvreader):\n",
    "               filename = row[0]\n",
    "               label = row[1]\n",
    "               if label in dictLabels.keys():\n",
    "                   dictLabels[label].append(filename)\n",
    "               else:\n",
    "                   dictLabels[label] = [filename]\n",
    "       return dictLabels\n",
    "\n",
    "   def create_batch(self, batchsz):\n",
    "       self.support_x_batch = []\n",
    "       self.query_x_batch = []\n",
    "       for b in range(batchsz):\n",
    "           selected_cls = np.random.choice(self.cls_num, self.n_way, False)\n",
    "           np.random.shuffle(selected_cls)\n",
    "           support_x = []\n",
    "           query_x = []\n",
    "           for cls in selected_cls:\n",
    "               selected_imgs_idx = np.random.choice(\n",
    "                   len(self.data[cls]), self.k_shot + self.k_query, False\n",
    "               )\n",
    "               np.random.shuffle(selected_imgs_idx)\n",
    "               indexDtrain = np.array(selected_imgs_idx[: self.k_shot])\n",
    "               indexDtest = np.array(selected_imgs_idx[self.k_shot :])\n",
    "               support_x.append(np.array(self.data[cls])[indexDtrain].tolist())\n",
    "               query_x.append(np.array(self.data[cls])[indexDtest].tolist())\n",
    "\n",
    "           random.shuffle(support_x)\n",
    "           random.shuffle(query_x)\n",
    "\n",
    "           self.support_x_batch.append(support_x)\n",
    "           self.query_x_batch.append(query_x)\n",
    "\n",
    "   def __getitem__(self, index):\n",
    "       support_x = torch.FloatTensor(self.setsz, 3, self.resize, self.resize)\n",
    "       support_y = np.zeros((self.setsz), dtype=np.int32)\n",
    "       query_x = torch.FloatTensor(self.querysz, 3, self.resize, self.resize)\n",
    "       query_y = np.zeros((self.querysz), dtype=np.int32)\n",
    "\n",
    "       flatten_support_x = [\n",
    "           os.path.join(self.path, item)\n",
    "           for sublist in self.support_x_batch[index]\n",
    "           for item in sublist\n",
    "       ]\n",
    "       support_y = np.array(\n",
    "           [\n",
    "               self.img2label[item[:9]]\n",
    "               for sublist in self.support_x_batch[index]\n",
    "               for item in sublist\n",
    "           ]\n",
    "       ).astype(np.int32)\n",
    "\n",
    "       flatten_query_x = [\n",
    "           os.path.join(self.path, item)\n",
    "           for sublist in self.query_x_batch[index]\n",
    "           for item in sublist\n",
    "       ]\n",
    "       query_y = np.array(\n",
    "           [\n",
    "               self.img2label[item[:9]]\n",
    "               for sublist in self.query_x_batch[index]\n",
    "               for item in sublist\n",
    "           ]\n",
    "       ).astype(np.int32)\n",
    "\n",
    "       unique = np.unique(support_y)\n",
    "       random.shuffle(unique)\n",
    "       support_y_relative = np.zeros(self.setsz)\n",
    "       query_y_relative = np.zeros(self.querysz)\n",
    "       for idx, l in enumerate(unique):\n",
    "           support_y_relative[support_y == l] = idx\n",
    "           query_y_relative[query_y == l] = idx\n",
    "\n",
    "       for i, path in enumerate(flatten_support_x):\n",
    "           support_x[i] = self.transform(path)\n",
    "\n",
    "       for i, path in enumerate(flatten_query_x):\n",
    "           query_x[i] = self.transform(path)\n",
    "\n",
    "       return (\n",
    "           support_x,\n",
    "           torch.LongTensor(support_y_relative),\n",
    "           query_x,\n",
    "           torch.LongTensor(query_y_relative),\n",
    "       )\n",
    "\n",
    "   def __len__(self):\n",
    "       return self.batchsz\n",
    "\n",
    "\n",
    "class Learner(nn.Module):\n",
    "   def __init__(self, config, imgc, imgsz):\n",
    "       super(Learner, self).__init__()\n",
    "       self.config = config\n",
    "       self.vars = nn.ParameterList()\n",
    "       self.vars_bn = nn.ParameterList()\n",
    "\n",
    "       for i, (name, param) in enumerate(self.config):\n",
    "           if name == \"conv2d\":\n",
    "               w = nn.Parameter(torch.ones(*param[:4]))\n",
    "               torch.nn.init.kaiming_normal_(w)\n",
    "               self.vars.append(w)\n",
    "               self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "           elif name == \"linear\":\n",
    "               w = nn.Parameter(torch.ones(*param))\n",
    "               torch.nn.init.kaiming_normal_(w)\n",
    "               self.vars.append(w)\n",
    "               self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "           elif name == \"bn\":\n",
    "               w = nn.Parameter(torch.ones(param[0]))\n",
    "               self.vars.append(w)\n",
    "               self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "               running_mean = nn.Parameter(torch.zeros(param[0]), requires_grad=False)\n",
    "               running_var = nn.Parameter(torch.ones(param[0]), requires_grad=False)\n",
    "               self.vars_bn.extend([running_mean, running_var])\n",
    "\n",
    "   def forward(self, x, vars=None, bn_training=True):\n",
    "       if vars is None:\n",
    "           vars = self.vars\n",
    "\n",
    "       idx = 0\n",
    "       bn_idx = 0\n",
    "       for name, param in self.config:\n",
    "           if name == \"conv2d\":\n",
    "               w, b = vars[idx], vars[idx + 1]\n",
    "               x = F.conv2d(x, w, b, stride=param[4], padding=param[5])\n",
    "               idx += 2\n",
    "           elif name == \"linear\":\n",
    "               w, b = vars[idx], vars[idx + 1]\n",
    "               x = F.linear(x, w, b)\n",
    "               idx += 2\n",
    "           elif name == \"bn\":\n",
    "               w, b = vars[idx], vars[idx + 1]\n",
    "               running_mean, running_var = (\n",
    "                   self.vars_bn[bn_idx],\n",
    "                   self.vars_bn[bn_idx + 1],\n",
    "               )\n",
    "               x = F.batch_norm(\n",
    "                   x, running_mean, running_var, weight=w, bias=b, training=bn_training\n",
    "               )\n",
    "               idx += 2\n",
    "               bn_idx += 2\n",
    "           elif name == \"flatten\":\n",
    "               x = x.view(x.size(0), -1)\n",
    "           elif name == \"relu\":\n",
    "               x = F.relu(x, inplace=param[0])\n",
    "           elif name == \"max_pool2d\":\n",
    "               x = F.max_pool2d(x, param[0], param[1], param[2])\n",
    "\n",
    "       assert idx == len(vars)\n",
    "       assert bn_idx == len(self.vars_bn)\n",
    "\n",
    "       return x\n",
    "\n",
    "   def parameters(self):\n",
    "       return self.vars\n",
    "\n",
    "\n",
    "class Meta(nn.Module):\n",
    "    def __init__(\n",
    "       self,\n",
    "       n_way,\n",
    "       k_spt,\n",
    "       k_qry,\n",
    "       task_num,\n",
    "       update_step,\n",
    "       update_step_test,\n",
    "       update_lr,\n",
    "       meta_lr,\n",
    "       config,\n",
    "       imgc,\n",
    "       imgsz,\n",
    "   ):\n",
    "        super(Meta, self).__init__()\n",
    "        self.n_way = n_way\n",
    "        self.k_spt = k_spt\n",
    "        self.k_qry = k_qry\n",
    "        self.task_num = task_num\n",
    "        self.update_step = update_step\n",
    "        self.update_step_test = update_step_test\n",
    "        self.update_lr = update_lr\n",
    "        self.meta_lr = meta_lr\n",
    "        self.config = config\n",
    "        self.imgc = imgc\n",
    "        self.imgsz = imgsz\n",
    "\n",
    "        self.net = Learner(config, imgc, imgsz)\n",
    "        self.meta_optim = optim.Adam(self.net.parameters(), lr=meta_lr)\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        task_num = x_spt.size(0)\n",
    "        querysz = x_qry.size(1)\n",
    "\n",
    "        losses_q = [0 for _ in range(self.update_step + 1)]\n",
    "        corrects = [0 for _ in range(self.update_step + 1)]\n",
    "\n",
    "        for i in range(task_num):\n",
    "            logits = self.net(x_spt[i], vars=None, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt[i])\n",
    "            grad = torch.autograd.grad(loss, self.net.parameters())\n",
    "            fast_weights = list(\n",
    "               map(\n",
    "                   lambda p: p[1] - self.update_lr * p[0],\n",
    "                   zip(grad, self.net.parameters()),\n",
    "               )\n",
    "           )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[0] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[0] = corrects[0] + correct\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[1] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[1] = corrects[1] + correct\n",
    "\n",
    "            for k in range(1, self.update_step):\n",
    "                logits = self.net(x_spt[i], fast_weights, bn_training=True)\n",
    "                loss = F.cross_entropy(logits, y_spt[i])\n",
    "                grad = torch.autograd.grad(loss, fast_weights)\n",
    "                fast_weights = list(\n",
    "                   map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights))\n",
    "               )\n",
    "\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[k + 1] += loss_q\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                    corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "        loss_q = losses_q[-1] / task_num\n",
    "        self.meta_optim.zero_grad()\n",
    "        loss_q.backward()\n",
    "        self.meta_optim.step()\n",
    "\n",
    "        accs = np.array(corrects) / (querysz * task_num)\n",
    "        return accs\n",
    "\n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        assert len(x_spt.shape) == 4\n",
    "        querysz = x_qry.size(0)\n",
    "        corrects = [0 for _ in range(self.update_step_test + 1)]\n",
    "        net = deepcopy(self.net)\n",
    "\n",
    "        logits = net(x_spt)\n",
    "        loss = F.cross_entropy(logits, y_spt)\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        fast_weights = list(\n",
    "           map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters()))\n",
    "       )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, net.parameters(), bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[0] = corrects[0] + correct\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[1] = corrects[1] + correct\n",
    "\n",
    "        for k in range(1, self.update_step_test):\n",
    "            logits = net(x_spt, fast_weights, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt)\n",
    "            grad = torch.autograd.grad(loss, fast_weights)\n",
    "            fast_weights = list(\n",
    "                map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights))\n",
    "            )\n",
    "\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "                corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "        del net\n",
    "        accs = np.array(corrects) / querysz\n",
    "        return accs\n",
    "\n",
    "\n",
    "def train_model(model, x_train, y_train):\n",
    "    meta_updates = []\n",
    "    accuracy_over_time = []\n",
    "    for meta_update in range(num_meta_updates):\n",
    "        # Sample a meta-batch of tasks\n",
    "        meta_batch_indices = torch.randperm(len(x_train))[:meta_batch_size]\n",
    "\n",
    "        # Inner loop updates for each task\n",
    "        for task_index in meta_batch_indices:\n",
    "            task_data = (\n",
    "                x_train[task_index : task_index + inner_batch_size],\n",
    "                y_train[task_index : task_index + inner_batch_size],\n",
    "            )\n",
    "\n",
    "            # Create a copy of the model for the inner loop updates\n",
    "            inner_model = deepcopy(model)\n",
    "            inner_model.load_state_dict(model.state_dict())\n",
    "\n",
    "            for inner_update in range(num_inner_updates):\n",
    "                # Perform inner loop update on the task-specific model\n",
    "                inner_model.train_step(task_data)\n",
    "\n",
    "            # Update the original model with the adapted weights\n",
    "            model.load_state_dict(inner_model.state_dict())\n",
    "\n",
    "        # Evaluate on the meta-test set\n",
    "        _, accuracy = model.evaluate(x_test, y_test)\n",
    "\n",
    "        # Store the meta-update step and accuracy\n",
    "        meta_updates.append(meta_update + 1)\n",
    "        accuracy_over_time.append(accuracy)\n",
    "\n",
    "    avg_accuracy = sum(accuracy_over_time) / len(accuracy_over_time)\n",
    "    return model, avg_accuracy\n",
    "\n",
    "\n",
    "def generate_diffie_hellman_parameters():\n",
    "    parameters = dh.generate_parameters(generator=2, key_size=512)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def generate_diffie_hellman_keys(parameters):\n",
    "    private_key = parameters.generate_private_key()\n",
    "    public_key = private_key.public_key()\n",
    "    return private_key, public_key\n",
    "\n",
    "\n",
    "def derive_key(private_key, peer_public_key):\n",
    "    shared_key = private_key.exchange(peer_public_key)\n",
    "    derived_key = HKDF(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32,\n",
    "        salt=None,\n",
    "        info=b\"handshake data\",\n",
    "    ).derive(shared_key)\n",
    "    return derived_key\n",
    "\n",
    "\n",
    "def encrypt_message_AES(key, message):\n",
    "    serialized_obj = pickle.dumps(message)\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    encryptor = cipher.encryptor()\n",
    "    padded_obj = serialized_obj + b\" \" * (16 - len(serialized_obj) % 16)\n",
    "    ciphertext = encryptor.update(padded_obj) + encryptor.finalize()\n",
    "    return ciphertext\n",
    "\n",
    "\n",
    "def decrypt_message_AES(key, ciphertext):\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    decryptor = cipher.decryptor()\n",
    "    padded_obj = decryptor.update(ciphertext) + decryptor.finalize()\n",
    "    serialized_obj = padded_obj.rstrip(b\" \")\n",
    "    obj = pickle.loads(serialized_obj)\n",
    "    return obj\n",
    "\n",
    "\n",
    "def setup_AES():\n",
    "    num_clients = len(clients)\n",
    "    parameters = generate_diffie_hellman_parameters()\n",
    "    server_private_key, server_public_key = generate_diffie_hellman_keys(parameters)\n",
    "    client_keys = [generate_diffie_hellman_keys(parameters) for _ in range(num_clients)]\n",
    "    shared_keys = [\n",
    "        derive_key(server_private_key, client_public_key)\n",
    "        for _, client_public_key in client_keys\n",
    "    ]\n",
    "    client_shared_keys = [\n",
    "        derive_key(client_private_key, server_public_key)\n",
    "        for client_private_key, _ in client_keys\n",
    "    ]\n",
    "\n",
    "    return client_keys, shared_keys, client_shared_keys\n",
    "\n",
    "\n",
    "def encrypt_wt(wtarray, i):\n",
    "    cwt = []\n",
    "    for layer in wtarray:\n",
    "        flat_array = layer.astype(np.float64).flatten()\n",
    "        chunks = np.array_split(flat_array, (len(flat_array) + 2**10 - 1) // 2**10)\n",
    "        clayer = []\n",
    "        for chunk in chunks:\n",
    "            ptxt = HE.encodeFrac(chunk)\n",
    "            ctxt = HE.encryptPtxt(ptxt)\n",
    "            clayer.append(ctxt)\n",
    "        cwt.append(clayer.copy())\n",
    "    ciphertext = encrypt_message_AES(client_shared_keys[i], cwt)\n",
    "    return ciphertext\n",
    "\n",
    "\n",
    "def aggregate_wt(encrypted_cwts):\n",
    "    cwts = []\n",
    "    for i, ecwt in enumerate(encrypted_cwts):\n",
    "        cwts.append(decrypt_message_AES(shared_keys[i], ecwt))\n",
    "    resmodel = []\n",
    "    for j in range(len(cwts[0])):  # for layers\n",
    "        layer = []\n",
    "        for k in range(len(cwts[0][j])):  # for chunks\n",
    "            tmp = cwts[0][j][k].copy()\n",
    "            for i in range(1, len(cwts)):  # for clients\n",
    "                tmp = tmp + cwts[i][j][k]\n",
    "            tmp = tmp / len(cwts)\n",
    "            layer.append(tmp)\n",
    "        resmodel.append(layer)\n",
    "\n",
    "    res = [resmodel.copy() for _ in range(len(clients))]\n",
    "    return res\n",
    "\n",
    "\n",
    "def decrypt_weights(res):\n",
    "    decrypted_weights = []\n",
    "    for client_weights, model in zip(res, models):\n",
    "        decrypted_client_weights = []\n",
    "        wtarray = model.get_weights()\n",
    "        for layer_weights, layer in zip(client_weights, wtarray):\n",
    "            decrypted_layer_weights = []\n",
    "            flat_array = layer.astype(np.float64).flatten()\n",
    "            chunks = np.array_split(flat_array, (len(flat_array) + 2**10 - 1) // 2**10)\n",
    "            for chunk, encrypted_chunk in zip(chunks, layer_weights):\n",
    "                decrypted_chunk = HE.decryptFrac(encrypted_chunk)\n",
    "                original_chunk_size = len(chunk)\n",
    "                decrypted_chunk = decrypted_chunk[:original_chunk_size]\n",
    "                decrypted_layer_weights.append(decrypted_chunk)\n",
    "            decrypted_layer_weights = np.concatenate(decrypted_layer_weights, axis=0)\n",
    "            decrypted_layer_weights = decrypted_layer_weights.reshape(layer.shape)\n",
    "            decrypted_client_weights.append(decrypted_layer_weights)\n",
    "        decrypted_weights.append(decrypted_client_weights)\n",
    "    return decrypted_weights\n",
    "\n",
    "\n",
    "def main():\n",
    "    epoch = 60000\n",
    "    n_way = 5\n",
    "    k_spt = 1\n",
    "    k_qry = 15\n",
    "    imgsz = 84\n",
    "    imgc = 3\n",
    "    task_num = 4\n",
    "    meta_lr = 1e-3\n",
    "    update_lr = 0.01\n",
    "    update_step = 5\n",
    "    update_step_test = 10\n",
    "\n",
    "    # Set the paths to your mini-imagenet dataset\n",
    "    root = \"./mini-imagenet\"\n",
    "\n",
    "    torch.manual_seed(222)\n",
    "    torch.cuda.manual_seed_all(222)\n",
    "    np.random.seed(222)\n",
    "\n",
    "    config = [\n",
    "        (\"conv2d\", [32, 3, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 1, 0]),\n",
    "        (\"flatten\", []),\n",
    "        (\"linear\", [n_way, 32 * 5 * 5]),\n",
    "    ]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    maml = Meta(\n",
    "        n_way,\n",
    "        k_spt,\n",
    "        k_qry,\n",
    "        task_num,\n",
    "        update_step,\n",
    "        update_step_test,\n",
    "        update_lr,\n",
    "        meta_lr,\n",
    "        config,\n",
    "        imgc,\n",
    "        imgsz,\n",
    "    ).to(device)\n",
    "\n",
    "    tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "    num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "    print(maml)\n",
    "    print(\"Total trainable tensors:\", num)\n",
    "\n",
    "    # batchsz here means total episode number\n",
    "    mini = MiniImagenet(\n",
    "        root,\n",
    "        mode=\"train\",\n",
    "        n_way=n_way,\n",
    "        k_shot=k_spt,\n",
    "        k_query=k_qry,\n",
    "        batchsz=10000,\n",
    "        resize=imgsz,\n",
    "    )\n",
    "    mini_test = MiniImagenet(\n",
    "        root,\n",
    "        mode=\"test\",\n",
    "        n_way=n_way,\n",
    "        k_shot=k_spt,\n",
    "        k_query=k_qry,\n",
    "        batchsz=100,\n",
    "        resize=imgsz,\n",
    "    )\n",
    "\n",
    "    # Load the MNIST dataset\n",
    "    (x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Preprocess the data\n",
    "    x_train_all = x_train_all.astype(np.float32) / 255.0\n",
    "    x_test = x_test.astype(np.float32) / 255.0\n",
    "\n",
    "    # Split data into n parts\n",
    "    X_train, _, y_train, _ = train_test_split(\n",
    "        x_train_all, y_train_all, test_size=0.2, random_state=42\n",
    "    )\n",
    "# Split data into n parts\n",
    "    # Split data into n parts\n",
    "    n_parts = len(clients)\n",
    "    dataset_parts = []\n",
    "    for i in range(n_parts):\n",
    "        train_loader = DataLoader(\n",
    "            mini, batch_size=task_num, shuffle=True, num_workers=1, pin_memory=True\n",
    "        )\n",
    "        dataset_parts.append(train_loader)\n",
    "\n",
    "    models = [maml for _ in range(len(clients))]\n",
    "\n",
    "    HE = Pyfhel()\n",
    "    ckks_params = {\n",
    "        \"scheme\": \"CKKS\",\n",
    "        \"n\": 2**14,\n",
    "        \"scale\": 2**30,\n",
    "        \"qi_sizes\": [60, 30, 30, 30, 60],\n",
    "    }\n",
    "    HE.contextGen(**ckks_params)\n",
    "    HE.keyGen()\n",
    "    HE.rotateKeyGen()\n",
    "\n",
    "    client_keys, shared_keys, client_shared_keys = setup_AES()\n",
    "\n",
    "    accuracies = [[] for _ in range(len(clients))]\n",
    "    losses = [[] for _ in range(len(clients))]\n",
    "\n",
    "    meta_batch_size = 32  # Number of tasks per meta-update\n",
    "    inner_batch_size = 5  # Number of examples per task\n",
    "    num_inner_updates = 5  # Number of inner loop updates per task\n",
    "    num_meta_updates = 100\n",
    "\n",
    "    cwts = [encrypt_wt(model.get_weights(), i) for i, model in enumerate(models)]\n",
    "    for e in tqdm(range(epoch)):\n",
    "        cwts = aggregate_wt(cwts)\n",
    "        wts = decrypt_weights(cwts)\n",
    "        cwts = []\n",
    "        for wt, model, dataset, i in zip(\n",
    "            wts, models, dataset_parts, range(len(clients))\n",
    "        ):\n",
    "            model.set_weights(wt)\n",
    "            model, accuracy = train_model(model, dataset[0], dataset[1])\n",
    "            accuracies[i].append(accuracy)\n",
    "            print(\"Accuracies\", accuracy)\n",
    "            wtarray = model.get_weights()\n",
    "            cwts.append(encrypt_wt(wtarray, i))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    epochs_range = range(1, epoch + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, client in enumerate(clients):\n",
    "        plt.plot(\n",
    "            epochs_range,\n",
    "            accuracies[i],\n",
    "            label=f\"Client {client}\" if client != 0 else \"Aggregate\",\n",
    "        )\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy for Each Client\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, client in enumerate(clients):\n",
    "        plt.plot(\n",
    "            epochs_range,\n",
    "            losses[i],\n",
    "            label=f\"Client {client}\" if client != 0 else \"Aggregate\",\n",
    "        )\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss for Each Client\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta(\n",
      "  (net): Learner(\n",
      "    (vars): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 32x3x3x3 (cuda:0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (2): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (3): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (4): Parameter containing: [torch.float32 of size 32x32x3x3 (cuda:0)]\n",
      "        (5): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (6): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (7): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (8): Parameter containing: [torch.float32 of size 32x32x3x3 (cuda:0)]\n",
      "        (9): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (10): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (11): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (12): Parameter containing: [torch.float32 of size 32x32x3x3 (cuda:0)]\n",
      "        (13): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (14): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (15): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (16): Parameter containing: [torch.float32 of size 5x800 (cuda:0)]\n",
      "        (17): Parameter containing: [torch.float32 of size 5 (cuda:0)]\n",
      "    )\n",
      "    (vars_bn): ParameterList(\n",
      "        (0): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (1): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (2): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (3): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (4): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (5): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (6): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "        (7): Parameter containing: [torch.float32 of size 32 (cuda:0)]\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Total trainable tensors: 32901\n",
      "shuffle DB :train, b:10000, 5-way, 1-shot, 15-query, resize:84\n",
      "shuffle DB :test, b:100, 5-way, 1-shot, 15-query, resize:84\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'client_shared_keys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 668\u001b[0m\n\u001b[1;32m    664\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 668\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 618\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    615\u001b[0m num_inner_updates \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Number of inner loop updates per task\u001b[39;00m\n\u001b[1;32m    616\u001b[0m num_meta_updates \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m--> 618\u001b[0m cwts \u001b[38;5;241m=\u001b[39m [encrypt_wt(model\u001b[38;5;241m.\u001b[39mstate_dict(), i) \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models)]\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epoch)):\n\u001b[1;32m    620\u001b[0m     cwts \u001b[38;5;241m=\u001b[39m aggregate_wt(cwts)\n",
      "Cell \u001b[0;32mIn[24], line 618\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m num_inner_updates \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m  \u001b[38;5;66;03m# Number of inner loop updates per task\u001b[39;00m\n\u001b[1;32m    616\u001b[0m num_meta_updates \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m--> 618\u001b[0m cwts \u001b[38;5;241m=\u001b[39m [\u001b[43mencrypt_wt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models)]\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epoch)):\n\u001b[1;32m    620\u001b[0m     cwts \u001b[38;5;241m=\u001b[39m aggregate_wt(cwts)\n",
      "Cell \u001b[0;32mIn[24], line 464\u001b[0m, in \u001b[0;36mencrypt_wt\u001b[0;34m(state_dict, i)\u001b[0m\n\u001b[1;32m    462\u001b[0m         clayer\u001b[38;5;241m.\u001b[39mappend(ctxt)\n\u001b[1;32m    463\u001b[0m     cwt[layer_name] \u001b[38;5;241m=\u001b[39m clayer\n\u001b[0;32m--> 464\u001b[0m ciphertext \u001b[38;5;241m=\u001b[39m encrypt_message_AES(\u001b[43mclient_shared_keys\u001b[49m[i], cwt)\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ciphertext\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client_shared_keys' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.primitives.asymmetric import dh\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "import pickle\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Pyfhel import Pyfhel\n",
    "\n",
    "clients = [0, 1, 2, 3]\n",
    "\n",
    "HE = Pyfhel()\n",
    "ckks_params = {\n",
    "    \"scheme\": \"CKKS\",\n",
    "    \"n\": 2**14,\n",
    "    \"scale\": 2**30,\n",
    "    \"qi_sizes\": [60, 30, 30, 30, 60],\n",
    "}\n",
    "HE.contextGen(**ckks_params)\n",
    "HE.keyGen()\n",
    "HE.rotateKeyGen()\n",
    "class MiniImagenet(Dataset):\n",
    "    def __init__(self, root, mode, batchsz, n_way, k_shot, k_query, resize, startidx=0):\n",
    "        self.batchsz = batchsz\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.k_query = k_query\n",
    "        self.setsz = self.n_way * self.k_shot\n",
    "        self.querysz = self.n_way * self.k_query\n",
    "        self.resize = resize\n",
    "        self.startidx = startidx\n",
    "        print(\n",
    "            \"shuffle DB :%s, b:%d, %d-way, %d-shot, %d-query, resize:%d\"\n",
    "            % (mode, batchsz, n_way, k_shot, k_query, resize)\n",
    "        )\n",
    "\n",
    "        if mode == \"train\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                    transforms.Resize((self.resize, self.resize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                    transforms.Resize((self.resize, self.resize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.path = os.path.join(root, \"images\")\n",
    "        csvdata = self.loadCSV(os.path.join(root, mode + \".csv\"))\n",
    "        self.data = []\n",
    "        self.img2label = {}\n",
    "        for i, (k, v) in enumerate(csvdata.items()):\n",
    "            self.data.append(v)\n",
    "            self.img2label[k] = i + self.startidx\n",
    "        self.cls_num = len(self.data)\n",
    "\n",
    "        self.create_batch(self.batchsz)\n",
    "\n",
    "    def loadCSV(self, csvf):\n",
    "        dictLabels = {}\n",
    "        with open(csvf) as csvfile:\n",
    "            csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "            next(csvreader, None)\n",
    "            for i, row in enumerate(csvreader):\n",
    "                filename = row[0]\n",
    "                label = row[1]\n",
    "                if label in dictLabels.keys():\n",
    "                    dictLabels[label].append(filename)\n",
    "                else:\n",
    "                    dictLabels[label] = [filename]\n",
    "        return dictLabels\n",
    "\n",
    "    def create_batch(self, batchsz):\n",
    "        self.support_x_batch = []\n",
    "        self.query_x_batch = []\n",
    "        for b in range(batchsz):\n",
    "            selected_cls = np.random.choice(self.cls_num, self.n_way, False)\n",
    "            np.random.shuffle(selected_cls)\n",
    "            support_x = []\n",
    "            query_x = []\n",
    "            for cls in selected_cls:\n",
    "                selected_imgs_idx = np.random.choice(\n",
    "                    len(self.data[cls]), self.k_shot + self.k_query, False\n",
    "                )\n",
    "                np.random.shuffle(selected_imgs_idx)\n",
    "                indexDtrain = np.array(selected_imgs_idx[: self.k_shot])\n",
    "                indexDtest = np.array(selected_imgs_idx[self.k_shot :])\n",
    "                support_x.append(np.array(self.data[cls])[indexDtrain].tolist())\n",
    "                query_x.append(np.array(self.data[cls])[indexDtest].tolist())\n",
    "\n",
    "            random.shuffle(support_x)\n",
    "            random.shuffle(query_x)\n",
    "\n",
    "            self.support_x_batch.append(support_x)\n",
    "            self.query_x_batch.append(query_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        support_x = torch.FloatTensor(self.setsz, 3, self.resize, self.resize)\n",
    "        support_y = np.zeros((self.setsz), dtype=np.int32)\n",
    "        query_x = torch.FloatTensor(self.querysz, 3, self.resize, self.resize)\n",
    "        query_y = np.zeros((self.querysz), dtype=np.int32)\n",
    "\n",
    "        flatten_support_x = [\n",
    "            os.path.join(self.path, item)\n",
    "            for sublist in self.support_x_batch[index]\n",
    "            for item in sublist\n",
    "        ]\n",
    "        support_y = np.array(\n",
    "            [\n",
    "                self.img2label[item[:9]]\n",
    "                for sublist in self.support_x_batch[index]\n",
    "                for item in sublist\n",
    "            ]\n",
    "        ).astype(np.int32)\n",
    "\n",
    "        flatten_query_x = [\n",
    "            os.path.join(self.path, item)\n",
    "            for sublist in self.query_x_batch[index]\n",
    "            for item in sublist\n",
    "        ]\n",
    "        query_y = np.array(\n",
    "            [\n",
    "                self.img2label[item[:9]]\n",
    "                for sublist in self.query_x_batch[index]\n",
    "                for item in sublist\n",
    "            ]\n",
    "        ).astype(np.int32)\n",
    "\n",
    "        unique = np.unique(support_y)\n",
    "        random.shuffle(unique)\n",
    "        support_y_relative = np.zeros(self.setsz)\n",
    "        query_y_relative = np.zeros(self.querysz)\n",
    "        for idx, l in enumerate(unique):\n",
    "            support_y_relative[support_y == l] = idx\n",
    "            query_y_relative[query_y == l] = idx\n",
    "\n",
    "        for i, path in enumerate(flatten_support_x):\n",
    "            support_x[i] = self.transform(path)\n",
    "\n",
    "        for i, path in enumerate(flatten_query_x):\n",
    "            query_x[i] = self.transform(path)\n",
    "\n",
    "        return (\n",
    "            support_x,\n",
    "            torch.LongTensor(support_y_relative),\n",
    "            query_x,\n",
    "            torch.LongTensor(query_y_relative),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batchsz\n",
    "\n",
    "\n",
    "class Learner(nn.Module):\n",
    "    def __init__(self, config, imgc, imgsz):\n",
    "        super(Learner, self).__init__()\n",
    "        self.config = config\n",
    "        self.vars = nn.ParameterList()\n",
    "        self.vars_bn = nn.ParameterList()\n",
    "\n",
    "        for i, (name, param) in enumerate(self.config):\n",
    "            if name == \"conv2d\":\n",
    "                w = nn.Parameter(torch.ones(*param[:4]))\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "            elif name == \"linear\":\n",
    "                w = nn.Parameter(torch.ones(*param))\n",
    "                torch.nn.init.kaiming_normal_(w)\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "            elif name == \"bn\":\n",
    "                w = nn.Parameter(torch.ones(param[0]))\n",
    "                self.vars.append(w)\n",
    "                self.vars.append(nn.Parameter(torch.zeros(param[0])))\n",
    "                running_mean = nn.Parameter(torch.zeros(param[0]), requires_grad=False)\n",
    "                running_var = nn.Parameter(torch.ones(param[0]), requires_grad=False)\n",
    "                self.vars_bn.extend([running_mean, running_var])\n",
    "\n",
    "    def forward(self, x, vars=None, bn_training=True):\n",
    "        if vars is None:\n",
    "            vars = self.vars\n",
    "\n",
    "        idx = 0\n",
    "        bn_idx = 0\n",
    "        for name, param in self.config:\n",
    "            if name == \"conv2d\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                x = F.conv2d(x, w, b, stride=param[4], padding=param[5])\n",
    "                idx += 2\n",
    "            elif name == \"linear\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                x = F.linear(x, w, b)\n",
    "                idx += 2\n",
    "            elif name == \"bn\":\n",
    "                w, b = vars[idx], vars[idx + 1]\n",
    "                running_mean, running_var = (\n",
    "                    self.vars_bn[bn_idx],\n",
    "                    self.vars_bn[bn_idx + 1],\n",
    "                )\n",
    "                x = F.batch_norm(\n",
    "                    x, running_mean, running_var, weight=w, bias=b, training=bn_training\n",
    "                )\n",
    "                idx += 2\n",
    "                bn_idx += 2\n",
    "            elif name == \"flatten\":\n",
    "                x = x.view(x.size(0), -1)\n",
    "            elif name == \"relu\":\n",
    "                x = F.relu(x, inplace=param[0])\n",
    "            elif name == \"max_pool2d\":\n",
    "                x = F.max_pool2d(x, param[0], param[1], param[2])\n",
    "\n",
    "        assert idx == len(vars)\n",
    "        assert bn_idx == len(self.vars_bn)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.vars\n",
    "\n",
    "\n",
    "class Meta(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_way,\n",
    "        k_spt,\n",
    "        k_qry,\n",
    "        task_num,\n",
    "        update_step,\n",
    "        update_step_test,\n",
    "        update_lr,\n",
    "        meta_lr,\n",
    "        config,\n",
    "        imgc,\n",
    "        imgsz,\n",
    "    ):\n",
    "        super(Meta, self).__init__()\n",
    "        self.n_way = n_way\n",
    "        self.k_spt = k_spt\n",
    "        self.k_qry = k_qry\n",
    "        self.task_num = task_num\n",
    "        self.update_step = update_step\n",
    "        self.update_step_test = update_step_test\n",
    "        self.update_lr = update_lr\n",
    "        self.meta_lr = meta_lr\n",
    "        self.config = config\n",
    "        self.imgc = imgc\n",
    "        self.imgsz = imgsz\n",
    "\n",
    "        self.net = Learner(config, imgc, imgsz)\n",
    "        self.meta_optim = optim.Adam(self.net.parameters(), lr=meta_lr)\n",
    "\n",
    "    def forward(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        task_num = x_spt.size(0)\n",
    "        querysz = x_qry.size(1)\n",
    "\n",
    "        losses_q = [0 for _ in range(self.update_step + 1)]\n",
    "        corrects = [0 for _ in range(self.update_step + 1)]\n",
    "\n",
    "        for i in range(task_num):\n",
    "            logits = self.net(x_spt[i], vars=None, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt[i])\n",
    "            grad = torch.autograd.grad(loss, self.net.parameters())\n",
    "            fast_weights = list(\n",
    "                map(\n",
    "                    lambda p: p[1] - self.update_lr * p[0],\n",
    "                    zip(grad, self.net.parameters()),\n",
    "                )\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], self.net.parameters(), bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[0] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[0] = corrects[0] + correct\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[1] += loss_q\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                corrects[1] = corrects[1] + correct\n",
    "\n",
    "            for k in range(1, self.update_step):\n",
    "                logits = self.net(x_spt[i], fast_weights, bn_training=True)\n",
    "                loss = F.cross_entropy(logits, y_spt[i])\n",
    "                grad = torch.autograd.grad(loss, fast_weights)\n",
    "                fast_weights = list(\n",
    "                    map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights))\n",
    "                )\n",
    "\n",
    "                logits_q = self.net(x_qry[i], fast_weights, bn_training=True)\n",
    "                loss_q = F.cross_entropy(logits_q, y_qry[i])\n",
    "                losses_q[k + 1] += loss_q\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                    correct = torch.eq(pred_q, y_qry[i]).sum().item()\n",
    "                    corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "        loss_q = losses_q[-1] / task_num\n",
    "        self.meta_optim.zero_grad()\n",
    "        loss_q.backward()\n",
    "        self.meta_optim.step()\n",
    "\n",
    "        accs = np.array(corrects) / (querysz * task_num)\n",
    "        return accs\n",
    "\n",
    "    def finetunning(self, x_spt, y_spt, x_qry, y_qry):\n",
    "        assert len(x_spt.shape) == 4\n",
    "        querysz = x_qry.size(0)\n",
    "        corrects = [0 for _ in range(self.update_step_test + 1)]\n",
    "        net = deepcopy(self.net)\n",
    "\n",
    "        logits = net(x_spt)\n",
    "        loss = F.cross_entropy(logits, y_spt)\n",
    "        grad = torch.autograd.grad(loss, net.parameters())\n",
    "        fast_weights = list(\n",
    "            map(lambda p: p[1] - self.update_lr * p[0], zip(grad, net.parameters()))\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, net.parameters(), bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[0] = corrects[0] + correct\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "            pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "            correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "            corrects[1] = corrects[1] + correct\n",
    "\n",
    "        for k in range(1, self.update_step_test):\n",
    "            logits = net(x_spt, fast_weights, bn_training=True)\n",
    "            loss = F.cross_entropy(logits, y_spt)\n",
    "            grad = torch.autograd.grad(loss, fast_weights)\n",
    "            fast_weights = list(\n",
    "                map(lambda p: p[1] - self.update_lr * p[0], zip(grad, fast_weights))\n",
    "            )\n",
    "\n",
    "            logits_q = net(x_qry, fast_weights, bn_training=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_q = F.softmax(logits_q, dim=1).argmax(dim=1)\n",
    "                correct = torch.eq(pred_q, y_qry).sum().item()\n",
    "                corrects[k + 1] = corrects[k + 1] + correct\n",
    "\n",
    "        del net\n",
    "        accs = np.array(corrects) / querysz\n",
    "        return accs\n",
    "\n",
    "\n",
    "def train_model(model, train_loader):\n",
    "    for meta_update in range(num_meta_updates):\n",
    "        # Sample a meta-batch of tasks\n",
    "        x_spt, y_spt, x_qry, y_qry = next(iter(train_loader))\n",
    "        x_spt, y_spt, x_qry, y_qry = (\n",
    "            x_spt.to(device),\n",
    "            y_spt.to(device),\n",
    "            x_qry.to(device),\n",
    "            y_qry.to(device),\n",
    "        )\n",
    "\n",
    "        # Perform meta-update\n",
    "        accs = model(x_spt, y_spt, x_qry, y_qry)\n",
    "\n",
    "    return model, accs[-1]\n",
    "\n",
    "\n",
    "def generate_diffie_hellman_parameters():\n",
    "    parameters = dh.generate_parameters(generator=2, key_size=512)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def generate_diffie_hellman_keys(parameters):\n",
    "    private_key = parameters.generate_private_key()\n",
    "    public_key = private_key.public_key()\n",
    "    return private_key, public_key\n",
    "\n",
    "\n",
    "def derive_key(private_key, peer_public_key):\n",
    "    shared_key = private_key.exchange(peer_public_key)\n",
    "    derived_key = HKDF(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32,\n",
    "        salt=None,\n",
    "        info=b\"handshake data\",\n",
    "    ).derive(shared_key)\n",
    "    return derived_key\n",
    "\n",
    "\n",
    "def encrypt_message_AES(key, message):\n",
    "    serialized_obj = pickle.dumps(message)\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    encryptor = cipher.encryptor()\n",
    "    padded_obj = serialized_obj + b\" \" * (16 - len(serialized_obj) % 16)\n",
    "    ciphertext = encryptor.update(padded_obj) + encryptor.finalize()\n",
    "    return ciphertext\n",
    "\n",
    "\n",
    "def decrypt_message_AES(key, ciphertext):\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    decryptor = cipher.decryptor()\n",
    "    padded_obj = decryptor.update(ciphertext) + decryptor.finalize()\n",
    "    serialized_obj = padded_obj.rstrip(b\" \")\n",
    "    obj = pickle.loads(serialized_obj)\n",
    "    return obj\n",
    "\n",
    "\n",
    "def setup_AES():\n",
    "    num_clients = len(clients)\n",
    "    parameters = generate_diffie_hellman_parameters()\n",
    "    server_private_key, server_public_key = generate_diffie_hellman_keys(parameters)\n",
    "    client_keys = [generate_diffie_hellman_keys(parameters) for _ in range(num_clients)]\n",
    "    shared_keys = [\n",
    "        derive_key(server_private_key, client_public_key)\n",
    "        for _, client_public_key in client_keys\n",
    "    ]\n",
    "    client_shared_keys = [\n",
    "        derive_key(client_private_key, server_public_key)\n",
    "        for client_private_key, _ in client_keys\n",
    "    ]\n",
    "\n",
    "    return client_keys, shared_keys, client_shared_keys\n",
    "\n",
    "\n",
    "def encrypt_wt(state_dict, i):\n",
    "    cwt = {}\n",
    "    for layer_name, layer_weights in state_dict.items():\n",
    "        flat_array = layer_weights.cpu().numpy().astype(np.float64).flatten()\n",
    "        chunks = np.array_split(flat_array, (len(flat_array) + 2**10 - 1) // 2**10)\n",
    "        clayer = []\n",
    "        for chunk in chunks:\n",
    "            ptxt = HE.encodeFrac(chunk)\n",
    "            ctxt = HE.encryptPtxt(ptxt)\n",
    "            clayer.append(ctxt)\n",
    "        cwt[layer_name] = clayer\n",
    "    ciphertext = encrypt_message_AES(client_shared_keys[i], cwt)\n",
    "    return ciphertext\n",
    "\n",
    "\n",
    "def aggregate_wt(encrypted_cwts):\n",
    "    cwts = []\n",
    "    for i, ecwt in enumerate(encrypted_cwts):\n",
    "        cwts.append(decrypt_message_AES(shared_keys[i], ecwt))\n",
    "\n",
    "    resmodel = {}\n",
    "    for layer_name in cwts[0].keys():  # for layers\n",
    "        layer = []\n",
    "        for k in range(len(cwts[0][layer_name])):  # for chunks\n",
    "            tmp = cwts[0][layer_name][k].copy()\n",
    "            for i in range(1, len(cwts)):  # for clients\n",
    "                tmp = tmp + cwts[i][layer_name][k]\n",
    "            tmp = tmp / len(cwts)\n",
    "            layer.append(tmp)\n",
    "        resmodel[layer_name] = layer\n",
    "\n",
    "    res = [resmodel.copy() for _ in range(len(clients))]\n",
    "    return res\n",
    "\n",
    "\n",
    "def decrypt_weights(res):\n",
    "    decrypted_weights = []\n",
    "    for client_weights, model in zip(res, models):\n",
    "        decrypted_client_weights = {}\n",
    "        for layer_name, layer_weights in client_weights.items():\n",
    "            decrypted_layer_weights = []\n",
    "            for encrypted_chunk in layer_weights:\n",
    "                decrypted_chunk = HE.decryptFrac(encrypted_chunk)\n",
    "                decrypted_layer_weights.append(decrypted_chunk)\n",
    "            decrypted_layer_weights = np.concatenate(decrypted_layer_weights, axis=0)\n",
    "            decrypted_layer_weights = torch.from_numpy(decrypted_layer_weights)\n",
    "            decrypted_client_weights[layer_name] = decrypted_layer_weights\n",
    "        decrypted_weights.append(decrypted_client_weights)\n",
    "    return decrypted_weights\n",
    "\n",
    "\n",
    "def main():\n",
    "    clients = [0, 1, 2, 3]\n",
    "    epoch = 60000\n",
    "    n_way = 5\n",
    "    k_spt = 1\n",
    "    k_qry = 15\n",
    "    imgsz = 84\n",
    "    imgc = 3\n",
    "    task_num = 4\n",
    "    meta_lr = 1e-3\n",
    "    update_lr = 0.01\n",
    "    update_step = 5\n",
    "    update_step_test = 10\n",
    "\n",
    "    # Set the paths to your mini-imagenet dataset\n",
    "    root = \"./mini-imagenet\"\n",
    "\n",
    "    torch.manual_seed(222)\n",
    "    torch.cuda.manual_seed_all(222)\n",
    "    np.random.seed(222)\n",
    "\n",
    "    config = [\n",
    "        (\"conv2d\", [32, 3, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 2, 0]),\n",
    "        (\"conv2d\", [32, 32, 3, 3, 1, 0]),\n",
    "        (\"relu\", [True]),\n",
    "        (\"bn\", [32]),\n",
    "        (\"max_pool2d\", [2, 1, 0]),\n",
    "        (\"flatten\", []),\n",
    "        (\"linear\", [n_way, 32 * 5 * 5]),\n",
    "    ]\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    maml = Meta(\n",
    "        n_way,\n",
    "        k_spt,\n",
    "        k_qry,\n",
    "        task_num,\n",
    "        update_step,\n",
    "        update_step_test,\n",
    "        update_lr,\n",
    "        meta_lr,\n",
    "        config,\n",
    "        imgc,\n",
    "        imgsz,\n",
    "    ).to(device)\n",
    "\n",
    "    tmp = filter(lambda x: x.requires_grad, maml.parameters())\n",
    "    num = sum(map(lambda x: np.prod(x.shape), tmp))\n",
    "    print(maml)\n",
    "    print(\"Total trainable tensors:\", num)\n",
    "\n",
    "    # batchsz here means total episode number\n",
    "    mini = MiniImagenet(\n",
    "        root,\n",
    "        mode=\"train\",\n",
    "        n_way=n_way,\n",
    "        k_shot=k_spt,\n",
    "        k_query=k_qry,\n",
    "        batchsz=10000,\n",
    "        resize=imgsz,\n",
    "    )\n",
    "    mini_test = MiniImagenet(\n",
    "        root,\n",
    "        mode=\"test\",\n",
    "        n_way=n_way,\n",
    "        k_shot=k_spt,\n",
    "        k_query=k_qry,\n",
    "        batchsz=100,\n",
    "        resize=imgsz,\n",
    "    )\n",
    "\n",
    "    # Split data into n parts\n",
    "    n_parts = len(clients)\n",
    "    dataset_parts = []\n",
    "    for i in range(n_parts):\n",
    "        train_loader = DataLoader(\n",
    "            mini, batch_size=task_num, shuffle=True, num_workers=1, pin_memory=True\n",
    "        )\n",
    "        dataset_parts.append(train_loader)\n",
    "\n",
    "    models = [maml for _ in range(len(clients))]\n",
    "\n",
    "    HE = Pyfhel()\n",
    "    ckks_params = {\n",
    "        \"scheme\": \"CKKS\",\n",
    "        \"n\": 2**14,\n",
    "        \"scale\": 2**30,\n",
    "        \"qi_sizes\": [60, 30, 30, 30, 60],\n",
    "    }\n",
    "    HE.contextGen(**ckks_params)\n",
    "    HE.keyGen()\n",
    "    HE.rotateKeyGen()\n",
    "\n",
    "    client_keys, shared_keys, client_shared_keys = setup_AES()\n",
    "\n",
    "    accuracies = [[] for _ in range(len(clients))]\n",
    "    losses = [[] for _ in range(len(clients))]\n",
    "\n",
    "    meta_batch_size = 32  # Number of tasks per meta-update\n",
    "    inner_batch_size = 5  # Number of examples per task\n",
    "    num_inner_updates = 5  # Number of inner loop updates per task\n",
    "    num_meta_updates = 100\n",
    "\n",
    "    cwts = [encrypt_wt(model.state_dict(), i) for i, model in enumerate(models)]\n",
    "    for e in tqdm(range(epoch)):\n",
    "        cwts = aggregate_wt(cwts)\n",
    "        wts = decrypt_weights(cwts)\n",
    "        cwts = []\n",
    "        for wt, model, dataset, i in zip(wts, models, dataset_parts, range(len(clients))):\n",
    "            model.load_state_dict(wt)\n",
    "            model, accuracy = train_model(model, dataset)\n",
    "            accuracies[i].append(accuracy.item())\n",
    "            print(\"Accuracies\", accuracy)\n",
    "\n",
    "            # Store the loss value for each client\n",
    "            loss = 1.0 - accuracy.item()\n",
    "            losses[i].append(loss)\n",
    "\n",
    "            wtarray = model.state_dict()\n",
    "            cwts.append(encrypt_wt(wtarray, i))\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    epochs_range = range(1, epoch + 1)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, client in enumerate(clients):\n",
    "        plt.plot(\n",
    "            epochs_range,\n",
    "            accuracies[i],\n",
    "            label=f\"Client {client}\" if client != 0 else \"Aggregate\",\n",
    "        )\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy for Each Client\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, client in enumerate(clients):\n",
    "        plt.plot(\n",
    "            epochs_range,\n",
    "            losses[i],\n",
    "            label=f\"Client {client}\" if client != 0 else \"Aggregate\",\n",
    "        )\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss for Each Client\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "he39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
