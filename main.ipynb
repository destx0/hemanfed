{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from MiniImagenet import MiniImagenet\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from copy import deepcopy\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniImagenet(Dataset):\n",
    "    def __init__(self, root, mode, batchsz, n_way, k_shot, k_query, resize, startidx=0):\n",
    "        self.batchsz = batchsz\n",
    "        self.n_way = n_way\n",
    "        self.k_shot = k_shot\n",
    "        self.k_query = k_query\n",
    "        self.setsz = self.n_way * self.k_shot\n",
    "        self.querysz = self.n_way * self.k_query\n",
    "        self.resize = resize\n",
    "        self.startidx = startidx\n",
    "        print(\n",
    "            \"shuffle DB :%s, b:%d, %d-way, %d-shot, %d-query, resize:%d\"\n",
    "            % (mode, batchsz, n_way, k_shot, k_query, resize)\n",
    "        )\n",
    "\n",
    "        if mode == \"train\":\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                    transforms.Resize((self.resize, self.resize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            self.transform = transforms.Compose(\n",
    "                [\n",
    "                    lambda x: Image.open(x).convert(\"RGB\"),\n",
    "                    transforms.Resize((self.resize, self.resize)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        self.path = os.path.join(root, \"images\")\n",
    "        csvdata = self.loadCSV(os.path.join(root, mode + \".csv\"))\n",
    "        self.data = []\n",
    "        self.img2label = {}\n",
    "        for i, (k, v) in enumerate(csvdata.items()):\n",
    "            self.data.append(v)\n",
    "            self.img2label[k] = i + self.startidx\n",
    "        self.cls_num = len(self.data)\n",
    "\n",
    "        self.create_batch(self.batchsz)\n",
    "\n",
    "    def loadCSV(self, csvf):\n",
    "        dictLabels = {}\n",
    "        with open(csvf) as csvfile:\n",
    "            csvreader = csv.reader(csvfile, delimiter=\",\")\n",
    "            next(csvreader, None)\n",
    "            for i, row in enumerate(csvreader):\n",
    "                filename = row[0]\n",
    "                label = row[1]\n",
    "                if label in dictLabels.keys():\n",
    "                    dictLabels[label].append(filename)\n",
    "                else:\n",
    "                    dictLabels[label] = [filename]\n",
    "        return dictLabels\n",
    "\n",
    "    def create_batch(self, batchsz):\n",
    "        self.support_x_batch = []\n",
    "        self.query_x_batch = []\n",
    "        for b in range(batchsz):\n",
    "            selected_cls = np.random.choice(self.cls_num, self.n_way, False)\n",
    "            np.random.shuffle(selected_cls)\n",
    "            support_x = []\n",
    "            query_x = []\n",
    "            for cls in selected_cls:\n",
    "                selected_imgs_idx = np.random.choice(\n",
    "                    len(self.data[cls]), self.k_shot + self.k_query, False\n",
    "                )\n",
    "                np.random.shuffle(selected_imgs_idx)\n",
    "                indexDtrain = np.array(selected_imgs_idx[: self.k_shot])\n",
    "                indexDtest = np.array(selected_imgs_idx[self.k_shot :])\n",
    "                support_x.append(np.array(self.data[cls])[indexDtrain].tolist())\n",
    "                query_x.append(np.array(self.data[cls])[indexDtest].tolist())\n",
    "\n",
    "            random.shuffle(support_x)\n",
    "            random.shuffle(query_x)\n",
    "\n",
    "            self.support_x_batch.append(support_x)\n",
    "            self.query_x_batch.append(query_x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        support_x = torch.FloatTensor(self.setsz, 3, self.resize, self.resize)\n",
    "        support_y = np.zeros((self.setsz), dtype=np.int32)\n",
    "        query_x = torch.FloatTensor(self.querysz, 3, self.resize, self.resize)\n",
    "        query_y = np.zeros((self.querysz), dtype=np.int32)\n",
    "\n",
    "        flatten_support_x = [\n",
    "            os.path.join(self.path, item)\n",
    "            for sublist in self.support_x_batch[index]\n",
    "            for item in sublist\n",
    "        ]\n",
    "        support_y = np.array(\n",
    "            [\n",
    "                self.img2label[item[:9]]\n",
    "                for sublist in self.support_x_batch[index]\n",
    "                for item in sublist\n",
    "            ]\n",
    "        ).astype(np.int32)\n",
    "\n",
    "        flatten_query_x = [\n",
    "            os.path.join(self.path, item)\n",
    "            for sublist in self.query_x_batch[index]\n",
    "            for item in sublist\n",
    "        ]\n",
    "        query_y = np.array(\n",
    "            [\n",
    "                self.img2label[item[:9]]\n",
    "                for sublist in self.query_x_batch[index]\n",
    "                for item in sublist\n",
    "            ]\n",
    "        ).astype(np.int32)\n",
    "\n",
    "        unique = np.unique(support_y)\n",
    "        random.shuffle(unique)\n",
    "        support_y_relative = np.zeros(self.setsz)\n",
    "        query_y_relative = np.zeros(self.querysz)\n",
    "        for idx, l in enumerate(unique):\n",
    "            support_y_relative[support_y == l] = idx\n",
    "            query_y_relative[query_y == l] = idx\n",
    "\n",
    "        for i, path in enumerate(flatten_support_x):\n",
    "            support_x[i] = self.transform(path)\n",
    "\n",
    "        for i, path in enumerate(flatten_query_x):\n",
    "            query_x[i] = self.transform(path)\n",
    "\n",
    "        return (\n",
    "            support_x,\n",
    "            torch.LongTensor(support_y_relative),\n",
    "            query_x,\n",
    "            torch.LongTensor(query_y_relative),\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batchsz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.utils.data import random_split, SubsetRandomSampler\n",
    "from torchvision import datasets, transforms, models \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./mini-imagenet\"\n",
    "csv_file = \"./mini-imagenet/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [0 , 1 ,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_parts = len(clients)\n",
    "part_size = len(X_train) // n_parts\n",
    "dataset_parts = []\n",
    "for i in range(n_parts):\n",
    "    start = i * part_size\n",
    "    end = (i + 1) * part_size\n",
    "    X_part = X_train[start:end]\n",
    "    y_part = y_train[start:end]\n",
    "    dataset_parts.append((X_part, y_part))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = root_dir\n",
    "csv_file = csv_file\n",
    "\n",
    "data = pd.read_csv(csv_file)\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "n_parts = len(clients)\n",
    "dataset_parts = []\n",
    "part_size = len(data) // n_parts\n",
    "for i in range(n_parts):\n",
    "    start = i * part_size\n",
    "    end = (i + 1) * part_size\n",
    "    dataset_parts.append(data.iloc[start:end].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([['n0774760700001069.jpg', 'n07747607'],\n",
       "        ['n0450941700000760.jpg', 'n04509417'],\n",
       "        ['n0383889900001242.jpg', 'n03838899'],\n",
       "        ...,\n",
       "        ['n0461250400000001.jpg', 'n04612504'],\n",
       "        ['n0279516900001176.jpg', 'n02795169'],\n",
       "        ['n0388860500000226.jpg', 'n03888605']], dtype=object),\n",
       " array([['n0425813800001252.jpg', 'n04258138'],\n",
       "        ['n0388860500000014.jpg', 'n03888605'],\n",
       "        ['n0282342800000353.jpg', 'n02823428'],\n",
       "        ...,\n",
       "        ['n0425813800000337.jpg', 'n04258138'],\n",
       "        ['n0211127700000559.jpg', 'n02111277'],\n",
       "        ['n0210855100000336.jpg', 'n02108551']], dtype=object),\n",
       " array([['n0279516900000399.jpg', 'n02795169'],\n",
       "        ['n0216545600000178.jpg', 'n02165456'],\n",
       "        ['n0450941700001187.jpg', 'n04509417'],\n",
       "        ...,\n",
       "        ['n0367648300000751.jpg', 'n03676483'],\n",
       "        ['n1305456000001232.jpg', 'n13054560'],\n",
       "        ['n0424354600001190.jpg', 'n04243546']], dtype=object)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(torch.tensor(X), torch.tensor(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "he38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
