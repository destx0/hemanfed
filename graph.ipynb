{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voy/.conda/envs/he39/lib/python3.9/site-packages/torch/cuda/__init__.py:118: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from cryptography.hazmat.primitives import hashes, serialization\n",
    "from cryptography.hazmat.primitives.asymmetric import dh\n",
    "from cryptography.hazmat.primitives.kdf.hkdf import HKDF\n",
    "from cryptography.hazmat.primitives.ciphers import Cipher, algorithms, modes\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import time\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as A\n",
    "\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchsummary import summary\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import numpy as np\n",
    "from Pyfhel import Pyfhel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [0 , 1 ,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Pyfhel import Pyfhel\n",
    "\n",
    "HE = Pyfhel()\n",
    "ckks_params = {\n",
    "    \"scheme\": \"CKKS\",\n",
    "    \"n\": 2**14,  # Polynomial modulus degree. For CKKS, n/2 values can be\n",
    "    \"scale\": 2**30,  # All the encodings will use it for float->fixed point\n",
    "    \"qi_sizes\": [60, 30, 30, 30, 60],  # Number of bits of each prime in the chain.\n",
    "}\n",
    "HE.contextGen(**ckks_params)  # Generate context for ckks scheme\n",
    "HE.keyGen()  # Key Generation: generates a pair of public/secret keys\n",
    "HE.rotateKeyGen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_diffie_hellman_parameters():\n",
    "    parameters = dh.generate_parameters(generator=2, key_size=512)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def generate_diffie_hellman_keys(parameters):\n",
    "    private_key = parameters.generate_private_key()\n",
    "    public_key = private_key.public_key()\n",
    "    return private_key, public_key\n",
    "\n",
    "\n",
    "def derive_key(private_key, peer_public_key):\n",
    "    shared_key = private_key.exchange(peer_public_key)\n",
    "    derived_key = HKDF(\n",
    "        algorithm=hashes.SHA256(),\n",
    "        length=32,\n",
    "        salt=None,\n",
    "        info=b\"handshake data\",\n",
    "    ).derive(shared_key)\n",
    "    return derived_key\n",
    "\n",
    "\n",
    "def encrypt_message_AES(key, message):\n",
    "    serialized_obj = pickle.dumps(message)\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    encryptor = cipher.encryptor()\n",
    "    padded_obj = serialized_obj + b\" \" * (16 - len(serialized_obj) % 16)\n",
    "    ciphertext = encryptor.update(padded_obj) + encryptor.finalize()\n",
    "    return ciphertext\n",
    "\n",
    "\n",
    "def decrypt_message_AES(key, ciphertext):\n",
    "    cipher = Cipher(algorithms.AES(key), modes.ECB())\n",
    "    decryptor = cipher.decryptor()\n",
    "    padded_obj = decryptor.update(ciphertext) + decryptor.finalize()\n",
    "    serialized_obj = padded_obj.rstrip(b\" \")\n",
    "    obj = pickle.loads(serialized_obj)\n",
    "    return obj\n",
    "\n",
    "\n",
    "def setup_AES():\n",
    "    num_clients = len(clients)\n",
    "    parameters = generate_diffie_hellman_parameters()\n",
    "    server_private_key, server_public_key = generate_diffie_hellman_keys(parameters)\n",
    "    client_keys = [generate_diffie_hellman_keys(parameters) for _ in range(num_clients)]\n",
    "    shared_keys = [\n",
    "        derive_key(server_private_key, client_public_key)\n",
    "        for _, client_public_key in client_keys\n",
    "    ]\n",
    "    client_shared_keys = [\n",
    "        derive_key(client_private_key, server_public_key)\n",
    "        for client_private_key, _ in client_keys\n",
    "    ]\n",
    "\n",
    "    return client_keys, shared_keys, client_shared_keys\n",
    "\n",
    "\n",
    "client_keys, shared_keys, client_shared_keys = setup_AES()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(model, weights):\n",
    "    with torch.no_grad():\n",
    "        for param, weight in zip(model.parameters(), weights):\n",
    "            param.copy_(torch.tensor(weight))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(model):\n",
    "    return [param.cpu().detach().numpy() for param in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_wt(encypted_cwts):\n",
    "    cwts = []\n",
    "    for i, ecwt in enumerate(encypted_cwts):\n",
    "        cwts.append(decrypt_message_AES(shared_keys[0], ecwt))\n",
    "    # cwts = encypted_cwts\n",
    "    resmodel = []\n",
    "    for j in range(len(cwts[0])):  # for layers\n",
    "        layer = []\n",
    "        for k in range(len(cwts[0][j])):  # for chunks\n",
    "            tmp = cwts[0][j][k].copy()\n",
    "            for i in range(1, len(cwts)):  # for clients\n",
    "                tmp = tmp + cwts[i][j][k]\n",
    "            tmp = tmp / len(cwts)\n",
    "            layer.append(tmp)\n",
    "        resmodel.append(layer)\n",
    "\n",
    "    res = [resmodel.copy() for _ in range(len(clients))]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_wt(wtarray, i):\n",
    "    cwt = []\n",
    "    for layer in wtarray:\n",
    "        flat_array = layer.astype(np.float64).flatten()\n",
    "\n",
    "        chunks = np.array_split(flat_array, (len(flat_array) + 2**13 - 1) // 2**13)\n",
    "        clayer = []\n",
    "        for chunk in chunks:\n",
    "            ptxt = HE.encodeFrac(chunk)\n",
    "            ctxt = HE.encryptPtxt(ptxt)\n",
    "            clayer.append(ctxt)\n",
    "        cwt.append(clayer.copy())\n",
    "    ciphertext = encrypt_message_AES(client_shared_keys[i], cwt)\n",
    "    return ciphertext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt_weights(res):\n",
    "    decrypted_weights = []\n",
    "    for client_weights, model in zip(res, models):\n",
    "        decrypted_client_weights = []\n",
    "        wtarray = get_weights(model)\n",
    "        for layer_weights, layer in zip(client_weights, wtarray):\n",
    "            decrypted_layer_weights = []\n",
    "            flat_array = layer.astype(np.float64).flatten()\n",
    "            chunks = np.array_split(flat_array, (len(flat_array) + 2**13 - 1) // 2**13)\n",
    "            for chunk, encrypted_chunk in zip(chunks, layer_weights):\n",
    "                decrypted_chunk = HE.decryptFrac(encrypted_chunk)\n",
    "                original_chunk_size = len(chunk)\n",
    "                decrypted_chunk = decrypted_chunk[:original_chunk_size]\n",
    "                decrypted_layer_weights.append(decrypted_chunk)\n",
    "            decrypted_layer_weights = np.concatenate(decrypted_layer_weights, axis=0)\n",
    "            decrypted_layer_weights = decrypted_layer_weights.reshape(layer.shape)\n",
    "            decrypted_client_weights.append(decrypted_layer_weights)\n",
    "        decrypted_weights.append(decrypted_client_weights)\n",
    "    return decrypted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loading ResNet50 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voy/.conda/envs/he39/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/voy/.conda/envs/he39/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Preparing dummy dataset...\n",
      "Dummy dataset prepared successfully!\n",
      "Training model for one epoch without encryption...\n",
      "[10] loss: 7.527\n",
      "[20] loss: 5.062\n",
      "[30] loss: 3.129\n",
      "Training time without encryption: 148.96 seconds\n",
      "Encrypting model parameters...\n",
      "Encryption time: 0.02 seconds\n",
      "Updating model with encrypted parameters...\n",
      "Model updated with encrypted parameters!\n",
      "Training model for one epoch with encrypted parameters...\n",
      "[10] loss: 6.520\n",
      "[20] loss: 5.667\n",
      "[30] loss: 5.096\n",
      "Training time with encryption: 133.28 seconds\n",
      "Final Results:\n",
      "Training time without encryption: 148.96 seconds\n",
      "Training time with encryption: 133.28 seconds\n",
      "Encryption time: 0.02 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# Example encryption function (dummy encryption)\n",
    "def encrypt_model_parameters(parameters):\n",
    "    encrypted_params = [param**2 for param in parameters]\n",
    "    return encrypted_params\n",
    "\n",
    "\n",
    "# Load ResNet50 model\n",
    "print(\"Loading ResNet50 model...\")\n",
    "model = torchvision.models.resnet50(pretrained=True).to(device)\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Prepare dummy dataset\n",
    "print(\"Preparing dummy dataset...\")\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "trainset = torchvision.datasets.FakeData(transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "print(\"Dummy dataset prepared successfully!\")\n",
    "\n",
    "# Function to train the model for one epoch\n",
    "def train_one_epoch(model, trainloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:  # Print every 10 batches\n",
    "            print(f\"[{i + 1}] loss: {running_loss / 10:.3f}\")\n",
    "            running_loss = 0.0\n",
    "    return running_loss\n",
    "\n",
    "\n",
    "# Measure training time without encryption\n",
    "print(\"Training model for one epoch without encryption...\")\n",
    "start_time = time.time()\n",
    "train_one_epoch(model, trainloader, criterion, optimizer, device)\n",
    "end_time = time.time()\n",
    "time_without_encryption = end_time - start_time\n",
    "print(f\"Training time without encryption: {time_without_encryption:.2f} seconds\")\n",
    "\n",
    "# Encrypt model parameters\n",
    "print(\"Encrypting model parameters...\")\n",
    "model_parameters = [param.data.clone().detach() for param in model.parameters()]\n",
    "start_encryption_time = time.time()\n",
    "encrypted_parameters = encrypt_model_parameters(model_parameters)\n",
    "end_encryption_time = time.time()\n",
    "encryption_time = end_encryption_time - start_encryption_time\n",
    "print(f\"Encryption time: {encryption_time:.2f} seconds\")\n",
    "\n",
    "# Update model with encrypted parameters (dummy update for demonstration)\n",
    "print(\"Updating model with encrypted parameters...\")\n",
    "for param, encrypted_param in zip(model.parameters(), encrypted_parameters):\n",
    "    param.data = encrypted_param.to(device)\n",
    "print(\"Model updated with encrypted parameters!\")\n",
    "\n",
    "# Measure training time with encryption\n",
    "print(\"Training model for one epoch with encrypted parameters...\")\n",
    "start_time = time.time()\n",
    "train_one_epoch(model, trainloader, criterion, optimizer, device)\n",
    "end_time = time.time()\n",
    "time_with_encryption = end_time - start_time\n",
    "print(f\"Training time with encryption: {time_with_encryption:.2f} seconds\")\n",
    "\n",
    "# Print final results\n",
    "print(\"Final Results:\")\n",
    "print(f\"Training time without encryption: {time_without_encryption:.2f} seconds\")\n",
    "print(f\"Training time with encryption: {time_with_encryption:.2f} seconds\")\n",
    "print(f\"Encryption time: {encryption_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " encryption time : 44.98 seconds\n"
     ]
    }
   ],
   "source": [
    "start_encryption_time = time.time()\n",
    "ew = encrypt_wt(get_weights(model), 0)\n",
    "end_encryption_time = time.time()\n",
    "encryption_time = end_encryption_time - start_encryption_time\n",
    "print(f\" encryption time : {encryption_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ags_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 2\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43maggregate_wt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mew\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m age_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m aggregation time : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mage_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mags_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36maggregate_wt\u001b[0;34m(encypted_cwts)\u001b[0m\n\u001b[1;32m      2\u001b[0m cwts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, ecwt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(encypted_cwts):\n\u001b[0;32m----> 4\u001b[0m     cwts\u001b[38;5;241m.\u001b[39mappend(\u001b[43mdecrypt_message_AES\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshared_keys\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mecwt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# cwts = encypted_cwts\u001b[39;00m\n\u001b[1;32m      6\u001b[0m resmodel \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[4], line 37\u001b[0m, in \u001b[0;36mdecrypt_message_AES\u001b[0;34m(key, ciphertext)\u001b[0m\n\u001b[1;32m     35\u001b[0m padded_obj \u001b[38;5;241m=\u001b[39m decryptor\u001b[38;5;241m.\u001b[39mupdate(ciphertext) \u001b[38;5;241m+\u001b[39m decryptor\u001b[38;5;241m.\u001b[39mfinalize()\n\u001b[1;32m     36\u001b[0m serialized_obj \u001b[38;5;241m=\u001b[39m padded_obj\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserialized_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ags_time = time.time()\n",
    "res = aggregate_wt([ew for _ in range(5)])\n",
    "age_time = time.time()  \n",
    "print(f\" aggregation time : {age_time - ags_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dencryption time : 6.41 seconds\n"
     ]
    }
   ],
   "source": [
    "start_dencryption_time = time.time()\n",
    "ew = encrypt_wt(get_weights(model), 0)\n",
    "end_encryption_time = time.time()\n",
    "encryption_time = end_encryption_time - start_dencryption_time\n",
    "print(f\" dencryption time : {encryption_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in      : 3504872\n",
      "Size of the       model: 13.60 MB\n",
      "Final Results:\n",
      "Number of parameters in : 3504872\n",
      "Size of the : 13.60 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import os\n",
    "\n",
    "\n",
    "# Count the number of parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters in      : {num_params}\")\n",
    "\n",
    "# Save the model to disk and get its size\n",
    "model_path = \"resnet50.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "model_size = os.path.getsize(model_path)\n",
    "print(f\"Size of the       model: {model_size / (1024 * 1024):.2f} MB\")\n",
    "\n",
    "# Cleanup\n",
    "os.remove(model_path)\n",
    "\n",
    "# Print results\n",
    "print(f\"Final Results:\")\n",
    "print(f\"Number of parameters in : {num_params}\")\n",
    "print(f\"Size of the : {model_size / (1024 * 1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579941217\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "size = sys.getsizeof(ew)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of pickle file: 14281067 bytes\n",
      "Size of pickle file: 13946.35 KB\n",
      "Size of pickle file: 13.62 MB\n",
      "Size of pickle file: 0.013300 GB\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "example_obj = model\n",
    "\n",
    "# Save object to a pickle file\n",
    "pickle_file = \"example_obj.pkl\"\n",
    "with open(pickle_file, \"wb\") as file:\n",
    "    pickle.dump(example_obj, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Check the size of the pickle file\n",
    "file_size_bytes = os.path.getsize(pickle_file)\n",
    "file_size_kb = file_size_bytes / 1024\n",
    "file_size_mb = file_size_kb / 1024\n",
    "file_size_gb = file_size_mb / 1024\n",
    "\n",
    "print(f\"Size of pickle file: {file_size_bytes} bytes\")\n",
    "print(f\"Size of pickle file: {file_size_kb:.2f} KB\")\n",
    "print(f\"Size of pickle file: {file_size_mb:.2f} MB\")\n",
    "print(f\"Size of pickle file: {file_size_gb:.6f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of pickle file: 579941193 bytes\n",
      "Size of pickle file: 566348.82 KB\n",
      "Size of pickle file: 553.08 MB\n",
      "Size of pickle file: 0.540112 GB\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "\n",
    "example_obj = ew\n",
    "\n",
    "# Save object to a pickle file\n",
    "pickle_file = \"example_obj.pkl\"\n",
    "with open(pickle_file, \"wb\") as file:\n",
    "    pickle.dump(example_obj, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# Check the size of the pickle file\n",
    "file_size_bytes = os.path.getsize(pickle_file)\n",
    "file_size_kb = file_size_bytes / 1024\n",
    "file_size_mb = file_size_kb / 1024\n",
    "file_size_gb = file_size_mb / 1024\n",
    "\n",
    "print(f\"Size of pickle file: {file_size_bytes} bytes\")\n",
    "print(f\"Size of pickle file: {file_size_kb:.2f} KB\")\n",
    "print(f\"Size of pickle file: {file_size_mb:.2f} MB\")\n",
    "print(f\"Size of pickle file: {file_size_gb:.6f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "he39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
